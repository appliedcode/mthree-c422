{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyODo/uVBW4f7It3iTGlq+0+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/appliedcode/mthree-c422/blob/mthree-422-salleh/Exercises/day-14/Audit_GovernanceAI_Audit_Governance_Practice_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Problem Statement**\n",
        "\n",
        "You are tasked with evaluating and auditing a machine learning–based **credit scoring model** to ensure it complies with **AI governance principles**, including fairness, transparency, and accountability.\n",
        "\n",
        "The goal is to:\n",
        "\n",
        "- Detect and measure potential **bias** in model predictions across demographic groups (in this case, `age_group` — younger vs older applicants).\n",
        "- Provide **model transparency** through explainability tools such as **SHAP** to understand feature influences on decisions.\n",
        "- Implement **AI auditing steps** by logging performance metrics, bias analysis, and interpretability findings, with proper documentation that could be used for **regulatory compliance** and internal governance processes.\n",
        "\n",
        "You must train, evaluate, audit, and document the AI model in a way that aligns with **ethical AI adoption** in financial services.\n",
        "\n",
        "**In this exercise, we will use the publicly available \"Credit-G\" dataset from OpenML.**\n",
        "\n",
        "### **Dataset Collection Code**\n",
        "\n"
      ],
      "metadata": {
        "id": "HaQejtuyrWAd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install necessary packages\n",
        "!pip install shap scikit-learn pandas -q\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.datasets import fetch_openml\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import shap\n",
        "import datetime"
      ],
      "metadata": {
        "id": "PkXDDf05sd1n"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import fetch_openml\n",
        "\n",
        "# Load dataset from OpenML\n",
        "credit_data = fetch_openml(name='credit-g', version=1, as_frame=True)\n",
        "\n",
        "# Features (X) and Target (y)\n",
        "X = credit_data.data\n",
        "y = credit_data.target\n",
        "\n",
        "# Convert target labels to binary (1 = good credit, 0 = bad credit)\n",
        "y = y.map({'good': 1, 'bad': 0})\n",
        "\n",
        "print(\"Dataset shape:\", X.shape)\n",
        "print(\"Target distribution:\\n\", y.value_counts())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b-Blchvlrq6N",
        "outputId": "d9cd044a-78dc-45ec-aab0-130b839069ac"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset shape: (1000, 20)\n",
            "Target distribution:\n",
            " class\n",
            "1    700\n",
            "0    300\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# One-hot encode categorical columns\n",
        "X_encoded = pd.get_dummies(X)\n",
        "# N.B. This was added to get rid of error: \"ValueError: could not convert string to float: 'no checking'\" on \"clf.fit(X_train, y_train)\" below\n",
        "\n",
        "# -------------------\n",
        "# Train-test split\n",
        "# -------------------\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X_encoded, y, test_size=0.3, random_state=42\n",
        ")"
      ],
      "metadata": {
        "id": "LUwXncydsqz2"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -------------------\n",
        "# Model Training\n",
        "# -------------------\n",
        "clf = RandomForestClassifier(random_state=42)\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "# Predictions\n",
        "y_pred = clf.predict(X_test)"
      ],
      "metadata": {
        "id": "S13fP1zutrou"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -------------------\n",
        "# Model Evaluation\n",
        "# -------------------\n",
        "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p5o8FAg5v5BO",
        "outputId": "0c6137cd-ab52-446a-bba4-43c141694e03"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.72      0.36      0.48        91\n",
            "           1       0.77      0.94      0.85       209\n",
            "\n",
            "    accuracy                           0.76       300\n",
            "   macro avg       0.74      0.65      0.66       300\n",
            "weighted avg       0.76      0.76      0.74       300\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# -------------------\n",
        "# AI Auditing Step 1: Log metrics\n",
        "# -------------------\n",
        "audit_log = {\n",
        "    \"timestamp\": datetime.datetime.now().isoformat(),\n",
        "    \"classification_report\": classification_report(y_test, y_pred, output_dict=True),\n",
        "    \"confusion_matrix\": confusion_matrix(y_test, y_pred).tolist()\n",
        "}\n",
        "print(\"\\nAudit Log Initial Entry:\\n\", audit_log)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bl9xQsLhwZ49",
        "outputId": "f7627411-4413-4b22-fa36-e6a98d744634"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Audit Log Initial Entry:\n",
            " {'timestamp': '2025-08-14T08:45:47.006558', 'classification_report': {'0': {'precision': 0.717391304347826, 'recall': 0.3626373626373626, 'f1-score': 0.48175182481751827, 'support': 91.0}, '1': {'precision': 0.7716535433070866, 'recall': 0.937799043062201, 'f1-score': 0.8466522678185745, 'support': 209.0}, 'accuracy': 0.7633333333333333, 'macro avg': {'precision': 0.7445224238274564, 'recall': 0.6502182028497818, 'f1-score': 0.6642020463180464, 'support': 300.0}, 'weighted avg': {'precision': 0.7551939974894443, 'recall': 0.7633333333333333, 'f1-score': 0.7359658001082541, 'support': 300.0}}, 'confusion_matrix': [[33, 58], [13, 196]]}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# -------------------\n",
        "# Bias Detection by Age Group\n",
        "# -------------------\n",
        "test_results = X_test.copy()\n",
        "test_results['actual'] = y_test\n",
        "test_results['predicted'] = y_pred\n",
        "\n",
        "grouped = test_results.groupby('age_group').agg(\n",
        "    total=('actual', 'count'),\n",
        "    positive_rate_actual=('actual', 'mean'),\n",
        "    positive_rate_predicted=('predicted', 'mean')\n",
        ")\n",
        "print(\"\\nOutcome rates by Age Group:\\n\", grouped)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        },
        "id": "zSVGDR6IwxLA",
        "outputId": "af412121-1773-4d70-d5e0-4aa9507fef3f"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "'age_group'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-4247412708.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mtest_results\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'predicted'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m grouped = test_results.groupby('age_group').agg(\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0mtotal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'actual'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'count'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mpositive_rate_actual\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'actual'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'mean'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mgroupby\u001b[0;34m(self, by, axis, level, as_index, sort, group_keys, observed, dropna)\u001b[0m\n\u001b[1;32m   9181\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"You have to supply one of 'by' and 'level'\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   9182\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 9183\u001b[0;31m         return DataFrameGroupBy(\n\u001b[0m\u001b[1;32m   9184\u001b[0m             \u001b[0mobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   9185\u001b[0m             \u001b[0mkeys\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mby\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/groupby/groupby.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, obj, keys, axis, level, grouper, exclusions, selection, as_index, sort, group_keys, observed, dropna)\u001b[0m\n\u001b[1;32m   1327\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1328\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mgrouper\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1329\u001b[0;31m             grouper, exclusions, obj = get_grouper(\n\u001b[0m\u001b[1;32m   1330\u001b[0m                 \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1331\u001b[0m                 \u001b[0mkeys\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/groupby/grouper.py\u001b[0m in \u001b[0;36mget_grouper\u001b[0;34m(obj, key, axis, level, sort, observed, validate, dropna)\u001b[0m\n\u001b[1;32m   1041\u001b[0m                 \u001b[0min_axis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgpr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgpr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1042\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1043\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgpr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1044\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgpr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mGrouper\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mgpr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkey\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1045\u001b[0m             \u001b[0;31m# Add key to exclusions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'age_group'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Add bias report to audit log\n",
        "bias_report = grouped.to_string()\n",
        "audit_log['bias_report'] = bias_report\n",
        "\n",
        "# -------------------\n",
        "# Model Interpretability with SHAP\n",
        "# -------------------\n",
        "explainer = shap.TreeExplainer(clf)\n",
        "shap_values = explainer.shap_values(X_test)\n",
        "\n",
        "# Plot summary for positive class (good credit)\n",
        "shap.summary_plot(shap_values[1], X_test)\n",
        "\n",
        "# -------------------\n",
        "# Compliance & Audit Documentation\n",
        "# -------------------\n",
        "compliance_notes = f\"\"\"\n",
        "Model Compliance and Audit Report:\n",
        "-----------------------------------\n",
        "Timestamp: {audit_log['timestamp']}\n",
        "\n",
        "Bias Detection:\n",
        "Outcome disparities between age groups:\n",
        "{bias_report}\n",
        "\n",
        "Model Performance:\n",
        "- Detailed metrics in classification report\n",
        "- Confusion matrix: {audit_log[\"confusion_matrix\"]}\n",
        "\n",
        "Transparency:\n",
        "- SHAP used to interpret feature importance and influence\n",
        "- Explainability provided for decision accountability\n",
        "\n",
        "Governance & Auditing:\n",
        "- Metrics, bias analysis, and interpretability documented\n",
        "- Ready for review under AI governance and financial regulatory frameworks\n",
        "\"\"\"\n",
        "\n",
        "print(compliance_notes)"
      ],
      "metadata": {
        "id": "twCdCpe4xTqE"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}