{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/appliedcode/mthree-c422/blob/mthree-c422-dipti/Exercises/day-6/Data_Cleaning/Data_Cleaning_Demo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data Cleansing with the Titanic Dataset in Google Colab\n",
        "Inspired by the image, this lab guides you step-by-step through practical data cleaning operations using the Titanic dataset. Itâ€™s designed for hands-on use in Google Colab.\n",
        "\n",
        "Objectives\n",
        "- Load and inspect the Titanic dataset.\n",
        "\n",
        "- Identify and handle missing or problematic data.\n",
        "\n",
        "- Apply data cleaning techniques using pandas.\n",
        "\n"
      ],
      "metadata": {
        "id": "RpsOG3v9XMxn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Set Up the Environment\n",
        "# Install pandas if not available (usually pre-installed in Colab)\n",
        "!pip install pandas\n"
      ],
      "metadata": {
        "id": "a5YshFxxYuMt",
        "outputId": "6bd1fb15-df90-4fbf-fd1a-0bfdf16c88d6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 2: Load the Titanic Dataset\n",
        "import pandas as pd\n",
        "\n",
        "url = \"https://raw.githubusercontent.com/datasciencedojo/datasets/master/titanic.csv\"\n",
        "df = pd.read_csv(url)\n",
        "print(df.head())\n"
      ],
      "metadata": {
        "id": "8P6FIt_AYwvl",
        "outputId": "618398ea-eb4c-4381-a2dc-9620ff1f06a8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   PassengerId  Survived  Pclass  \\\n",
            "0            1         0       3   \n",
            "1            2         1       1   \n",
            "2            3         1       3   \n",
            "3            4         1       1   \n",
            "4            5         0       3   \n",
            "\n",
            "                                                Name     Sex   Age  SibSp  \\\n",
            "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
            "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
            "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
            "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
            "4                           Allen, Mr. William Henry    male  35.0      0   \n",
            "\n",
            "   Parch            Ticket     Fare Cabin Embarked  \n",
            "0      0         A/5 21171   7.2500   NaN        S  \n",
            "1      0          PC 17599  71.2833   C85        C  \n",
            "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
            "3      0            113803  53.1000  C123        S  \n",
            "4      0            373450   8.0500   NaN        S  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 3: Preliminary Data Inspection\n",
        "# General info and statistics\n",
        "print(df.info())\n",
        "print(df.describe())\n",
        "\n",
        "# Check for missing values\n",
        "print(df.isnull().sum())\n"
      ],
      "metadata": {
        "id": "DS2Al26qY-pd",
        "outputId": "200e6376-17cd-4617-be61-fa47167232da",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 891 entries, 0 to 890\n",
            "Data columns (total 12 columns):\n",
            " #   Column       Non-Null Count  Dtype  \n",
            "---  ------       --------------  -----  \n",
            " 0   PassengerId  891 non-null    int64  \n",
            " 1   Survived     891 non-null    int64  \n",
            " 2   Pclass       891 non-null    int64  \n",
            " 3   Name         891 non-null    object \n",
            " 4   Sex          891 non-null    object \n",
            " 5   Age          714 non-null    float64\n",
            " 6   SibSp        891 non-null    int64  \n",
            " 7   Parch        891 non-null    int64  \n",
            " 8   Ticket       891 non-null    object \n",
            " 9   Fare         891 non-null    float64\n",
            " 10  Cabin        204 non-null    object \n",
            " 11  Embarked     889 non-null    object \n",
            "dtypes: float64(2), int64(5), object(5)\n",
            "memory usage: 83.7+ KB\n",
            "None\n",
            "       PassengerId    Survived      Pclass         Age       SibSp  \\\n",
            "count   891.000000  891.000000  891.000000  714.000000  891.000000   \n",
            "mean    446.000000    0.383838    2.308642   29.699118    0.523008   \n",
            "std     257.353842    0.486592    0.836071   14.526497    1.102743   \n",
            "min       1.000000    0.000000    1.000000    0.420000    0.000000   \n",
            "25%     223.500000    0.000000    2.000000   20.125000    0.000000   \n",
            "50%     446.000000    0.000000    3.000000   28.000000    0.000000   \n",
            "75%     668.500000    1.000000    3.000000   38.000000    1.000000   \n",
            "max     891.000000    1.000000    3.000000   80.000000    8.000000   \n",
            "\n",
            "            Parch        Fare  \n",
            "count  891.000000  891.000000  \n",
            "mean     0.381594   32.204208  \n",
            "std      0.806057   49.693429  \n",
            "min      0.000000    0.000000  \n",
            "25%      0.000000    7.910400  \n",
            "50%      0.000000   14.454200  \n",
            "75%      0.000000   31.000000  \n",
            "max      6.000000  512.329200  \n",
            "PassengerId      0\n",
            "Survived         0\n",
            "Pclass           0\n",
            "Name             0\n",
            "Sex              0\n",
            "Age            177\n",
            "SibSp            0\n",
            "Parch            0\n",
            "Ticket           0\n",
            "Fare             0\n",
            "Cabin          687\n",
            "Embarked         2\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 4: Data Cleansing Tasks\n",
        "# 4.1: Handling Missing Values\n",
        "\n",
        "# Drop columns with too many missing values or not useful\n",
        "df = df.drop(columns=['Cabin'])\n",
        "\n",
        "# Fill missing 'Age' values with the median\n",
        "df['Age'].fillna(df['Age'].median(), inplace=True)\n",
        "\n",
        "# Fill missing 'Embarked' values with the mode\n",
        "df['Embarked'].fillna(df['Embarked'].mode()[0], inplace=True)\n"
      ],
      "metadata": {
        "id": "HAlXERpgZAVg",
        "outputId": "0270b4e8-5e0a-4e0f-a9b8-7a6b2531e359",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2547701583.py:8: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df['Age'].fillna(df['Age'].median(), inplace=True)\n",
            "/tmp/ipython-input-2547701583.py:11: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df['Embarked'].fillna(df['Embarked'].mode()[0], inplace=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 4.2: Remove Duplicates (if any)\n",
        "df = df.drop_duplicates()\n"
      ],
      "metadata": {
        "id": "LUdOqnKLZGkr"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 4.3: Convert Categorical Variables to Numeric (optional)\n",
        "df['Sex'] = df['Sex'].map({'male': 0, 'female': 1})\n",
        "df = pd.get_dummies(df, columns=['Embarked'], drop_first=True)\n"
      ],
      "metadata": {
        "id": "0GuuUCURZIg1"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 5: Verify the Clean Data\n",
        "print(df.isnull().sum())\n",
        "print(df.head())\n",
        "print(df.info())\n"
      ],
      "metadata": {
        "id": "j7MIkV44ZMTU",
        "outputId": "780eeeb1-cfbe-4414-cec4-3ef7f4e066a9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PassengerId    0\n",
            "Survived       0\n",
            "Pclass         0\n",
            "Name           0\n",
            "Sex            0\n",
            "Age            0\n",
            "SibSp          0\n",
            "Parch          0\n",
            "Ticket         0\n",
            "Fare           0\n",
            "Embarked_Q     0\n",
            "Embarked_S     0\n",
            "dtype: int64\n",
            "   PassengerId  Survived  Pclass  \\\n",
            "0            1         0       3   \n",
            "1            2         1       1   \n",
            "2            3         1       3   \n",
            "3            4         1       1   \n",
            "4            5         0       3   \n",
            "\n",
            "                                                Name  Sex   Age  SibSp  Parch  \\\n",
            "0                            Braund, Mr. Owen Harris    0  22.0      1      0   \n",
            "1  Cumings, Mrs. John Bradley (Florence Briggs Th...    1  38.0      1      0   \n",
            "2                             Heikkinen, Miss. Laina    1  26.0      0      0   \n",
            "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)    1  35.0      1      0   \n",
            "4                           Allen, Mr. William Henry    0  35.0      0      0   \n",
            "\n",
            "             Ticket     Fare  Embarked_Q  Embarked_S  \n",
            "0         A/5 21171   7.2500       False        True  \n",
            "1          PC 17599  71.2833       False       False  \n",
            "2  STON/O2. 3101282   7.9250       False        True  \n",
            "3            113803  53.1000       False        True  \n",
            "4            373450   8.0500       False        True  \n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 891 entries, 0 to 890\n",
            "Data columns (total 12 columns):\n",
            " #   Column       Non-Null Count  Dtype  \n",
            "---  ------       --------------  -----  \n",
            " 0   PassengerId  891 non-null    int64  \n",
            " 1   Survived     891 non-null    int64  \n",
            " 2   Pclass       891 non-null    int64  \n",
            " 3   Name         891 non-null    object \n",
            " 4   Sex          891 non-null    int64  \n",
            " 5   Age          891 non-null    float64\n",
            " 6   SibSp        891 non-null    int64  \n",
            " 7   Parch        891 non-null    int64  \n",
            " 8   Ticket       891 non-null    object \n",
            " 9   Fare         891 non-null    float64\n",
            " 10  Embarked_Q   891 non-null    bool   \n",
            " 11  Embarked_S   891 non-null    bool   \n",
            "dtypes: bool(2), float64(2), int64(6), object(2)\n",
            "memory usage: 71.5+ KB\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 6: Reflection Questions\n",
        "In your Colab notebook, answer:\n",
        "\n",
        "- What were the main issues you found during the cleaning process?\n",
        "Ans:- The main data quality issues found during cleaning included:\n",
        "\n",
        "Missing values:\n",
        "Age had 177 missing entries.\n",
        "Cabin had 687 missing entries.\n",
        "Embarked had 2 missing entries.\n",
        "\n",
        "Irrelevant or sparse columns:Cabin was dropped due to too many missing values.\n",
        "\n",
        "Categorical variables:The Sex and Embarked columns were converted to numeric format for easier analysis/modeling.\n",
        "\n",
        "Possible duplicates:Duplicates were checked and removed to avoid data skew.\n",
        "\n",
        "\n",
        "- Why is it important to handle missing values appropriately?\n",
        "Ans:-Missing data can bias results:Ignoring missing values may lead to inaccurate conclusions or misleading model predictions.\n",
        "\n",
        "Some algorithms cannot handle NaNs:Machine learning models (like Logistic Regression or SVM) typically fail if missing values are present.\n",
        "\n",
        "Preserving data integrity:Filling missing values (using median/mode/mean or advanced techniques) helps maintain data completeness and consistency.\n",
        "\n",
        "- What are potential risks if data cleansing is skipped before modeling/analysis?\n",
        "Ans:-Model failure:Algorithms may crash or produce errors when fed unclean data.\n",
        "\n",
        "Poor performance:Irrelevant features or noise can lower model accuracy.\n",
        "\n",
        "Biased predictions:Models trained on incomplete or incorrect data may generalize poorly.\n",
        "\n",
        "Misleading insights:Exploratory analysis may reflect patterns based on errors, not actual trends.\n",
        "\n",
        "Interpretability issues:Dirty data can hide meaningful relationships between variables."
      ],
      "metadata": {
        "id": "B94DmrlTZTcI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# (Optional) Save the Cleaned Dataset\n",
        "df.to_csv(\"titanic_cleaned.csv\", index=False)\n"
      ],
      "metadata": {
        "id": "vijfchs7ZPIc"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Deliverables:\n",
        "\n",
        "- Code outputs for each task.\n",
        "\n",
        "- Written answers to the reflection questions."
      ],
      "metadata": {
        "id": "amzKTjUEZwnQ"
      }
    }
  ],
  "metadata": {
    "colab": {
      "name": "Welcome to Colab",
      "toc_visible": true,
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}