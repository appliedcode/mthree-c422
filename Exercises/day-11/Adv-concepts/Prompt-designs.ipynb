{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/appliedcode/mthree-c422/blob/main/Exercises/day-11/Adv-concepts/Prompt-designs.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# üìì Lab: Advanced Prompt Design Techniques in AI Conversations"
      ],
      "metadata": {
        "id": "hFnkDgKDTUgk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Setup\n",
        "!pip install openai -q\n",
        "\n",
        "from openai import OpenAI\n",
        "client = OpenAI(api_key=\"YOUR_API_KEY\")  # Replace with your API key\n",
        "\n",
        "def ask_gpt(prompt, temperature=0.7, max_tokens=500):\n",
        "    \"\"\"Query GPT-4o-mini (or another model) with given prompt.\"\"\"\n",
        "    response = client.chat.completions.create(\n",
        "        model=\"gpt-4o-mini\",\n",
        "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "        temperature=temperature,\n",
        "        max_tokens=max_tokens\n",
        "    )\n",
        "    return response.choices[0].message.content"
      ],
      "metadata": {
        "id": "tum27-jCRCHH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **1Ô∏è‚É£ Interview Pattern Prompting**\n",
        "\n",
        "**Goal:** Simulate an interview by prompting the model to ask and answer a series of questions on a topic. Helps in extracting detailed and structured info."
      ],
      "metadata": {
        "id": "3CPaNFrYRGxO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "base_prompt = \"\"\"\n",
        "Simulate an interview between a reporter and an AI expert about the impact of AI on education.\n",
        "Format it as a Q&A conversation with the reporter asking questions and the expert answering.\n",
        "Start with an introductory question.\n",
        "\"\"\"\n",
        "\n",
        "print(ask_gpt(base_prompt, temperature=0.6))"
      ],
      "metadata": {
        "id": "2vMB3TKnRHNn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **2Ô∏è‚É£ Tree-of-Thoughts Prompting**\n",
        "\n",
        "**Goal:** Explore multiple lines of reasoning or ideas branching from a prompt before converging on an answer."
      ],
      "metadata": {
        "id": "YB1JLDOURLet"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"\"\"\n",
        "You want to plan a weekend trip. Using a tree-of-thoughts approach, list 3 possible destinations.\n",
        "For each destination, list 2 pros and 2 cons.\n",
        "Then choose the best destination and explain why.\n",
        "\"\"\"\n",
        "\n",
        "print(ask_gpt(prompt, temperature=0.7))"
      ],
      "metadata": {
        "id": "O982EGKMRNB8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **3Ô∏è‚É£ Step-by-Step Reasoning \\& Decomposition**\n",
        "\n",
        "**Goal:** Decompose complex problems into steps and guide the AI to reason about each part sequentially."
      ],
      "metadata": {
        "id": "z_tt5nA4RO4I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"\"\"\n",
        "Q: A bookstore sold 30 books on Monday and 20% more on Tuesday.\n",
        "Calculate how many books were sold on Tuesday and in total.\n",
        "Let's decompose and reason step-by-step.\n",
        "\"\"\"\n",
        "\n",
        "print(ask_gpt(prompt, temperature=0))"
      ],
      "metadata": {
        "id": "cx8TjPsaRPwN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **4Ô∏è‚É£ Combining Prompts \\& Managing Context**\n",
        "\n",
        "**Goal:** Use multiple prompts or instructions combined to explore different aspects of a problem in one session."
      ],
      "metadata": {
        "id": "k_G-xkGGRSRW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"\"\"\n",
        "You are a financial advisor.\n",
        "\n",
        "Part 1: Summarize the benefits of investing in renewable energy funds.\n",
        "Part 2: List 3 risks associated with these investments.\n",
        "Part 3: Provide advice on how to mitigate these risks.\n",
        "\n",
        "Answer each part clearly.\n",
        "\"\"\"\n",
        "\n",
        "print(ask_gpt(prompt, temperature=0.7))"
      ],
      "metadata": {
        "id": "zbFdASwMRUeP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **5Ô∏è‚É£ Prompt Chaining \\& Multi-Turn Conversations**\n",
        "\n",
        "**Goal:** Maintain context over multiple conversational turns, where each turn builds on previous responses."
      ],
      "metadata": {
        "id": "4ZrSZmSuRXwF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Simulate multi-turn conversation by running prompts sequentially:\n",
        "\n",
        "# Turn 1: Ask for basic explanation\n",
        "turn1 = \"Explain blockchain technology in simple terms.\"\n",
        "\n",
        "response1 = ask_gpt(turn1)\n",
        "print(\"Turn 1 Response:\\n\", response1)\n",
        "\n",
        "# Turn 2: Ask for comparison based on previous answer\n",
        "turn2 = f\"\"\"Based on your previous explanation: \"{response1}\",\n",
        "explain how blockchain differs from traditional databases.\"\"\"\n",
        "\n",
        "response2 = ask_gpt(turn2)\n",
        "print(\"\\nTurn 2 Response:\\n\", response2)\n",
        "\n",
        "# Turn 3: Ask for real-world applications using previous info\n",
        "turn3 = f\"\"\"Given previous responses:\n",
        "1. {response1}\n",
        "2. {response2}\n",
        "List 3 industries that can benefit from blockchain and why.\n",
        "\"\"\"\n",
        "\n",
        "response3 = ask_gpt(turn3)\n",
        "print(\"\\nTurn 3 Response:\\n\", response3)"
      ],
      "metadata": {
        "id": "BT3WP1HaRaG4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# üí° Tips for Students:\n",
        "\n",
        "- Experiment with your own prompts to see how outputs vary.\n",
        "- Compare responses when adding or removing instructions.\n",
        "- Try chaining more turns in the multi-turn conversation part.\n",
        "- Notice how stepwise reasoning improves clarity and accuracy."
      ],
      "metadata": {
        "id": "Oc0EbdU4Rb8d"
      }
    }
  ],
  "metadata": {
    "colab": {
      "name": "Welcome to Colab",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}