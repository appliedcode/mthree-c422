{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMd2d4gxa9rZdR13vye0epC",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/appliedcode/mthree-c422/blob/mthree-c422-Likhitha/Production_Ready_Practice_2_md.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SAv4OD26e_V8"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import classification_report\n",
        "import hashlib\n",
        "import datetime\n",
        "import json\n",
        "\n",
        "np.random.seed(77)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "n = 1500\n",
        "genders = [\"Male\", \"Female\", \"Other\"]\n",
        "cities = [\"Metro\", \"Urban\", \"Town\"]\n",
        "\n",
        "data = pd.DataFrame({\n",
        "    \"Driver_ID\": range(1, n+1),\n",
        "    \"Age\": np.random.randint(21, 65, n),\n",
        "    \"Gender\": np.random.choice(genders, n, p=[0.6, 0.35, 0.05]),\n",
        "    \"City_Type\": np.random.choice(cities, n, p=[0.4, 0.45, 0.15]),\n",
        "    \"Trips_Completed\": np.random.randint(50, 2000, n),\n",
        "    \"Avg_Rating\": np.round(np.random.uniform(3.0, 5.0, n), 2),\n",
        "    \"Complaints\": np.random.randint(0, 20, n),\n",
        "    \"Accidents\": np.random.randint(0, 5, n)\n",
        "})\n",
        "\n",
        "# Label generation (logic + small bias for Metro)\n",
        "data[\"Flagged_For_Review\"] = np.where(\n",
        "    (data[\"Complaints\"] > 5) | (data[\"Accidents\"] > 0),\n",
        "    np.random.choice([1, 0], n, p=[0.7, 0.3]),\n",
        "    np.random.choice([1, 0], n, p=[0.15, 0.85])\n",
        ")\n",
        "\n",
        "mask_metro = data[\"City_Type\"] == \"Metro\"\n",
        "# set different distribution only for metro rows (avoid broadcasting bug)\n",
        "data.loc[mask_metro, \"Flagged_For_Review\"] = np.random.choice([1, 0], mask_metro.sum(), p=[0.4, 0.6])\n",
        "\n",
        "print(\"Dataset created. Sample:\")\n",
        "print(data.head(), \"\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GIjQMjO1f6WX",
        "outputId": "62ff1f2e-c38c-4843-c2b8-5411a83fdd4c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset created. Sample:\n",
            "   Driver_ID  Age  Gender City_Type  Trips_Completed  Avg_Rating  Complaints  \\\n",
            "0          1   44   Other     Metro              324        3.88          12   \n",
            "1          2   52    Male     Urban              323        3.96          17   \n",
            "2          3   41  Female     Urban              448        3.53           4   \n",
            "3          4   41  Female      Town             1485        4.83          19   \n",
            "4          5   64    Male     Urban              501        3.66          15   \n",
            "\n",
            "   Accidents  Flagged_For_Review  \n",
            "0          3                   1  \n",
            "1          3                   0  \n",
            "2          4                   1  \n",
            "3          1                   0  \n",
            "4          2                   0   \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_df = data.copy()\n",
        "driver_ids = model_df[\"Driver_ID\"].copy()  # keep original ids\n",
        "y = model_df[\"Flagged_For_Review\"]\n",
        "\n",
        "X = model_df.drop(columns=[\"Driver_ID\", \"Flagged_For_Review\"])\n",
        "\n",
        "# One-hot encode categorical variables safely\n",
        "X = pd.get_dummies(X, columns=[\"Gender\", \"City_Type\"], drop_first=True)\n",
        "\n",
        "# Train/test split\n",
        "X_train, X_test, y_train, y_test, ids_train, ids_test = train_test_split(\n",
        "    X, y, driver_ids, test_size=0.30, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "print(f\"Train size: {X_train.shape}, Test size: {X_test.shape}\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ui36twd0gAlr",
        "outputId": "800633fc-0748-4145-ea21-bfe2eb0f0e2e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train size: (1050, 9), Test size: (450, 9)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "model.fit(X_train, y_train)  # will not error: X numeric only\n",
        "\n",
        "y_pred = model.predict(X_test)\n",
        "print(\"Baseline evaluation (classification report):\")\n",
        "print(classification_report(y_test, y_pred, zero_division=0))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3yZhMUvygFsY",
        "outputId": "cb0610a2-cce9-4bdb-f9d5-35e89124f0f7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Baseline evaluation (classification report):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.54      0.54      0.54       202\n",
            "           1       0.63      0.62      0.63       248\n",
            "\n",
            "    accuracy                           0.59       450\n",
            "   macro avg       0.58      0.58      0.58       450\n",
            "weighted avg       0.59      0.59      0.59       450\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# attach predictions and original sensitive attributes for analysis\n",
        "test_df = X_test.copy().reset_index(drop=True)\n",
        "test_df[\"y_true\"] = y_test.reset_index(drop=True)\n",
        "test_df[\"y_pred\"] = y_pred\n",
        "# retrieve Gender and City_Type from original data (we encoded drop_first=True)\n",
        "# We'll reconstruct human-readable groups using the original test ids mapping:\n",
        "orig_test_rows = data.loc[ids_test.index]  # careful: ids_test is a Series made by train_test_split\n",
        "# Better approach: make a df mapping index -> id before split\n",
        "# We'll instead join by index: create mapping index->sensitive features\n",
        "full = data.reset_index().loc[X_test.index, [\"Gender\", \"City_Type\"]].reset_index(drop=True)\n",
        "test_df[\"Gender\"] = full[\"Gender\"]\n",
        "test_df[\"City_Type\"] = full[\"City_Type\"]\n",
        "\n",
        "def positive_rate_by(group_col):\n",
        "    rates = test_df.groupby(group_col)[\"y_pred\"].mean()\n",
        "    return rates\n",
        "\n",
        "print(\"\\nPositive prediction rates by Gender:\")\n",
        "print(positive_rate_by(\"Gender\"))\n",
        "\n",
        "print(\"\\nPositive prediction rates by City_Type:\")\n",
        "print(positive_rate_by(\"City_Type\"))\n",
        "\n",
        "# Fairness disparity function\n",
        "def fairness_gate(df, sensitive_col, threshold=0.08):\n",
        "    rates = df.groupby(sensitive_col)[\"y_pred\"].mean()\n",
        "    disparity = rates.max() - rates.min()\n",
        "    return float(disparity), (disparity <= threshold)\n",
        "\n",
        "# Check for Gender & City_Type\n",
        "disp_gender, pass_gender = fairness_gate(test_df, \"Gender\", threshold=0.08)\n",
        "disp_city, pass_city = fairness_gate(test_df, \"City_Type\", threshold=0.08)\n",
        "print(f\"\\nGender disparity = {disp_gender:.3f} -> pass={pass_gender}\")\n",
        "print(f\"City_Type disparity = {disp_city:.3f} -> pass={pass_city}\")\n",
        "\n",
        "if not (pass_gender and pass_city):\n",
        "    print(\"\\n⚠️ Fairness gate failed for at least one sensitive attribute. Mitigation required before deployment.\\n\")\n",
        "else:\n",
        "    print(\"\\n✅ Fairness gate passed.\\n\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AOq2AqargMX1",
        "outputId": "5cacba4b-7b1d-452b-8682-57dad313c721"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Positive prediction rates by Gender:\n",
            "Gender\n",
            "Female    0.537931\n",
            "Male      0.551237\n",
            "Other     0.590909\n",
            "Name: y_pred, dtype: float64\n",
            "\n",
            "Positive prediction rates by City_Type:\n",
            "City_Type\n",
            "Metro    0.212435\n",
            "Town     0.771930\n",
            "Urban    0.810000\n",
            "Name: y_pred, dtype: float64\n",
            "\n",
            "Gender disparity = 0.053 -> pass=True\n",
            "City_Type disparity = 0.598 -> pass=False\n",
            "\n",
            "⚠️ Fairness gate failed for at least one sensitive attribute. Mitigation required before deployment.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "feat_imp = pd.Series(model.feature_importances_, index=X_train.columns).sort_values(ascending=False)\n",
        "print(\"Top 10 feature importances:\")\n",
        "print(feat_imp.head(10))\n",
        "\n",
        "# Flag socio-demographic features if they are high ranked\n",
        "sensitive_features = [c for c in X_train.columns if c.startswith(\"Gender_\") or c.startswith(\"City_Type_\")]\n",
        "top_k = feat_imp.head(10).index.tolist()\n",
        "flagged = [f for f in sensitive_features if f in top_k]\n",
        "if flagged:\n",
        "    print(\"\\n⚠️ Sensitive features appearing among top importances:\", flagged)\n",
        "    print(\"Suggested mitigations: drop or mask sensitive features, reweight samples, add fairness-aware training (e.g., re-sampling), or use post-processing adjustments.\")\n",
        "else:\n",
        "    print(\"\\nSensitive features not in top 10 importances (good).\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kA42nvNcgR31",
        "outputId": "91c0cb0a-8132-4e97-c3a3-ed7d2e2f1ada"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top 10 feature importances:\n",
            "Avg_Rating         0.221579\n",
            "Trips_Completed    0.218803\n",
            "Age                0.188983\n",
            "Complaints         0.158824\n",
            "Accidents          0.089914\n",
            "City_Type_Urban    0.050205\n",
            "Gender_Male        0.030451\n",
            "City_Type_Town     0.029744\n",
            "Gender_Other       0.011497\n",
            "dtype: float64\n",
            "\n",
            "⚠️ Sensitive features appearing among top importances: ['Gender_Male', 'Gender_Other', 'City_Type_Town', 'City_Type_Urban']\n",
            "Suggested mitigations: drop or mask sensitive features, reweight samples, add fairness-aware training (e.g., re-sampling), or use post-processing adjustments.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nEthics user stories:\")\n",
        "print(\"1) As a product manager, I want the model to avoid unfairly flagging drivers based on city type or gender, so flagged lists are equitable.\")\n",
        "print(\"2) As an ops engineer, I want prediction logs (including model version) to be stored securely so investigators can audit decisions.\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RHBc5uW2gVrr",
        "outputId": "4a69d47b-7435-4217-fdde-3e350a8eca4d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Ethics user stories:\n",
            "1) As a product manager, I want the model to avoid unfairly flagging drivers based on city type or gender, so flagged lists are equitable.\n",
            "2) As an ops engineer, I want prediction logs (including model version) to be stored securely so investigators can audit decisions.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prediction_log = []\n",
        "MODEL_VERSION = \"rf_v1.0\"\n",
        "\n",
        "def hash_id(x):\n",
        "    return hashlib.sha256(str(x).encode()).hexdigest()\n",
        "\n",
        "def predict_and_log_single(row_features: pd.Series, driver_id: int):\n",
        "    \"\"\"\n",
        "    row_features: pandas Series containing same columns as model X (without Driver_ID)\n",
        "    driver_id: original numeric ID (will be hashed before storing)\n",
        "    \"\"\"\n",
        "    # Ensure feature vector has same columns as training (in case of missing columns)\n",
        "    aligned = pd.DataFrame([row_features]).reindex(columns=X_train.columns, fill_value=0)\n",
        "    pred = int(model.predict(aligned)[0])\n",
        "    log_entry = {\n",
        "        \"timestamp\": datetime.datetime.utcnow().isoformat(),\n",
        "        \"model_version\": MODEL_VERSION,\n",
        "        \"driver_id_hash\": hash_id(driver_id),\n",
        "        \"input\": aligned.iloc[0].to_dict(),\n",
        "        \"prediction\": pred\n",
        "    }\n",
        "    prediction_log.append(log_entry)\n",
        "    return pred\n",
        "\n",
        "# Example: predict and log for first test row\n",
        "sample_idx = X_test.index[0]\n",
        "sample_driver_id = data.loc[sample_idx, \"Driver_ID\"]\n",
        "sample_features = X_test.loc[sample_idx]\n",
        "sample_pred = predict_and_log_single(sample_features, sample_driver_id)\n",
        "print(\"Logged one prediction. Sample log entry:\")\n",
        "print(json.dumps(prediction_log[-1], indent=2)[:800], \"\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3fw4r0bZgZ_Z",
        "outputId": "646ba6cc-2d41-462b-ce3a-2f8e4be748dc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logged one prediction. Sample log entry:\n",
            "{\n",
            "  \"timestamp\": \"2025-08-13T08:18:09.225868\",\n",
            "  \"model_version\": \"rf_v1.0\",\n",
            "  \"driver_id_hash\": \"480f5a496560ae4228bb7977ecf29b2c589d7a7aa6b609534566af8cbc229a9e\",\n",
            "  \"input\": {\n",
            "    \"Age\": 40,\n",
            "    \"Trips_Completed\": 304,\n",
            "    \"Avg_Rating\": 4.09,\n",
            "    \"Complaints\": 19,\n",
            "    \"Accidents\": 0,\n",
            "    \"Gender_Male\": true,\n",
            "    \"Gender_Other\": false,\n",
            "    \"City_Type_Town\": false,\n",
            "    \"City_Type_Urban\": false\n",
            "  },\n",
            "  \"prediction\": 1\n",
            "} \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def monitor_fairness(log_df_entries, threshold=0.08):\n",
        "    # We will compute positive rates by pulling predictions and mapping back to gender/city type via hashed id mapping.\n",
        "    # For this simulation we can use test_df (which has true mapping).\n",
        "    rates_gender = test_df.groupby(\"Gender\")[\"y_pred\"].mean()\n",
        "    rates_city = test_df.groupby(\"City_Type\")[\"y_pred\"].mean()\n",
        "    disp_g = rates_gender.max() - rates_gender.min()\n",
        "    disp_c = rates_city.max() - rates_city.min()\n",
        "    alerts = []\n",
        "    if disp_g > threshold:\n",
        "        alerts.append(f\"Gender disparity {disp_g:.3f} exceeds threshold {threshold}.\")\n",
        "    if disp_c > threshold:\n",
        "        alerts.append(f\"City_Type disparity {disp_c:.3f} exceeds threshold {threshold}.\")\n",
        "    return alerts, disp_g, disp_c\n",
        "\n",
        "alerts, d_g, d_c = monitor_fairness(prediction_log)\n",
        "if alerts:\n",
        "    print(\"Monitoring Alerts:\")\n",
        "    for a in alerts:\n",
        "        print(\" -\", a)\n",
        "else:\n",
        "    print(\"Monitoring: no alerts.\")\n",
        "\n",
        "print(f\"\\nCurrent (simulated) gender disparity: {d_g:.3f}\")\n",
        "print(f\"Current (simulated) city disparity: {d_c:.3f}\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MbedhsGTgh2i",
        "outputId": "3c0f9f7f-c6e5-4e42-fa55-70070968b0f2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Monitoring Alerts:\n",
            " - City_Type disparity 0.598 exceeds threshold 0.08.\n",
            "\n",
            "Current (simulated) gender disparity: 0.053\n",
            "Current (simulated) city disparity: 0.598\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Simulating feedback from underrepresented group 'Other' gender in Town city...\")\n",
        "\n",
        "# Create 10 synthetic feedback examples representing underrepresented drivers\n",
        "feedback_examples = pd.DataFrame({\n",
        "    \"Driver_ID\": range(n+1, n+11),\n",
        "    \"Age\": np.random.randint(21, 65, 10),\n",
        "    \"Gender\": [\"Other\"]*10,\n",
        "    \"City_Type\": [\"Town\"]*10,\n",
        "    \"Trips_Completed\": np.random.randint(50, 500, 10),\n",
        "    \"Avg_Rating\": np.round(np.random.uniform(3.0, 5.0, 10), 2),\n",
        "    \"Complaints\": np.random.randint(0, 5, 10),\n",
        "    \"Accidents\": np.random.randint(0, 2, 10),\n",
        "    \"Flagged_For_Review\": [0]*10  # assume feedback says they should not be flagged\n",
        "})\n",
        "\n",
        "# Append to original data and re-prepare features\n",
        "data_aug = pd.concat([data, feedback_examples], ignore_index=True)\n",
        "print(\"New dataset size (after feedback):\", data_aug.shape)\n",
        "\n",
        "# Re-prepare X, y with same encoding pipeline (get_dummies) and align columns with previous training\n",
        "X_aug = data_aug.drop(columns=[\"Driver_ID\", \"Flagged_For_Review\"])\n",
        "X_aug = pd.get_dummies(X_aug, columns=[\"Gender\", \"City_Type\"], drop_first=True)\n",
        "# Ensure same columns as original X_train\n",
        "X_aug = X_aug.reindex(columns=X_train.columns, fill_value=0)\n",
        "y_aug = data_aug[\"Flagged_For_Review\"]\n",
        "\n",
        "# Retrain on augmented data (quick retrain demonstration)\n",
        "model2 = RandomForestClassifier(n_estimators=100, random_state=0)\n",
        "model2.fit(X_aug, y_aug)\n",
        "print(\"Retrained model on augmented dataset. (Demonstration only)\\n\")"
      ],
      "metadata": {
        "id": "tgY4dEkvgmf5",
        "outputId": "0664fc32-3e53-4f0d-85f1-aeda1cf57dd1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Simulating feedback from underrepresented group 'Other' gender in Town city...\n",
            "New dataset size (after feedback): (1510, 9)\n",
            "Retrained model on augmented dataset. (Demonstration only)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "incident_plan = {\n",
        "    \"detection\": \"Automated monitoring flagged unusually high flag-rate for 'Town' drivers.\",\n",
        "    \"investigation\": \"Collect logs, run SHAP/LIME explanations for representative flagged drivers, review recent data changes and model version.\",\n",
        "    \"communication\": \"Notify stakeholders, publish transparency report with summary statistics, inform affected driver support team.\",\n",
        "    \"remediation\": \"Temporarily disable automated flagging for group, retrain model with inclusive examples, deploy corrected model, and monitor metrics.\"\n",
        "}\n",
        "print(\"Mock Incident Response Plan:\")\n",
        "print(json.dumps(incident_plan, indent=2))"
      ],
      "metadata": {
        "id": "XiRgyDCSgrL_",
        "outputId": "8fc33260-c682-4368-87f1-913282b3678e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mock Incident Response Plan:\n",
            "{\n",
            "  \"detection\": \"Automated monitoring flagged unusually high flag-rate for 'Town' drivers.\",\n",
            "  \"investigation\": \"Collect logs, run SHAP/LIME explanations for representative flagged drivers, review recent data changes and model version.\",\n",
            "  \"communication\": \"Notify stakeholders, publish transparency report with summary statistics, inform affected driver support team.\",\n",
            "  \"remediation\": \"Temporarily disable automated flagging for group, retrain model with inclusive examples, deploy corrected model, and monitor metrics.\"\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n--- Summary ---\")\n",
        "print(\"Model version:\", MODEL_VERSION)\n",
        "print(\"Number of logged predictions:\", len(prediction_log))\n",
        "print(\"Fairness checks: gender disparity=%.3f, city disparity=%.3f\" % (d_g, d_c))\n",
        "print(\"\\nYou can inspect 'prediction_log' list variable for stored log entries (with hashed driver IDs).\")"
      ],
      "metadata": {
        "id": "XIWL_l51gui2",
        "outputId": "ebb34b4a-cec7-456a-a3b3-d1cb3a53172a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Summary ---\n",
            "Model version: rf_v1.0\n",
            "Number of logged predictions: 1\n",
            "Fairness checks: gender disparity=0.053, city disparity=0.598\n",
            "\n",
            "You can inspect 'prediction_log' list variable for stored log entries (with hashed driver IDs).\n"
          ]
        }
      ]
    }
  ]
}