{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPwjWIIsefYhLk/3TnwFQW2",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/appliedcode/mthree-c422/blob/mthree-422-srilatha/Evaluation_metrics.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 106,
      "metadata": {
        "id": "Ol4GLlaA_2bw"
      },
      "outputs": [],
      "source": [
        "# Setup and Imports\n",
        "# Install scikit-learn if needed\n",
        "!pip install scikit-learn -q\n",
        "\n",
        "import numpy as np\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score, classification_report"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Simulate Classification Results\n",
        "# Let's create dummy data to simulate predictions from a binary classification model.\n",
        "# True labels\n",
        "y_true = np.array([0, 1, 1, 1, 0, 0, 1, 0, 1, 1])\n",
        "\n",
        "# Predicted labels by a model\n",
        "y_pred = np.array([0, 0, 1, 1, 0, 1, 1, 0, 1, 0])\n",
        "\n",
        "print(\"True labels:\", y_true)\n",
        "print(\"Predicted labels:\", y_pred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4SEAM2-zANrM",
        "outputId": "c3d7be43-c387-4a0f-bc2c-8dbaaa9c5186"
      },
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True labels: [0 1 1 1 0 0 1 0 1 1]\n",
            "Predicted labels: [0 0 1 1 0 1 1 0 1 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate Precision, Recall, and F1-score\n",
        "# Precision: Out of predicted positives, how many were correct?\n",
        "precision = precision_score(y_true, y_pred)\n",
        "\n",
        "# Recall: Out of actual positives, how many did we find?\n",
        "recall = recall_score(y_true, y_pred)\n",
        "\n",
        "# F1-score: Harmonic mean of precision and recall\n",
        "f1 = f1_score(y_true, y_pred)\n",
        "\n",
        "print(f\"Precision: {precision:.2f}\")\n",
        "print(f\"Recall:    {recall:.2f}\")\n",
        "print(f\"F1-score:  {f1:.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Di3mmfnAD2O5",
        "outputId": "22ff453c-f318-4c01-b4e9-bf1dc1c01e57"
      },
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Precision: 0.80\n",
            "Recall:    0.67\n",
            "F1-score:  0.73\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate a Full Classification Report\n",
        "# Provides metrics for both classes, along with support (number of samples for each class)\n",
        "print(classification_report(y_true, y_pred, target_names=[\"Class 0\", \"Class 1\"]))\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vVkcx5p-Ekp0",
        "outputId": "ba7a7200-4b15-4613-bd10-5477312d938e"
      },
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "     Class 0       0.60      0.75      0.67         4\n",
            "     Class 1       0.80      0.67      0.73         6\n",
            "\n",
            "    accuracy                           0.70        10\n",
            "   macro avg       0.70      0.71      0.70        10\n",
            "weighted avg       0.72      0.70      0.70        10\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#High Precision, Low Recall\n",
        "y_true = np.array([0, 1, 1, 1, 1, 1])\n",
        "y_pred = np.array([0, 1, 0, 0, 0, 0])\n",
        "\n",
        "print(\"True labels:\", y_true)\n",
        "print(\"Predicted labels:\", y_pred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nd9SjYQbCUSB",
        "outputId": "341d70b5-976c-4737-fbaf-12141f303fc1"
      },
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True labels: [0 1 1 1 1 1]\n",
            "Predicted labels: [0 1 0 0 0 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate Precision, Recall, and F1-score\n",
        "# Precision: Out of predicted positives, how many were correct?\n",
        "precision = precision_score(y_true, y_pred)\n",
        "\n",
        "# Recall: Out of actual positives, how many did we find?\n",
        "recall = recall_score(y_true, y_pred)\n",
        "\n",
        "# F1-score: Harmonic mean of precision and recall\n",
        "f1 = f1_score(y_true, y_pred)\n",
        "\n",
        "print(f\"Precision: {precision:.2f}\")\n",
        "print(f\"Recall:    {recall:.2f}\")\n",
        "print(f\"F1-score:  {f1:.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-QXDE051Dcqn",
        "outputId": "db7c98b6-3b64-45d9-ab74-4263003017a2"
      },
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Precision: 1.00\n",
            "Recall:    0.20\n",
            "F1-score:  0.33\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate a Full Classification Report\n",
        "# Provides metrics for both classes, along with support (number of samples for each class)\n",
        "print(classification_report(y_true, y_pred, target_names=[\"Class 0\", \"Class 1\"]))\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SJ8M2L5LEiNT",
        "outputId": "c71f4f49-433f-45ea-94de-debc06f0580a"
      },
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "     Class 0       0.20      1.00      0.33         1\n",
            "     Class 1       1.00      0.20      0.33         5\n",
            "\n",
            "    accuracy                           0.33         6\n",
            "   macro avg       0.60      0.60      0.33         6\n",
            "weighted avg       0.87      0.33      0.33         6\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Low Precision, High Recall\n",
        "y_true = np.array([0, 0, 0, 1, 1, 1])\n",
        "y_pred = np.array([1, 1, 1, 1, 1, 1])"
      ],
      "metadata": {
        "id": "GnkMrhT5C9vd"
      },
      "execution_count": 113,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate Precision, Recall, and F1-score\n",
        "# Precision: Out of predicted positives, how many were correct?\n",
        "precision = precision_score(y_true, y_pred)\n",
        "\n",
        "# Recall: Out of actual positives, how many did we find?\n",
        "recall = recall_score(y_true, y_pred)\n",
        "\n",
        "# F1-score: Harmonic mean of precision and recall\n",
        "f1 = f1_score(y_true, y_pred)\n",
        "\n",
        "print(f\"Precision: {precision:.2f}\")\n",
        "print(f\"Recall:    {recall:.2f}\")\n",
        "print(f\"F1-score:  {f1:.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5r9h1MZDDbSy",
        "outputId": "c2d853b2-6e8a-4463-add4-aae1d06e9205"
      },
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Precision: 0.50\n",
            "Recall:    1.00\n",
            "F1-score:  0.67\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate a Full Classification Report\n",
        "# Provides metrics for both classes, along with support (number of samples for each class)\n",
        "print(classification_report(y_true, y_pred, target_names=[\"Class 0\", \"Class 1\"], zero_division=0))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5rZcfmYuEgoI",
        "outputId": "b5778559-8788-4d5c-e4ef-cbf2b9d69365"
      },
      "execution_count": 115,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "     Class 0       0.00      0.00      0.00         3\n",
            "     Class 1       0.50      1.00      0.67         3\n",
            "\n",
            "    accuracy                           0.50         6\n",
            "   macro avg       0.25      0.50      0.33         6\n",
            "weighted avg       0.25      0.50      0.33         6\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Perfect Precision and Recall\n",
        "\n",
        "y_true = np.array([0, 1, 0, 1])\n",
        "y_pred = np.array([0, 1, 0, 1])"
      ],
      "metadata": {
        "id": "G4sBAneTDOTK"
      },
      "execution_count": 116,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate Precision, Recall, and F1-score\n",
        "# Precision: Out of predicted positives, how many were correct?\n",
        "precision = precision_score(y_true, y_pred)\n",
        "\n",
        "# Recall: Out of actual positives, how many did we find?\n",
        "recall = recall_score(y_true, y_pred)\n",
        "\n",
        "# F1-score: Harmonic mean of precision and recall\n",
        "f1 = f1_score(y_true, y_pred)\n",
        "\n",
        "print(f\"Precision: {precision:.2f}\")\n",
        "print(f\"Recall:    {recall:.2f}\")\n",
        "print(f\"F1-score:  {f1:.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WjJ5aVShAXqb",
        "outputId": "3ee454dd-7f44-42a2-9412-224568d13674"
      },
      "execution_count": 117,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Precision: 1.00\n",
            "Recall:    1.00\n",
            "F1-score:  1.00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate a Full Classification Report\n",
        "# Provides metrics for both classes, along with support (number of samples for each class)\n",
        "print(classification_report(y_true, y_pred, target_names=[\"Class 0\", \"Class 1\"]))\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A93FTR7PAhgj",
        "outputId": "73e85776-2df4-4e8f-9fe5-e13ae8169591"
      },
      "execution_count": 118,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "     Class 0       1.00      1.00      1.00         2\n",
            "     Class 1       1.00      1.00      1.00         2\n",
            "\n",
            "    accuracy                           1.00         4\n",
            "   macro avg       1.00      1.00      1.00         4\n",
            "weighted avg       1.00      1.00      1.00         4\n",
            "\n"
          ]
        }
      ]
    }
  ]
}