{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/diptidhande/AI-ML/blob/main/Exercises/day-5/Evaluation_metrics.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Machine Learning Evaluation Metrics\n",
        "In this lab, you'll learn how to compute and interpret precision, recall, and F1-score using Python and scikit-learn. These metrics are crucial for evaluating classification models, especially in imbalanced datasets."
      ],
      "metadata": {
        "id": "u0hcu68CrwW7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Setup and Imports\n",
        "# Install scikit-learn if needed\n",
        "!pip install scikit-learn -q\n",
        "\n",
        "import numpy as np\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score, classification_report\n"
      ],
      "metadata": {
        "id": "fyisAqxurvXQ"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Simulate Classification Results\n",
        "# Let's create dummy data to simulate predictions from a binary classification model.\n",
        "# True labels\n",
        "y_true = np.array([0, 1, 1, 1, 0, 0, 1, 0, 1, 1])\n",
        "\n",
        "# Predicted labels by a model\n",
        "y_pred = np.array([0, 0, 1, 1, 0, 1, 1, 0, 1, 0])\n",
        "\n",
        "print(\"True labels:\", y_true)\n",
        "print(\"Predicted labels:\", y_pred)"
      ],
      "metadata": {
        "id": "UpZgAb8Kr23L",
        "outputId": "7405f44d-6488-4fcb-e33f-096208565181",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True labels: [0 1 1 1 0 0 1 0 1 1]\n",
            "Predicted labels: [0 0 1 1 0 1 1 0 1 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate Precision, Recall, and F1-score\n",
        "# Precision: Out of predicted positives, how many were correct?\n",
        "precision = precision_score(y_true, y_pred)\n",
        "\n",
        "# Recall: Out of actual positives, how many did we find?\n",
        "recall = recall_score(y_true, y_pred)\n",
        "\n",
        "# F1-score: Harmonic mean of precision and recall\n",
        "f1 = f1_score(y_true, y_pred)\n",
        "\n",
        "print(f\"Precision: {precision:.2f}\")\n",
        "print(f\"Recall:    {recall:.2f}\")\n",
        "print(f\"F1-score:  {f1:.2f}\")\n"
      ],
      "metadata": {
        "id": "JBd4C-ePr_Lg",
        "outputId": "1837bd84-4c80-4be1-b774-49bae5a564a6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Precision: 0.80\n",
            "Recall:    0.67\n",
            "F1-score:  0.73\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate a Full Classification Report\n",
        "# Provides metrics for both classes, along with support (number of samples for each class)\n",
        "print(classification_report(y_true, y_pred, target_names=[\"Class 0\", \"Class 1\"]))"
      ],
      "metadata": {
        "id": "3sn24KHMsJNe",
        "outputId": "da5fc3d5-0749-4dd2-ec62-91056bb2d67c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "     Class 0       0.60      0.75      0.67         4\n",
            "     Class 1       0.80      0.67      0.73         6\n",
            "\n",
            "    accuracy                           0.70        10\n",
            "   macro avg       0.70      0.71      0.70        10\n",
            "weighted avg       0.72      0.70      0.70        10\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Practice Tasks\n",
        "- Modify y_true and y_pred to try different scenarios.\n",
        "\n",
        "- Explain the difference between high precision and high recall in your own words."
      ],
      "metadata": {
        "id": "GLvoI2NcsPRT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Short Summary\n",
        "- **Precision**: Of what we predicted as positive, what percentage was correct.\n",
        "\n",
        "- **Recall**: Of all actual positives, what percentage did we find.\n",
        "\n",
        "- **F1-score**: Balance between precision and recall."
      ],
      "metadata": {
        "id": "xzap36NosZb_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_true = np.array([0, 1, 1, 1, 1, 1])     # 5 positives\n",
        "y_pred = np.array([0, 1, 0, 0, 0, 0])     # Only 1 predicted positive, which is correct\n",
        "\n",
        "precision = precision_score(y_true, y_pred)  # 1.0\n",
        "recall = recall_score(y_true, y_pred)        # 0.20\n"
      ],
      "metadata": {
        "id": "g3KvuEm_o_Wu"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_true = np.array([0, 1, 1, 1, 0, 0])\n",
        "y_pred = np.array([1, 1, 1, 1, 1, 1])     # Predicts all as positive\n",
        "\n",
        "precision = precision_score(y_true, y_pred)  # 0.50\n",
        "recall = recall_score(y_true, y_pred)        # 1.00\n"
      ],
      "metadata": {
        "id": "00ts50HFpAbl"
      },
      "execution_count": 6,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "Welcome to Colab",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}