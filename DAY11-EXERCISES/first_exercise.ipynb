{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WlrZVOqw_49s",
        "outputId": "36ddf301-7600-4527-ec45-34007c279952"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ OpenAI API key loaded safely\n"
          ]
        }
      ],
      "source": [
        "from google.colab import userdata\n",
        "import os\n",
        "\n",
        "# Set your OpenAI API key securely in Colab Secrets (once)\n",
        "# userdata.set(\"OPENAI_API_KEY\", \"your-api-key-here\")\n",
        "\n",
        "# Retrieve key in your notebook\n",
        "openai_api_key = userdata.get(\"OPENAI_API_KEY\")\n",
        "if openai_api_key:\n",
        "    os.environ[\"OPENAI_API_KEY\"] = openai_api_key\n",
        "    print(\"‚úÖ OpenAI API key loaded safely\")\n",
        "else:\n",
        "    print(\"‚ùå OpenAI API key not found. Please set it using Colab Secrets.\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --quiet openai -q"
      ],
      "metadata": {
        "id": "sYlhihVHCDsr"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create client\n",
        "from openai import OpenAI\n",
        "client = OpenAI(api_key=os.environ[\"OPENAI_API_KEY\"])"
      ],
      "metadata": {
        "id": "qcu6PP2vCQIG"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "prompt = \"Explain what prompt engineering is in one paragraph.\"\n",
        "\n",
        "response = client.chat.completions.create(\n",
        "    model=\"gpt-4o-mini\",  # Free-tier friendly\n",
        "    messages=[\n",
        "        {\"role\": \"system\", \"content\": \"You are a helpful teacher.\"},\n",
        "        {\"role\": \"user\", \"content\": prompt}\n",
        "    ],\n",
        "    max_tokens=100\n",
        ")\n",
        "\n",
        "print(\"\\nüí¨ Model Output:\\n\")\n",
        "print(response.choices[0].message.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KdAUnoJ2CSX9",
        "outputId": "41d972bc-cbe6-4024-c844-bb4a33f18230"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üí¨ Model Output:\n",
            "\n",
            "Prompt engineering is the practice of designing and refining input prompts to effectively communicate with artificial intelligence models, particularly language models, in order to achieve desired outputs. This involves crafting specific, clear, and contextually rich prompts that guide the AI in generating relevant and high-quality responses. By understanding how the model interprets language and the nuances of its training data, practitioners can optimize prompts to reduce ambiguity, focus on particular themes or formats, and elicit more accurate and useful information from the AI. This discipline is\n"
          ]
        }
      ]
    }
  ]
}