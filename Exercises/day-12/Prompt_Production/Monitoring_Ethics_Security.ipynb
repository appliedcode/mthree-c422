{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/appliedcode/mthree-c422/blob/main/Exercises/day-12/Prompt_Production/Monitoring_Ethics_Security.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Lab Exercises: Monitoring, Ethics, and Security in Prompt Engineering\n",
        "\n",
        "***\n",
        "\n",
        "### Setup:\n",
        "\n",
        "- Use OpenAI API or any language model API accessible in your Colab.\n",
        "- If API keys are needed, ensure they are safely added as environment variables or input by the user."
      ],
      "metadata": {
        "id": "eq4qKCdSNSko"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "import os\n",
        "\n",
        "# Set your OpenAI API key securely in Colab Secrets (once)\n",
        "# userdata.set(\"OPENAI_API_KEY\", \"your-api-key-here\")\n",
        "\n",
        "# Retrieve key in your notebook\n",
        "openai_api_key = userdata.get(\"OPENAI_API_KEY\")\n",
        "if openai_api_key:\n",
        "    os.environ[\"OPENAI_API_KEY\"] = openai_api_key\n",
        "    print(\"✅ OpenAI API key loaded safely\")\n",
        "else:\n",
        "    print(\"❌ OpenAI API key not found. Please set it using Colab Secrets.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2YMRqyRCNGmo",
        "outputId": "ff0d7246-fab6-4966-9510-e01bd254173e"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ OpenAI API key loaded safely\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "!pip install --quiet openai -q\n",
        "# Create client\n",
        "from openai import OpenAI\n",
        "client = OpenAI(api_key=os.environ[\"OPENAI_API_KEY\"])"
      ],
      "metadata": {
        "id": "9qrFrzlcPI1n"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Helper Function to Send Prompts\n",
        "def generate_response(prompt, model=\"gpt-4o-mini\", temperature=0.7):\n",
        "    \"\"\"\n",
        "    Send a prompt to the OpenAI model and return the response text.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        completion = client.chat.completions.create(\n",
        "            model=model,\n",
        "            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "            temperature=temperature\n",
        "        )\n",
        "        return completion.choices[0].message.content.strip()\n",
        "    except Exception as e:\n",
        "        return f\"Error: {e}\"\n"
      ],
      "metadata": {
        "id": "AieFziFDTcuy"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "***\n",
        "\n",
        "## Exercise 1: Monitoring and Logging Prompt Usage\n",
        "\n",
        "**Goal:** Understand how to track prompt usage, log inputs and outputs, and monitor anomalies or trends.\n",
        "\n",
        "**Task:**\n",
        "\n",
        "1. Simulate logging prompts and responses in a Python list or dictionary.\n",
        "2. Implement a simple function to add prompt-response pairs with timestamps to a log.\n",
        "3. Print sample logs formatted clearly.\n",
        "4. (Optional) Add a check to detect repeated or anomalous prompts (e.g., same prompt repeated more than 3 times)."
      ],
      "metadata": {
        "id": "0XAQN4c4dID3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import datetime\n",
        "\n",
        "# Initialize log storage\n",
        "prompt_log = []\n",
        "\n",
        "def log_prompt_response(prompt, response):\n",
        "    timestamp = datetime.datetime.now().isoformat()\n",
        "    entry = {\n",
        "        \"timestamp\": timestamp,\n",
        "        \"prompt\": prompt,\n",
        "        \"response_excerpt\": response[:100]  # Save first 100 chars only\n",
        "    }\n",
        "    prompt_log.append(entry)\n",
        "\n",
        "def print_log():\n",
        "    for e in prompt_log:\n",
        "        print(f\"[{e['timestamp']}] Prompt: {e['prompt']}\")\n",
        "        print(f\"Response (excerpt): {e['response_excerpt']}\\n\")\n",
        "\n",
        "# Example usage\n",
        "sample_prompts = [\n",
        "    \"Explain the greenhouse effect.\",\n",
        "    \"List 3 benefits of renewable energy.\",\n",
        "    \"Explain the greenhouse effect.\"\n",
        "]\n",
        "\n",
        "for p in sample_prompts:\n",
        "    r = generate_response(p)\n",
        "    log_prompt_response(p, r)\n",
        "\n",
        "print_log()"
      ],
      "metadata": {
        "id": "shzDX21jdI5J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "***\n",
        "\n",
        "## Exercise 2: Ethical Considerations in Prompt Design\n",
        "\n",
        "**Goal:** Identify ethical risks like bias or harm in prompt design and incorporate fairness and transparency.\n",
        "\n",
        "**Task:**\n",
        "\n",
        "1. Write a biased prompt, e.g., `\"Why are some groups less skilled at math?\"`.\n",
        "2. Generate the response.\n",
        "3. Rewrite the prompt to a fair, neutral version instructing the AI to avoid stereotypes and provide an inclusive answer.\n",
        "4. Generate the refined response."
      ],
      "metadata": {
        "id": "BY6WMB3XdLNN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Biased prompt\n",
        "biased_prompt = \"Why are some groups less skilled at math?\"\n",
        "\n",
        "print(\"Biased Prompt Output:\")\n",
        "print(generate_response(biased_prompt), \"\\n\")\n",
        "\n",
        "# Ethical refined prompt\n",
        "ethical_prompt = \"\"\"\n",
        "Discuss factors that influence mathematical skills across all groups,\n",
        "emphasizing equal potential and avoiding stereotypes or biases.\n",
        "\"\"\"\n",
        "\n",
        "print(\"Ethical Prompt Output:\")\n",
        "print(generate_response(ethical_prompt))"
      ],
      "metadata": {
        "id": "GvMqfb3wdOPd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "***\n",
        "\n",
        "## Exercise 3: Security and Privacy in Prompt-Based Systems\n",
        "\n",
        "**Goal:** Practice designing prompts that respect user privacy and prevent exposure of sensitive data.\n",
        "\n",
        "**Task:**\n",
        "\n",
        "1. Write a prompt asking for personal information about a public figure (e.g., `\"Provide the home address of Elon Musk.\"`).\n",
        "2. Generate the output and observe.\n",
        "3. Rewrite the prompt to request only publicly available information without private details and instruct the model not to reveal personal data or sensitive info.\n",
        "4. Generate the safer response."
      ],
      "metadata": {
        "id": "lfNCSvscdQfN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "unsafe_prompt = \"Provide the home address of Elon Musk.\"\n",
        "print(\"Unsafe Prompt Output:\")\n",
        "print(generate_response(unsafe_prompt), \"\\n\")\n",
        "\n",
        "safe_prompt = \"\"\"\n",
        "Provide a brief biography of Elon Musk focusing only on his public achievements, companies founded, and technological contributions.\n",
        "Do not include any personal, contact, or location information.\n",
        "\"\"\"\n",
        "print(\"Safe Prompt Output:\")\n",
        "print(generate_response(safe_prompt))"
      ],
      "metadata": {
        "id": "90FVyYDWdSJe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "***\n",
        "\n",
        "### Summary for Students\n",
        "\n",
        "- **Monitoring and logging** prompt and response data helps maintain transparency, detect issues, and improve systems.\n",
        "- In **ethical prompt design**, you must actively reduce bias, promote fairness and inclusivity, and be transparent about AI limitations.\n",
        "- For **security and privacy**, design prompts that avoid eliciting or revealing sensitive personal data, and embed clear instructions for responsible AI use.\n",
        "\n",
        "***"
      ],
      "metadata": {
        "id": "5feTOmhOdUUE"
      }
    }
  ],
  "metadata": {
    "colab": {
      "name": "Welcome to Colab",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}