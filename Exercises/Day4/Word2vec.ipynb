{"cells":[{"cell_type":"markdown","metadata":{"id":"view-in-github"},"source":["<a href=\"https://colab.research.google.com/github/appliedcode/mthree-c422/blob/main/Exercises/day-4/Conversion_techniques/Word2vec.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"]},{"cell_type":"markdown","source":["# ðŸ§  Word2Vec Exercise\n","\n","## ðŸŽ¯ Objective\n","- Train a **Word2Vec** model on a small text corpus.\n","- Convert words into **dense vector representations** (embeddings).\n","- Explore **semantically similar words** and basic **word relationships**.\n","\n","---\n","\n","## ðŸ“š Dataset\n","\n","Use the following **6 sentences** as your training corpus:\n","\n","1. *I enjoy walking in the park.*\n","2. *Walking and running are good exercises.*\n","3. *I love jogging around the neighborhood.*\n","4. *Exercise keeps me healthy and energetic.*\n","5. *Morning walks help clear my mind.*\n","6. *The park is full of beautiful trees.*\n","\n","## ðŸ§© Tasks\n","\n","### ðŸ”„ Preprocessing\n","- Convert all sentences to **lowercase**.\n","- **Tokenize** each sentence into individual words.\n","- **Remove punctuation** from the tokens.\n","\n","---\n","\n","### ðŸ› ï¸ Train Word2Vec Model\n","- Use the **skip-gram** architecture (`sg=1`).\n","- Set:\n","  - `vector_size = 50`\n","  - `window = 3`\n","  - `epochs = 100`\n","- Input the **preprocessed tokenized sentences** into the model for training.\n","\n","---\n","\n","### ðŸ” Explore Embeddings\n","\n","- **Extract and display** the vector embedding corresponding to the word `\"walking\"` from the trained Word2Vec model.\n","\n","- **Identify and print** the top five words most similar to `\"walking\"`, ranked by cosine similarity.\n","\n","- **Calculate and report** the cosine similarity score between the words `\"walking\"` and `\"running\"`.\n","\n","- **Solve a word analogy** using vector arithmetic:  \n","  Determine the word that is most similar to the result of `\"running\"` + `\"morning\"` âˆ’ `\"walking\"`."],"metadata":{"id":"bOx5MkTlY-ec"}},{"cell_type":"code","source":["import nltk\n","# Download both old and new tokenizer data\n","nltk.download('punkt')\n","nltk.download('punkt_tab')\n","nltk.download('stopwords')"],"metadata":{"id":"fCRYJGvtY995","outputId":"55166f29-6769-4e72-d1b8-c6dd11dd4ffb","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1753973363098,"user_tz":-330,"elapsed":2619,"user":{"displayName":"Rania","userId":"13750069140470329881"}}},"execution_count":1,"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n","[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n","[nltk_data]   Package punkt_tab is already up-to-date!\n","[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Package stopwords is already up-to-date!\n"]},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":1}]},{"cell_type":"code","source":["# Step 1: Downgrade numpy to a compatible version (most stable with gensim)\n","!pip install numpy==1.24.3 --force-reinstall --no-cache-dir\n","\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":602},"id":"vww_CwPF8_A8","executionInfo":{"status":"ok","timestamp":1753973307393,"user_tz":-330,"elapsed":10417,"user":{"displayName":"Rania","userId":"13750069140470329881"}},"outputId":"03e4432f-89ee-4752-f26a-566feac60df6"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting numpy==1.24.3\n","  Downloading numpy-1.24.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.6 kB)\n","Downloading numpy-1.24.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.3 MB)\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m17.3/17.3 MB\u001b[0m \u001b[31m211.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: numpy\n","  Attempting uninstall: numpy\n","    Found existing installation: numpy 1.26.4\n","    Uninstalling numpy-1.26.4:\n","      Successfully uninstalled numpy-1.26.4\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","jaxlib 0.5.1 requires numpy>=1.25, but you have numpy 1.24.3 which is incompatible.\n","arviz 0.22.0 requires numpy>=1.26.0, but you have numpy 1.24.3 which is incompatible.\n","jax 0.5.2 requires numpy>=1.25, but you have numpy 1.24.3 which is incompatible.\n","opencv-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.24.3 which is incompatible.\n","pymc 5.25.1 requires numpy>=1.25.0, but you have numpy 1.24.3 which is incompatible.\n","opencv-python-headless 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.24.3 which is incompatible.\n","opencv-contrib-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.24.3 which is incompatible.\n","tensorflow 2.18.0 requires numpy<2.1.0,>=1.26.0, but you have numpy 1.24.3 which is incompatible.\n","treescope 0.1.9 requires numpy>=1.25.2, but you have numpy 1.24.3 which is incompatible.\n","tsfresh 0.21.0 requires scipy>=1.14.0; python_version >= \"3.10\", but you have scipy 1.13.1 which is incompatible.\n","thinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.24.3 which is incompatible.\n","xarray 2025.7.1 requires numpy>=1.26, but you have numpy 1.24.3 which is incompatible.\n","xarray-einstats 0.9.1 requires numpy>=1.25, but you have numpy 1.24.3 which is incompatible.\n","albucore 0.0.24 requires numpy>=1.24.4, but you have numpy 1.24.3 which is incompatible.\n","blosc2 3.6.1 requires numpy>=1.26, but you have numpy 1.24.3 which is incompatible.\n","albumentations 2.0.8 requires numpy>=1.24.4, but you have numpy 1.24.3 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed numpy-1.24.3\n"]},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["numpy"]},"id":"8f8a5e4577a34d0fa9112be32a442b18"}},"metadata":{}}]},{"cell_type":"code","source":["# Step 2: Restart the runtime (important!)\n","# In Colab: Runtime â†’ Restart Runtime\n","\n","# Step 3: Reinstall gensim and nltk after restarting, just to be sure\n","!pip install gensim nltk -q"],"metadata":{"id":"wAdO2kmJ9IGo","executionInfo":{"status":"ok","timestamp":1753973377433,"user_tz":-330,"elapsed":8327,"user":{"displayName":"Rania","userId":"13750069140470329881"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["# Install required packages if you have not already\n","!pip install gensim nltk -q\n","\n","import nltk\n","from nltk.tokenize import word_tokenize\n","from gensim.models import Word2Vec\n","import string\n","\n","# Download punkt tokenizer once\n","nltk.download('punkt')\n","\n","# Step 1: Corpus and Preprocessing\n","sentences = [\n","    \"I enjoy walking in the park.\",\n","    \"Walking and running are good exercises.\",\n","    \"I love jogging around the neighborhood.\",\n","    \"Exercise keeps me healthy and energetic.\",\n","    \"Morning walks help clear my mind.\",\n","    \"The park is full of beautiful trees.\"\n","]\n","\n","def preprocess(sent):\n","    # Lowercase\n","    sent = sent.lower()\n","    # Remove punctuation\n","    sent = sent.translate(str.maketrans('', '', string.punctuation))\n","    # Tokenize\n","    tokens = word_tokenize(sent)\n","    return tokens\n","\n","tokenized_sentences = [preprocess(s) for s in sentences]\n","\n","# Step 2: Train Word2Vec Model\n","model = Word2Vec(\n","    sentences=tokenized_sentences,\n","    vector_size=50,\n","    window=3,\n","    min_count=1,  # consider all words\n","    sg=1,         # skip-gram\n","    epochs=100\n",")\n","\n","# Step 3: Vector for 'walking'\n","print(\"Vector for 'walking' (first 10 dimensions):\")\n","print(model.wv['walking'][:10])\n","\n","# Step 4: Top 5 most similar words to 'walking'\n","print(\"\\nTop 5 words similar to 'walking':\")\n","for word, score in model.wv.most_similar('walking', topn=5):\n","    print(f\"{word}: {score:.4f}\")\n","\n","# Step 5: Similarity between 'walking' and 'running'\n","similarity = model.wv.similarity('walking', 'running')\n","print(f\"\\nSimilarity between 'walking' and 'running': {similarity:.4f}\")\n","\n","# Step 6: Analogy: running + morning - walking\n","print(\"\\nWords most similar to the analogy 'running' + 'morning' - 'walking':\")\n","for word, score in model.wv.most_similar(positive=['running', 'morning'], negative=['walking'], topn=3):\n","    print(f\"{word}: {score:.4f}\")\n"],"metadata":{"id":"0bsGrAzv3BD7","outputId":"55e963cf-daae-4f88-b5de-0769a0821d9c","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1753973394874,"user_tz":-330,"elapsed":8626,"user":{"displayName":"Rania","userId":"13750069140470329881"}}},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Vector for 'walking' (first 10 dimensions):\n","[-0.01759433  0.00767909  0.01061761  0.0114562   0.0146957  -0.0129286\n","  0.00259938  0.0126877  -0.00618321 -0.01260977]\n","\n","Top 5 words similar to 'walking':\n","me: 0.2180\n","and: 0.1931\n","exercises: 0.1745\n","help: 0.1718\n","the: 0.1668\n","\n","Similarity between 'walking' and 'running': 0.1529\n","\n","Words most similar to the analogy 'running' + 'morning' - 'walking':\n","in: 0.1845\n","mind: 0.1780\n","clear: 0.1610\n"]},{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"YvNnRER87lfJ"},"execution_count":null,"outputs":[]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"}},"nbformat":4,"nbformat_minor":0}