{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Lab Exercise: Introduction to Prompt Engineering and Large Language Models (LLMs)\n",
        "\n",
        "## Objectives\n",
        "\n",
        "- Understand *what prompt engineering is* and its importance in AI\n",
        "- Learn about *Large Language Models (LLMs)* and their key capabilities\n",
        "- Explore prompt engineering as a *new programming paradigm*\n",
        "- Survey *major LLM types* from OpenAI, Anthropic, and Google\n",
        "- Discuss *real-world applications* of prompt engineering\n",
        "- Gain practical experience crafting and testing prompts with OpenAI's GPT models in Colab\n",
        "\n",
        "***\n",
        "\n",
        "## 1. What is Prompt Engineering and Why It Matters\n",
        "\n",
        "Read this definition:\n",
        "*Prompt Engineering* is the practice of designing and refining the instructions or inputs (\"prompts\") given to Large Language Models (LLMs) to elicit desired and accurate outputs. Unlike traditional programming, here you \"program\" by language interaction.\n",
        "\n",
        "**Why it matters:**\n",
        "\n",
        "- Maximizes LLM output quality without retraining\n",
        "- Enables custom task control via instructions, examples, personas\n",
        "- Reduces hallucinations and irrelevant output\n",
        "- Vital for practical AI deployments\n",
        "\n",
        "***\n",
        "\n",
        "## 2. Overview of Large Language Models (LLMs)\n",
        "\n",
        "- LLMs are pretrained AI models with billions+ parameters trained on massive text corpora.\n",
        "- They understand and can generate human-like text in multiple formats and languages.\n",
        "- Examples:\n",
        "    - **OpenAI:** GPT-3, GPT-4, ChatGPT\n",
        "    - **Anthropic:** Claude family\n",
        "    - **Google:** PaLM, Gemini\n",
        "\n",
        "*Capabilities:* text generation, summarization, translation, question answering, code writing, conversational AI.\n",
        "\n",
        "***\n",
        "\n",
        "## 3. Prompt Engineering as a New Programming Paradigm\n",
        "\n",
        "- Move from traditional code and logic to instructing LLMs with natural language prompts\n",
        "- Incorporates clear instructions, few-shot examples, role assignments (personas)\n",
        "- Iteratively refine prompt design based on responses\n",
        "- Allows rapid prototyping across diverse tasks\n",
        "\n",
        "***\n",
        "\n",
        "## 4. Types of Popular LLMs\n",
        "\n",
        "| Provider | Model Examples | Special Features |\n",
        "| :-- | :-- | :-- |\n",
        "| OpenAI | GPT-3, GPT-4, ChatGPT | Large-scale APIs, conversational AI |\n",
        "| Anthropic | Claude | Safety-focused, steerable chatbots |\n",
        "| Google (DeepMind) | PaLM, Gemini | Multi-modal, grounded reasoning |\n",
        "\n",
        "Good to know: Different models have different token limits, pricing, and availability.\n",
        "\n",
        "***\n",
        "\n",
        "## 5. Real-World Applications of Prompt Engineering\n",
        "\n",
        "- Customer support chatbots\n",
        "- Content creation (blogs, ads, scripts)\n",
        "- Code generation and debugging\n",
        "- Legal and medical document analysis\n",
        "- Personalized tutoring and coaching\n",
        "- Data extraction and summarization\n",
        "\n",
        "***\n"
      ],
      "metadata": {
        "id": "hFnkDgKDTUgk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "import os\n",
        "\n",
        "# Set your OpenAI API key securely in Colab Secrets (once)\n",
        "# userdata.set(\"OPENAI_API_KEY\", \"your-api-key-here\")\n",
        "\n",
        "# Retrieve key in your notebook\n",
        "openai_api_key = userdata.get(\"OPENAI_API_KEY\")\n",
        "if openai_api_key:\n",
        "    os.environ[\"OPENAI_API_KEY\"] = openai_api_key\n",
        "    print(\"‚úÖ OpenAI API key loaded safely\")\n",
        "else:\n",
        "    print(\"‚ùå OpenAI API key not found. Please set it using Colab Secrets.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b-MrRDkKZxI6",
        "outputId": "e2795299-fe1b-48a0-d380-42a8f266ba96"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ OpenAI API key loaded safely\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --quiet openai -q"
      ],
      "metadata": {
        "id": "eyeKWLK4bM2Q"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create client\n",
        "from openai import OpenAI\n",
        "client = OpenAI(api_key=os.environ[\"OPENAI_API_KEY\"])"
      ],
      "metadata": {
        "id": "lNqOYjPrbNo7"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"Explain what prompt engineering is in one paragraph.\"\n",
        "\n",
        "response = client.chat.completions.create(\n",
        "    model=\"gpt-4o-mini\",  # Free-tier friendly\n",
        "    messages=[\n",
        "        {\"role\": \"system\", \"content\": \"You are a helpful teacher.\"},\n",
        "        {\"role\": \"user\", \"content\": prompt}\n",
        "    ],\n",
        "    max_tokens=100\n",
        ")\n",
        "\n",
        "print(\"\\nüí¨ Model Output:\\n\")\n",
        "print(response.choices[0].message.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8U4WXgvtbWV-",
        "outputId": "c5d7aa87-50c8-40e9-cc59-4d876eb1dfb6"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üí¨ Model Output:\n",
            "\n",
            "Prompt engineering is the process of designing and optimizing input prompts given to artificial intelligence models, particularly language models, to elicit desired responses or behaviors. It involves crafting specific phrases, questions, or instructions that guide the model in producing relevant and accurate outputs. By experimenting with different forms of prompts, users can improve the effectiveness of the model in generating coherent text, answering queries, or completing tasks, thereby enhancing its overall usability and performance in various applications. This skill is increasingly important as AI becomes more integrated into\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}