{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "580d9902",
   "metadata": {},
   "source": [
    "# Session 7: Sentiment Analysis Deep Dive\n",
    "\n",
    "## üìö Learning Objectives\n",
    "- Understand rule-based and ML-based sentiment analysis\n",
    "- Apply VADER and machine learning models for sentiment\n",
    "- Handle negation and context in sentiment analysis\n",
    "- Visualize sentiment distribution and results\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3357d42",
   "metadata": {},
   "source": [
    "## üõ†Ô∏è Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "289979b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Download NLTK data\n",
    "nltk.download('vader_lexicon', quiet=True)\n",
    "nltk.download('punkt', quiet=True)\n",
    "nltk.download('stopwords', quiet=True)\n",
    "\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "print('‚úÖ Libraries imported and NLTK data downloaded!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e74bd62",
   "metadata": {},
   "source": [
    "## üìä Data Preparation\n",
    "We'll use a small sample of product reviews for demonstration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a345f9ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample product reviews\n",
    "reviews = [\n",
    "    'This product is amazing! I love it.',\n",
    "    'Terrible experience, will not buy again.',\n",
    "    'It works as expected. Nothing special.',\n",
    "    'Absolutely fantastic! Exceeded my expectations.',\n",
    "    'Not worth the price. Very disappointed.',\n",
    "    'Great value for money.',\n",
    "    'The quality is poor and it broke quickly.',\n",
    "    'I am satisfied with my purchase.',\n",
    "    'Worst product ever.',\n",
    "    'Decent, but could be better.'\n",
    "]\n",
    "labels = ['positive', 'negative', 'neutral', 'positive', 'negative', 'positive', 'negative', 'positive', 'negative', 'neutral']\n",
    "df = pd.DataFrame({'review': reviews, 'label': labels})\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54f0a3c6",
   "metadata": {},
   "source": [
    "## üèãÔ∏è Exercise 1: VADER Rule-Based Sentiment Analysis\n",
    "Apply VADER to classify sentiment and visualize the distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2487412c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sia = SentimentIntensityAnalyzer()\n",
    "df['vader_score'] = df['review'].apply(lambda x: sia.polarity_scores(x)['compound'])\n",
    "def vader_label(score):\n",
    "    if score >= 0.05:\n",
    "        return 'positive'\n",
    "    elif score <= -0.05:\n",
    "        return 'negative'\n",
    "    else:\n",
    "        return 'neutral'\n",
    "df['vader_pred'] = df['vader_score'].apply(vader_label)\n",
    "\n",
    "print('VADER Sentiment Predictions:')\n",
    "print(df[['review', 'vader_score', 'vader_pred']])\n",
    "\n",
    "# Visualization\n",
    "plt.figure(figsize=(6,4))\n",
    "sns.countplot(x='vader_pred', data=df, order=['positive','neutral','negative'])\n",
    "plt.title('VADER Sentiment Distribution')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8d44f11",
   "metadata": {},
   "source": [
    "## üèãÔ∏è Exercise 2: ML-Based Sentiment Classification\n",
    "Train a logistic regression model using TF-IDF features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "561aad91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing\n",
    "X = df['review']\n",
    "y = df['label']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n",
    "\n",
    "vectorizer = TfidfVectorizer(stop_words='english')\n",
    "X_train_vec = vectorizer.fit_transform(X_train)\n",
    "X_test_vec = vectorizer.transform(X_test)\n",
    "\n",
    "clf = LogisticRegression(max_iter=200)\n",
    "clf.fit(X_train_vec, y_train)\n",
    "y_pred = clf.predict(X_test_vec)\n",
    "\n",
    "print('Classification Report:')\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred, labels=['positive','neutral','negative'])\n",
    "plt.figure(figsize=(5,4))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['positive','neutral','negative'], yticklabels=['positive','neutral','negative'])\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.title('Confusion Matrix (Logistic Regression)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5aad129",
   "metadata": {},
   "source": [
    "## üèãÔ∏è Exercise 3: Handling Negation and Context\n",
    "Explore how negation affects sentiment and analyze context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0124e631",
   "metadata": {},
   "outputs": [],
   "source": [
    "negation_examples = [\n",
    "    'I do not like this product.',\n",
    "    'Not bad at all!',\n",
    "    'I can't say it's good.',\n",
    "    'This is not the worst experience.',\n",
    "    'I am not unhappy with the result.'\n",
    "]\n",
    "for text in negation_examples:\n",
    "    score = sia.polarity_scores(text)['compound']\n",
    "    label = vader_label(score)\n",
    "    print(f'\"{text}\" -> Score: {score:.2f}, Sentiment: {label}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "708b5c1d",
   "metadata": {},
   "source": [
    "## üèãÔ∏è Exercise 4: Sentiment Distribution Analysis\n",
    "Visualize the distribution of sentiment labels in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29960fdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6,4))\n",
    "sns.countplot(x='label', data=df, order=['positive','neutral','negative'])\n",
    "plt.title('True Sentiment Distribution')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2d2875f",
   "metadata": {},
   "source": [
    "## üìö Summary\n",
    "- Compared VADER rule-based and ML-based sentiment analysis\n",
    "- Explored negation and context effects\n",
    "- Visualized sentiment distributions\n",
    "\n",
    "**Next steps:** Try with larger datasets, experiment with other models (SVM, transformers), and analyze real-world data!"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
