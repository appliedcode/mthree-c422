{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNs4ChfQH/FMNbZx5GfWDkt",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/appliedcode/mthree-c422/blob/main/Exercises/day-4/Sampling/Lab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Je1rSo0GgiJ0"
      },
      "outputs": [],
      "source": [
        "# Lab Exercises: Sampling Techniques\n",
        "## This notebook demonstrates various probabilistic and non-probabilistic sampling methods using the Iris dataset. Run each section to see how samples differ.\n",
        ")\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.datasets import load_iris\n",
        "\n",
        "# Load Iris dataset into DataFrame\n",
        "iris = load_iris(as_frame=True)\n",
        "df = iris.frame\n",
        "df['target'] = iris.target\n",
        "df.head()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Probabilistic Sampling Methods"
      ],
      "metadata": {
        "id": "6MJQn8_Ylk_W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1.1 Simple Random Sampling\n",
        "# Select n rows uniformly at random.\n",
        "\n",
        "# Simple random sample of 50 observations\n",
        "simple_rand = df.sample(n=50, random_state=42)\n",
        "print(simple_rand.shape)\n"
      ],
      "metadata": {
        "id": "HA57g_BllnWG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1.2 Systematic Sampling\n",
        "# Choose every kᵗʰ record after a random start.\n",
        "def systematic_sampling(data, k, seed=42):\n",
        "    np.random.seed(seed)\n",
        "    start = np.random.randint(0, k)\n",
        "    indices = np.arange(start, len(data), k)\n",
        "    return data.iloc[indices]\n",
        "\n",
        "# Every 10th after a random start\n",
        "sys_sample = systematic_sampling(df, k=10)\n",
        "print(sys_sample.shape)\n",
        "\n"
      ],
      "metadata": {
        "id": "XGR9LhsTltpH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1.3 Stratified Random Sampling\n",
        "# Sample within each class proportional to its size.\n",
        "# Stratified sample: 30% from each species\n",
        "strata = df.groupby('target', group_keys=False).apply(\n",
        "    lambda x: x.sample(frac=0.3, random_state=42)\n",
        ")\n",
        "print(strata['target'].value_counts(normalize=True))\n"
      ],
      "metadata": {
        "id": "cQk9lbhWlyKp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1.4 Cluster Sampling\n",
        "# Randomly select entire clusters, then use all items in chosen clusters.\n",
        "\n",
        "# Define clusters by rounding sepal length\n",
        "df['cluster'] = (df['sepal length (cm)'] // 1).astype(int)\n",
        "clusters = df['cluster'].unique()\n",
        "\n",
        "# Randomly pick 2 clusters\n",
        "chosen = np.random.choice(clusters, size=2, replace=False)\n",
        "cluster_sample = df[df['cluster'].isin(chosen)]\n",
        "print(\"Clusters chosen:\", chosen)\n",
        "print(cluster_sample['cluster'].value_counts())\n"
      ],
      "metadata": {
        "id": "UpzdWeEKl1El"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Non-Probabilistic Sampling Methods"
      ],
      "metadata": {
        "id": "_ttcpYi1l3MO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 2.1 Convenience Sampling\n",
        "# Select the first n rows or any easily accessible subset.\n",
        "# First 50 rows as a convenience sample\n",
        "convenience = df.head(50)\n",
        "print(convenience.shape)\n"
      ],
      "metadata": {
        "id": "dBqLmzgql45U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 2.2 Judgmental (Selective) Sampling\n",
        "# Manually pick samples based on domain knowledge.\n",
        "# E.g., pick all Setosa and first 10 Versicolor\n",
        "judgmental = pd.concat([\n",
        "    df[df['target'] == 0],\n",
        "    df[df['target'] == 1].head(10)\n",
        "])\n",
        "print(judgmental['target'].value_counts())\n"
      ],
      "metadata": {
        "id": "M2hKxrC-l_5T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 2.3 Snowball Sampling\n",
        "# Begin with a small seed and expand via similarity (simulated by nearest neighbors here).\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "\n",
        "# Seed: pick 5 random points\n",
        "seed = df.sample(n=5, random_state=42)\n",
        "nbrs = NearestNeighbors(n_neighbors=3).fit(df.drop(columns=['target','cluster']))\n",
        "distances, indices = nbrs.kneighbors(seed.drop(columns=['target','cluster']))\n",
        "\n",
        "# Snowball: union of seed and their neighbors\n",
        "snowball_idx = set(seed.index)\n",
        "for neigh in indices:\n",
        "    snowball_idx.update(neigh)\n",
        "snowball = df.loc[list(snowball_idx)]\n",
        "print(snowball.shape)\n"
      ],
      "metadata": {
        "id": "bqFL2e8ymCpi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 2.4 Quota Sampling\n",
        "# Ensure the sample meets predefined quotas for each stratum.\n",
        "# Quotas: 20 Setosa, 15 Versicolor, 10 Virginica\n",
        "quota = pd.concat([\n",
        "    df[df['target']==0].sample(n=20, random_state=42),\n",
        "    df[df['target']==1].sample(n=15, random_state=42),\n",
        "    df[df['target']==2].sample(n=10, random_state=42)\n",
        "])\n",
        "print(quota['target'].value_counts())\n"
      ],
      "metadata": {
        "id": "s0i2wM6GmJSZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Instructions\n",
        "- Run each cell and observe the sampled subsets.\n",
        "\n",
        "- Compare sample sizes and class distributions.\n",
        "\n",
        "- Modify parameters (n, k, frac, quotas) to explore their effects.\n",
        "\n",
        "- Reflect on when each sampling method is appropriate in practice."
      ],
      "metadata": {
        "id": "WU-SA0ArmP67"
      }
    }
  ]
}