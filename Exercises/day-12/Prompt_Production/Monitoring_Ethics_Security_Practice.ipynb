{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPAXqohao/S3PYyMjvWtl+T",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/appliedcode/mthree-c422/blob/mthree-422-salleh/Exercises/day-12/Prompt_Production/Monitoring_Ethics_Security_Practice.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Self‑Practice Problem Set – Monitoring, Ethics \\& Security in Prompt Engineering**\n",
        "***\n",
        "\n",
        "### **Section 1 – Monitoring \\& Logging Prompt Usage**\n",
        "\n",
        "**Problem 1 – Basic Prompt Tracker**\n",
        "\n",
        "- Create a Python script that logs **every prompt** sent to the AI along with:\n",
        "    - Timestamp\n",
        "    - Prompt text\n",
        "    - Word count\n",
        "- After 5 test runs, print a formatted log table.\n",
        "\n",
        "**Problem 2 – Token Usage Monitor**\n",
        "\n",
        "- Use model’s metadata to record **input/output token count** for each request.\n",
        "- Compute:\n",
        "    - Average tokens per prompt\n",
        "    - Most token‑heavy prompt\n",
        "- Think about ways to minimize cost based on these readings.\n",
        "\n",
        "**Problem 3 – Duplicate Prompt Detection**\n",
        "\n",
        "- Log prompts for 10 queries.\n",
        "- Add a feature that detects if a prompt is repeated more than once and flags it in the log.\n",
        "\n",
        "***\n",
        "\n",
        "### **Section 2 – Ethical Considerations in Prompt Design**\n",
        "\n",
        "**Problem 4 – Detecting Potential Bias**\n",
        "\n",
        "- Give the model a prompt likely to produce biased content (your choice of topic).\n",
        "- Record \\& analyze the output for signs of bias.\n",
        "- Redesign the prompt to encourage a **balanced, fair perspective**.\n",
        "- Compare the before/after answers.\n",
        "\n",
        "**Problem 5 – Transparency in AI Role**\n",
        "\n",
        "- Design a prompt for a medical Q\\&A assistant.\n",
        "- Ensure:\n",
        "    - It explicitly states it’s **not a medical professional**.\n",
        "    - It encourages consulting certified experts for serious issues.\n",
        "- Ask a high‑risk health question and observe if your role/policy statement is respected.\n",
        "\n",
        "**Problem 6 – Content Filtering Prompt**\n",
        "\n",
        "- Try to get the AI to generate violent story content.\n",
        "- Then create a filtered prompt instructing:\n",
        "    - No explicit, graphic, or harmful details.\n",
        "    - Focus on safe, general descriptions.\n",
        "- Compare tone and detail between outputs.\n",
        "\n",
        "***\n",
        "\n",
        "### **Section 3 – Security \\& Privacy in Prompt‑Based Systems**\n",
        "\n",
        "**Problem 7 – Privacy Protection**\n",
        "\n",
        "- Attempt to retrieve private contact information for a public figure.\n",
        "- Then rewrite:\n",
        "    - Only public domain facts permitted.\n",
        "    - Include explicit “Do not disclose personal data” instruction.\n",
        "- Observe differences in compliance.\n",
        "\n",
        "**Problem 8 – Preventing Data Leakage**\n",
        "\n",
        "- Simulate a chatbot that stores user queries.\n",
        "- Demonstrate how sensitive data could accidentally be exposed in a later conversation.\n",
        "- Then modify the system to **mask or remove** sensitive info from logs.\n",
        "\n",
        "**Problem 9 – Role‑Restricted Responses**\n",
        "\n",
        "- Assign the AI a role as **“STEM tutor”**.\n",
        "- Ask both STEM and non‑STEM questions.\n",
        "- Ensure:\n",
        "    - STEM queries are answered properly.\n",
        "    - Non‑STEM queries are politely declined with a safe explanation.\n",
        "\n",
        "***\n",
        "\n",
        "### **Student Guidelines**\n",
        "\n",
        "For each problem:\n",
        "\n",
        "1. **Implement your own code \\& prompts** in Colab.\n",
        "2. Run the **initial (less safe)** version first, then create a safer/ethical version.\n",
        "3. Keep a **written log** of:\n",
        "    - Prompt text\n",
        "    - Model output (excerpt if long)\n",
        "    - Risks identified\n",
        "    - Improvements made\n",
        "4. Summarize your takeaway after each exercise.\n",
        "\n",
        "***"
      ],
      "metadata": {
        "id": "yk39uZv8y8XQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "import os\n",
        "\n",
        "# Set your OpenAI API key securely in Colab Secrets (once)\n",
        "# userdata.set(\"OPENAI_API_KEY\", \"your-api-key-here\")\n",
        "\n",
        "# Retrieve key in your notebook\n",
        "openai_api_key = userdata.get(\"OPENAI_API_KEY\")\n",
        "if openai_api_key:\n",
        "    os.environ[\"OPENAI_API_KEY\"] = openai_api_key\n",
        "    print(\"✅ OpenAI API key loaded safely\")\n",
        "else:\n",
        "    print(\"❌ OpenAI API key not found. Please set it using Colab Secrets.\")"
      ],
      "metadata": {
        "id": "MpG4TjngzM7x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --quiet openai -q\n",
        "# Create client\n",
        "from openai import OpenAI\n",
        "client = OpenAI(api_key=os.environ[\"OPENAI_API_KEY\"])"
      ],
      "metadata": {
        "id": "Q_puWhWnzUtl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Helper Function to Send Prompts\n",
        "def generate_response(prompt, model=\"gpt-4o-mini\", temperature=0.7):\n",
        "    \"\"\"\n",
        "    Send a prompt to the OpenAI model and return the response text.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        completion = client.chat.completions.create(\n",
        "            model=model,\n",
        "            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "            temperature=temperature\n",
        "        )\n",
        "        return completion.choices[0].message.content.strip()\n",
        "    except Exception as e:\n",
        "        return f\"Error: {e}\"\n"
      ],
      "metadata": {
        "id": "QsWFsH_Hzf01"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Problem 1 – Basic Prompt Tracker"
      ],
      "metadata": {
        "id": "1R9cL8h7zHij"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_U_dxcgsysH8"
      },
      "outputs": [],
      "source": [
        "import datetime\n",
        "\n",
        "# Initialize log storage\n",
        "prompt_log = []\n",
        "\n",
        "def log_prompt_response(prompt, response):\n",
        "    timestamp = datetime.datetime.now().isoformat()\n",
        "    entry = {\n",
        "        \"timestamp\": timestamp,\n",
        "        \"prompt\": prompt,\n",
        "        \"word_count\": len(prompt.split()),\n",
        "        \"response_excerpt\": response[:100]  # Save first 100 chars only\n",
        "    }\n",
        "    prompt_log.append(entry)\n",
        "\n",
        "def print_log():\n",
        "    for e in prompt_log:\n",
        "        print(f\"[{e['timestamp']}] Prompt: {e['prompt']}\")\n",
        "        print(f\"Response (excerpt): {e['response_excerpt']}\\n\")\n",
        "\n",
        "# Example usage\n",
        "sample_prompts = [\n",
        "    \"Explain the greenhouse effect.\",\n",
        "    \"List 3 benefits of renewable energy.\",\n",
        "    \"Explain the greenhouse effect.\"\n",
        "]\n",
        "\n",
        "for p in sample_prompts:\n",
        "    r = generate_response(p)\n",
        "    log_prompt_response(p, r)\n",
        "\n",
        "print_log()"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hN72WzCBzlu_"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}