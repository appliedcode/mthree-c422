{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOI2a9amGTjCDnqELt1uAEv",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/appliedcode/mthree-c422/blob/mthree-c422-dipti/Exercises/day-14/Audit_Governance/AI_Audit_Governance_Practice_3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Problem Statement** â€“ AI Governance, Bias Detection \\& Auditing in Income Prediction Model\n",
        "\n",
        "You are part of an **AI governance team** at a tech company developing a predictive analytics system to identify individuals likely to earn more than **\\$50K/year**.\n",
        "\n",
        "The model must comply with **AI governance principles**, focusing on **fairness, transparency, and accountability**.\n",
        "\n",
        "Your tasks in this exercise are to:\n",
        "\n",
        "- **Detect and measure bias** in predictions across demographic groups (here we will use `\"sex\"` as a sensitive attribute: Male vs Female).\n",
        "- **Provide model transparency** using **SHAP explainability** to understand the most influential features driving predictions.\n",
        "- **Implement AI auditing** by logging performance metrics, bias statistics, and interpretability results.\n",
        "- **Generate a compliance report** that can be reviewed by internal governance boards or external regulators.\n",
        "\n",
        "**Business Context:**\n",
        "Such a model must not unfairly disadvantage certain protected groups. This auditing ensures the system adheres to ethical AI frameworks (like IEEE, OECD, NIST AI RMF) and privacy regulations.\n",
        "\n",
        "***\n",
        "\n",
        "### **Dataset Collection Code**\n",
        "\n",
        "```python\n",
        "from sklearn.datasets import fetch_openml\n",
        "\n",
        "# Load Adult Census dataset from OpenML\n",
        "adult_data = fetch_openml(name='adult', version=2, as_frame=True)\n",
        "\n",
        "# Extract features and target\n",
        "X = adult_data.data\n",
        "y = adult_data.target\n",
        "\n",
        "# Convert target to binary: >50K = 1, <=50K = 0\n",
        "y = y.map({'>50K': 1, '<=50K': 0})\n",
        "\n",
        "print(\"Dataset shape:\", X.shape)\n",
        "print(\"Target distribution:\\n\", y.value_counts())\n",
        "```\n",
        "\n",
        "\n",
        "***"
      ],
      "metadata": {
        "id": "pyS8WGsVp_oy"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OZHr-jL-p-mx",
        "outputId": "02919a9e-9446-4987-ffe3-3e90a8746ea7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset shape: (48842, 14)\n",
            "Target distribution:\n",
            " class\n",
            "0    37155\n",
            "1    11687\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.89      0.93      0.91     11233\n",
            "           1       0.73      0.63      0.68      3420\n",
            "\n",
            "    accuracy                           0.86     14653\n",
            "   macro avg       0.81      0.78      0.79     14653\n",
            "weighted avg       0.85      0.86      0.85     14653\n",
            "\n",
            "\n",
            "Audit Log Initial Entry:\n",
            " {'timestamp': '2025-08-14T08:19:46.751705', 'classification_report': {'0': {'precision': 0.8918271287976037, 'recall': 0.9277129885159797, 'f1-score': 0.9094161794222881, 'support': 11233.0}, '1': {'precision': 0.7264150943396226, 'recall': 0.6304093567251462, 'f1-score': 0.6750156543519098, 'support': 3420.0}, 'accuracy': 0.8583225278100047, 'macro avg': {'precision': 0.8091211115686132, 'recall': 0.779061172620563, 'f1-score': 0.792215916887099, 'support': 14653.0}, 'weighted avg': {'precision': 0.8532200750989554, 'recall': 0.8583225278100047, 'f1-score': 0.8547072600378144, 'support': 14653.0}}, 'confusion_matrix': [[10421, 812], [1264, 2156]]}\n",
            "\n",
            "Outcome rates by Sex:\n",
            "           total  positive_rate_actual  positive_rate_predicted\n",
            "sex_attr                                                      \n",
            "Female     4851              0.104102                 0.076479\n",
            "Male       9802              0.297388                 0.264946\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-1180528891.py:82: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
            "  grouped = test_results.groupby('sex_attr').agg(\n"
          ]
        }
      ],
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"Adult Census AI Governance, Compliance, and Auditing\"\"\"\n",
        "\n",
        "# Install necessary packages\n",
        "!pip install shap scikit-learn pandas -q\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.datasets import fetch_openml\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import shap\n",
        "import datetime\n",
        "\n",
        "# -------------------\n",
        "# Dataset Collection\n",
        "# -------------------\n",
        "adult_data = fetch_openml(name='adult', version=2, as_frame=True)\n",
        "\n",
        "# Features (X) and Target (y)\n",
        "X = adult_data.data\n",
        "y = adult_data.target.map({'>50K': 1, '<=50K': 0})\n",
        "\n",
        "print(\"Dataset shape:\", X.shape)\n",
        "print(\"Target distribution:\\n\", y.value_counts())\n",
        "\n",
        "# Encode categorical variables (One-Hot Encoding)\n",
        "X = pd.get_dummies(X, drop_first=True)\n",
        "\n",
        "# Sensitive attribute: We reconstruct 'sex' column for bias detection\n",
        "# Original dataset contains 'sex', we need it separately for bias audit\n",
        "adult_original = adult_data.data\n",
        "sensitive_attr = adult_original['sex'].map({'Male': 1, 'Female': 0})  # 1=Male, 0=Female\n",
        "\n",
        "X['sex_attr'] = sensitive_attr  # Keep a separate column\n",
        "\n",
        "# -------------------\n",
        "# Train-Test Split\n",
        "# -------------------\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.3, random_state=42\n",
        ")\n",
        "\n",
        "# -------------------\n",
        "# Model Training\n",
        "# -------------------\n",
        "clf = RandomForestClassifier(random_state=42)\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "# Predictions\n",
        "y_pred = clf.predict(X_test)\n",
        "\n",
        "# -------------------\n",
        "# Model Evaluation\n",
        "# -------------------\n",
        "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n",
        "\n",
        "# -------------------\n",
        "# AI Auditing Step 1: Log metrics\n",
        "# -------------------\n",
        "audit_log = {\n",
        "    \"timestamp\": datetime.datetime.now().isoformat(),\n",
        "    \"classification_report\": classification_report(y_test, y_pred, output_dict=True),\n",
        "    \"confusion_matrix\": confusion_matrix(y_test, y_pred).tolist()\n",
        "}\n",
        "print(\"\\nAudit Log Initial Entry:\\n\", audit_log)\n",
        "\n",
        "# -------------------\n",
        "# Bias Detection by Sex\n",
        "# -------------------\n",
        "# Retrieve sensitive attribute from test set\n",
        "test_results = X_test.copy()\n",
        "test_results['actual'] = y_test.values\n",
        "test_results['predicted'] = y_pred\n",
        "\n",
        "# Convert 'actual' and 'predicted' to numeric before aggregation\n",
        "test_results['actual'] = test_results['actual'].astype(int)\n",
        "test_results['predicted'] = test_results['predicted'].astype(int)\n",
        "\n",
        "\n",
        "grouped = test_results.groupby('sex_attr').agg(\n",
        "    total=('actual', 'count'),\n",
        "    positive_rate_actual=('actual', 'mean'),\n",
        "    positive_rate_predicted=('predicted', 'mean')\n",
        ")\n",
        "\n",
        "grouped.index = grouped.index.map({0: 'Female', 1: 'Male'})\n",
        "print(\"\\nOutcome rates by Sex:\\n\", grouped)\n",
        "\n",
        "# Add bias report to audit log\n",
        "bias_report = grouped.to_string()\n",
        "audit_log['bias_report'] = bias_report\n",
        "\n",
        "# -------------------\n",
        "# Model Transparency with SHAP\n",
        "# -------------------\n",
        "explainer = shap.TreeExplainer(clf)\n",
        "shap_values = explainer.shap_values(X_test)\n",
        "\n",
        "# Plot summary for class '1' (>50K income)\n",
        "shap.summary_plot(shap_values[1], X_test, show=True)\n",
        "\n",
        "# -------------------\n",
        "# Compliance & Audit Documentation\n",
        "# -------------------\n",
        "compliance_notes = f\"\"\"\n",
        "Model Compliance and Audit Report:\n",
        "-----------------------------------\n",
        "Timestamp: {audit_log['timestamp']}\n",
        "\n",
        "Bias Detection:\n",
        "Outcome disparities between sex groups:\n",
        "{bias_report}\n",
        "\n",
        "Model Performance:\n",
        "- Detailed metrics in classification report\n",
        "- Confusion matrix: {audit_log[\"confusion_matrix\"]}\n",
        "\n",
        "Transparency:\n",
        "- SHAP used to interpret feature importance and influence\n",
        "- Explainability provided for decision accountability\n",
        "\n",
        "Governance & Auditing:\n",
        "- Metrics, bias analysis, and interpretability documented\n",
        "- Ready for review under AI governance frameworks and regulatory requirements\n",
        "\"\"\"\n",
        "\n",
        "print(compliance_notes)"
      ]
    }
  ]
}