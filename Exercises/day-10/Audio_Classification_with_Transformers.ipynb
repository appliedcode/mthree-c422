{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOj0Nhmcc2v89Ns74w9Hosp",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/appliedcode/mthree-c422/blob/mthree-422-salleh/Exercises/day-10/Audio_Classification_with_Transformers.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Problem Statement: Audio Classification with Transformers on the ESC-50 Environmental Sound Dataset\n",
        "\n",
        "This is from the file Exercises/day-10/Problem_Statement_Audio.md\n",
        "\n",
        "### Objective\n",
        "\n",
        "Build and evaluate a transformer-based audio classification model using the ESC-50 dataset. The task involves loading and preprocessing environmental audio clips, applying a pretrained transformer or fine-tuning it for classifying audio into 50 environmental sound classes, and analyzing model performance.\n",
        "\n",
        "### Dataset\n",
        "\n",
        "**ESC-50** (Environmental Sound Classification)\n",
        "\n",
        "- Publicly available dataset of 2,000 labeled environmental audio recordings (5 seconds each) across 50 classes such as dog bark, rain, siren, and keyboard typing.\n",
        "- Download URL: https://github.com/karolpiczak/ESC-50 (direct audio files in WAV format and metadata CSV)\n",
        "- The dataset is well suited for benchmarking environmental audio classification models.\n",
        "\n",
        "\n",
        "### Learning Objectives\n",
        "\n",
        "- Load and preprocess short environmental audio clips (sample rate standardization, normalization).\n",
        "- Extract audio features suitable for transformer models (raw waveform or learned embeddings).\n",
        "- Use a pretrained audio transformer model (e.g., Wav2Vec 2.0, Hubert) as a feature extractor or fine-tune it for classification.\n",
        "- Train, validate, and test the model on the ESC-50 dataset classes.\n",
        "- Visualize training progress and assess model accuracy, confusion matrices, and class-wise performance.\n",
        "- Investigate the attention patterns of the transformer to understand which audio segments influence classification.\n",
        "\n",
        "\n",
        "### Tasks\n",
        "\n",
        "1. **Dataset Preparation**\n",
        "    - Download and unzip ESC-50.\n",
        "    - Load metadata CSV to map audio file names to labels.\n",
        "    - Implement audio loading pipeline (e.g., using librosa or torchaudio) to read and preprocess the clips uniformly.\n",
        "2. **Feature Extraction and Modeling**\n",
        "    - Use pretrained transformer audio models (e.g., `facebook/wav2vec2-base`, `superb/hubert-large-superb-ks`) from Hugging Face Transformers.\n",
        "    - Convert audio clips into model inputs (waveform arrays or processed features).\n",
        "    - Fine-tune on ESC-50 or extract fixed embeddings and train a classifier head.\n",
        "3. **Training and Evaluation**\n",
        "    - Split data into training and testing sets as per standard ESC-50 folds or create your own split.\n",
        "    - Train the model and monitor learning curves.\n",
        "    - Evaluate accuracy, per-class precision \\& recall, and generate confusion matrix.\n",
        "4. **Attention Visualization and Analysis (Optional)**\n",
        "    - Visualize attention maps or gradients to interpret model focus on specific temporal audio segments.\n",
        "    - Analyze attention differences across sound classes.\n",
        "5. **Reporting**\n",
        "    - Summarize data preprocessing challenges and solutions.\n",
        "    - Present quantitative model results and qualitative insights from attention visualizations.\n",
        "    - Discuss potential improvements like data augmentation or ensembling.\n",
        "\n",
        "### Deliverables\n",
        "\n",
        "- Python notebook or script implementing data loading, preprocessing, training, and evaluation.\n",
        "- Visualizations of attention weights and model performance metrics.\n",
        "- A brief report or markdown summarizing findings, challenges, and future directions.\n",
        "\n",
        "This problem encourages hands-on experience with transformer models for audio classification on a real, publicly available dataset, expanding beyond speech recognition to environmental sound understanding.\n",
        "\n",
        "If you'd like, I can also help generate starter code or a complete Colab notebook for this task! Would you be interested?"
      ],
      "metadata": {
        "id": "vcROP-N294Zy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install required packages\n",
        "# !pip install transformers datasets torch torchaudio librosa soundfile scikit-learn matplotlib seaborn\n",
        "\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import librosa\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from transformers import Wav2Vec2FeatureExtractor, Wav2Vec2Model\n",
        "import requests\n",
        "import zipfile\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "id": "Quf6XeNn_B6t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Device\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "print(f\"Using device: {device}\")"
      ],
      "metadata": {
        "id": "x8vkziYb_HJL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Download the ESC-50 dataset"
      ],
      "metadata": {
        "id": "JWO9G9vs_NWV"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}