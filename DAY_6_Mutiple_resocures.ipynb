{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOhvYx0I7/uhceJXy4bicc+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/appliedcode/mthree-c422/blob/c422_Mounika/DAY_6_Mutiple_resocures.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3nIkOzhdbui9"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Step 1: Set Up Environment\n",
        "!pip install pandas requests -q\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 2: Ingest Data from Multiple Sources\n",
        "# a. CSV File\n",
        "import pandas as pd\n",
        "\n",
        "csv_url = \"https://raw.githubusercontent.com/uiuc-cse/data-fa14/gh-pages/data/iris.csv\"\n",
        "df_csv = pd.read_csv(csv_url)\n",
        "print(\"CSV Data Sample:\")\n",
        "print(df_csv.head())\n",
        "\n",
        "# b. JSON File\n",
        "import json\n",
        "\n",
        "json_url = \"https://jsonplaceholder.typicode.com/users\"\n",
        "df_json = pd.read_json(json_url)\n",
        "print(\"\\nJSON Data Sample:\")\n",
        "print(df_json.head())\n",
        "\n",
        "#c. REST API\n",
        "import requests\n",
        "\n",
        "api_url = \"https://randomuser.me/api/?results=5\"\n",
        "response = requests.get(api_url)\n",
        "data = response.json()\n",
        "df_api = pd.json_normalize(data['results'])\n",
        "print(\"\\nREST API Data Sample:\")\n",
        "print(df_api.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vo3zyzhjcA5A",
        "outputId": "62a13282-31dd-4d51-fb38-a601b0febf05"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CSV Data Sample:\n",
            "   sepal_length  sepal_width  petal_length  petal_width species\n",
            "0           5.1          3.5           1.4          0.2  setosa\n",
            "1           4.9          3.0           1.4          0.2  setosa\n",
            "2           4.7          3.2           1.3          0.2  setosa\n",
            "3           4.6          3.1           1.5          0.2  setosa\n",
            "4           5.0          3.6           1.4          0.2  setosa\n",
            "\n",
            "JSON Data Sample:\n",
            "   id              name   username                      email  \\\n",
            "0   1     Leanne Graham       Bret          Sincere@april.biz   \n",
            "1   2      Ervin Howell  Antonette          Shanna@melissa.tv   \n",
            "2   3  Clementine Bauch   Samantha         Nathan@yesenia.net   \n",
            "3   4  Patricia Lebsack   Karianne  Julianne.OConner@kory.org   \n",
            "4   5  Chelsey Dietrich     Kamren   Lucio_Hettinger@annie.ca   \n",
            "\n",
            "                                             address                  phone  \\\n",
            "0  {'street': 'Kulas Light', 'suite': 'Apt. 556',...  1-770-736-8031 x56442   \n",
            "1  {'street': 'Victor Plains', 'suite': 'Suite 87...    010-692-6593 x09125   \n",
            "2  {'street': 'Douglas Extension', 'suite': 'Suit...         1-463-123-4447   \n",
            "3  {'street': 'Hoeger Mall', 'suite': 'Apt. 692',...      493-170-9623 x156   \n",
            "4  {'street': 'Skiles Walks', 'suite': 'Suite 351...          (254)954-1289   \n",
            "\n",
            "         website                                            company  \n",
            "0  hildegard.org  {'name': 'Romaguera-Crona', 'catchPhrase': 'Mu...  \n",
            "1  anastasia.net  {'name': 'Deckow-Crist', 'catchPhrase': 'Proac...  \n",
            "2    ramiro.info  {'name': 'Romaguera-Jacobson', 'catchPhrase': ...  \n",
            "3       kale.biz  {'name': 'Robel-Corkery', 'catchPhrase': 'Mult...  \n",
            "4   demarco.info  {'name': 'Keebler LLC', 'catchPhrase': 'User-c...  \n",
            "\n",
            "REST API Data Sample:\n",
            "   gender                       email           phone            cell nat  \\\n",
            "0    male  jordan.jenkins@example.com    041-308-6784    081-430-0415  IE   \n",
            "1    male      jimi.harju@example.com      03-994-034   048-631-34-44  FI   \n",
            "2    male   pablo.richard@example.com  03-94-77-52-89  06-16-36-62-48  FR   \n",
            "3  female         ln.rdyy@example.com    048-50095840   0935-692-2652  IR   \n",
            "4    male   armando.garza@example.com  (844) 227-9965  (686) 583-1277  US   \n",
            "\n",
            "  name.title name.first name.last  location.street.number  \\\n",
            "0         Mr     Jordan   Jenkins                    8417   \n",
            "1         Mr       Jimi     Harju                    7799   \n",
            "2         Mr      Pablo   Richard                    6190   \n",
            "3         Ms       النا     رضایی                    3066   \n",
            "4         Mr    Armando     Garza                    7944   \n",
            "\n",
            "  location.street.name  ...  \\\n",
            "0         Boghall Road  ...   \n",
            "1          Suvantokatu  ...   \n",
            "2    Rue Dugas-Montbel  ...   \n",
            "3                داودی  ...   \n",
            "4     Hickory Creek Dr  ...   \n",
            "\n",
            "                                        login.sha256  \\\n",
            "0  cee3b09d28511cf1319cab1b27d26f242d23889aa0c44b...   \n",
            "1  f27989c74836324fcc21c1b53e2e9fcbc9678d7d698ace...   \n",
            "2  0351f13ad7bfedc3796cfb9f9c69b685132ccdebd2d458...   \n",
            "3  4f196e609980de57b475cc51444ebe1e8feab6cd619909...   \n",
            "4  0f1ce74713b05b8eae8017d2c7c6c269461ae5c76870c1...   \n",
            "\n",
            "                   dob.date dob.age           registered.date registered.age  \\\n",
            "0  1960-10-09T17:30:21.481Z      64  2019-10-11T19:57:29.448Z              5   \n",
            "1  1961-06-12T05:09:18.239Z      64  2021-09-24T05:48:35.753Z              3   \n",
            "2  1967-12-01T17:35:08.402Z      57  2012-04-03T01:09:00.368Z             13   \n",
            "3  1969-10-18T05:37:13.254Z      55  2011-11-27T23:04:07.231Z             13   \n",
            "4  1986-11-17T00:25:24.221Z      38  2016-06-01T06:59:26.192Z              9   \n",
            "\n",
            "  id.name           id.value  \\\n",
            "0     PPS           1230267T   \n",
            "1    HETU  NaNNA277undefined   \n",
            "2   INSEE   1671148479283 03   \n",
            "3                       None   \n",
            "4     SSN        226-38-5609   \n",
            "\n",
            "                                      picture.large  \\\n",
            "0    https://randomuser.me/api/portraits/men/70.jpg   \n",
            "1     https://randomuser.me/api/portraits/men/1.jpg   \n",
            "2    https://randomuser.me/api/portraits/men/96.jpg   \n",
            "3  https://randomuser.me/api/portraits/women/62.jpg   \n",
            "4    https://randomuser.me/api/portraits/men/17.jpg   \n",
            "\n",
            "                                      picture.medium  \\\n",
            "0  https://randomuser.me/api/portraits/med/men/70...   \n",
            "1  https://randomuser.me/api/portraits/med/men/1.jpg   \n",
            "2  https://randomuser.me/api/portraits/med/men/96...   \n",
            "3  https://randomuser.me/api/portraits/med/women/...   \n",
            "4  https://randomuser.me/api/portraits/med/men/17...   \n",
            "\n",
            "                                   picture.thumbnail  \n",
            "0  https://randomuser.me/api/portraits/thumb/men/...  \n",
            "1  https://randomuser.me/api/portraits/thumb/men/...  \n",
            "2  https://randomuser.me/api/portraits/thumb/men/...  \n",
            "3  https://randomuser.me/api/portraits/thumb/wome...  \n",
            "4  https://randomuser.me/api/portraits/thumb/men/...  \n",
            "\n",
            "[5 rows x 34 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 2: Ingest Data from Multiple Sources\n",
        "# a. CSV File\n",
        "import pandas as pd\n",
        "\n",
        "csv_url = \"https://raw.githubusercontent.com/uiuc-cse/data-fa14/gh-pages/data/iris.csv\"\n",
        "df_csv = pd.read_csv(csv_url)\n",
        "print(\"CSV Data Sample:\")\n",
        "print(df_csv.columns)\n",
        "\n",
        "# b. JSON File\n",
        "import json\n",
        "\n",
        "json_url = \"https://jsonplaceholder.typicode.com/users\"\n",
        "df_json = pd.read_json(json_url)\n",
        "print(\"\\nJSON Data Sample:\")\n",
        "print(df_json.head())\n",
        "\n",
        "#c. REST API\n",
        "import requests\n",
        "\n",
        "api_url = \"https://randomuser.me/api/?results=5\"\n",
        "response = requests.get(api_url)\n",
        "data = response.json()\n",
        "df_api = pd.json_normalize(data['results'])\n",
        "print(\"\\nREST API Data Sample:\")\n",
        "print(df_api.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aljPd4mTcGEp",
        "outputId": "46135831-c42b-469d-9cb5-7d9012990933"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CSV Data Sample:\n",
            "Index(['sepal_length', 'sepal_width', 'petal_length', 'petal_width',\n",
            "       'species'],\n",
            "      dtype='object')\n",
            "\n",
            "JSON Data Sample:\n",
            "   id              name   username                      email  \\\n",
            "0   1     Leanne Graham       Bret          Sincere@april.biz   \n",
            "1   2      Ervin Howell  Antonette          Shanna@melissa.tv   \n",
            "2   3  Clementine Bauch   Samantha         Nathan@yesenia.net   \n",
            "3   4  Patricia Lebsack   Karianne  Julianne.OConner@kory.org   \n",
            "4   5  Chelsey Dietrich     Kamren   Lucio_Hettinger@annie.ca   \n",
            "\n",
            "                                             address                  phone  \\\n",
            "0  {'street': 'Kulas Light', 'suite': 'Apt. 556',...  1-770-736-8031 x56442   \n",
            "1  {'street': 'Victor Plains', 'suite': 'Suite 87...    010-692-6593 x09125   \n",
            "2  {'street': 'Douglas Extension', 'suite': 'Suit...         1-463-123-4447   \n",
            "3  {'street': 'Hoeger Mall', 'suite': 'Apt. 692',...      493-170-9623 x156   \n",
            "4  {'street': 'Skiles Walks', 'suite': 'Suite 351...          (254)954-1289   \n",
            "\n",
            "         website                                            company  \n",
            "0  hildegard.org  {'name': 'Romaguera-Crona', 'catchPhrase': 'Mu...  \n",
            "1  anastasia.net  {'name': 'Deckow-Crist', 'catchPhrase': 'Proac...  \n",
            "2    ramiro.info  {'name': 'Romaguera-Jacobson', 'catchPhrase': ...  \n",
            "3       kale.biz  {'name': 'Robel-Corkery', 'catchPhrase': 'Mult...  \n",
            "4   demarco.info  {'name': 'Keebler LLC', 'catchPhrase': 'User-c...  \n",
            "\n",
            "REST API Data Sample:\n",
            "   gender                        email           phone            cell nat  \\\n",
            "0  female     grace.cooper@example.com  (305)-017-7025  (865)-336-9307  NZ   \n",
            "1    male        hugo.mota@example.com  (697) 151 9585  (603) 623 3766  MX   \n",
            "2  female    noemie.martin@example.com  01-89-48-37-07  06-58-08-59-72  FR   \n",
            "3    male         emile.li@example.com    L91 X39-3949    H78 T23-3172  CA   \n",
            "4  female  deborah.morales@example.com    015395 27522    07776 346002  GB   \n",
            "\n",
            "  name.title name.first name.last  location.street.number  \\\n",
            "0        Mrs      Grace    Cooper                    6602   \n",
            "1         Mr       Hugo      Mota                    8827   \n",
            "2         Ms     Noemie    Martin                    3336   \n",
            "3         Mr      Emile        Li                    1600   \n",
            "4       Miss    Deborah   Morales                    3300   \n",
            "\n",
            "     location.street.name  ...  \\\n",
            "0              Innes Road  ...   \n",
            "1          Retorno Oaxaca  ...   \n",
            "2  Quai Charles-De-Gaulle  ...   \n",
            "3            Richmond Ave  ...   \n",
            "4          Highfield Road  ...   \n",
            "\n",
            "                                        login.sha256  \\\n",
            "0  4b5be0e4672d27203978ac67402b582136e1ebd7b89745...   \n",
            "1  3138b5c592fb981b5fb54175d791b904f65745edd88c2c...   \n",
            "2  049228a1ecef9d57fd50b1e9643d92f93e1cae1135ab9c...   \n",
            "3  19b9a9926b4a6df19d7f14bc66c0fa953ca3281ad17d1c...   \n",
            "4  2b15543d86d0d7a8626b56b2624f5057c5d3d1fe40db9a...   \n",
            "\n",
            "                   dob.date dob.age           registered.date registered.age  \\\n",
            "0  1978-11-23T19:52:19.627Z      46  2002-08-14T15:54:37.910Z             22   \n",
            "1  1993-04-20T18:55:37.672Z      32  2019-12-30T02:54:28.738Z              5   \n",
            "2  1995-07-23T03:11:48.758Z      30  2014-03-24T03:50:38.868Z             11   \n",
            "3  1952-07-03T22:47:09.413Z      73  2022-02-12T02:14:01.929Z              3   \n",
            "4  1991-08-20T22:54:11.505Z      33  2007-12-09T01:51:00.554Z             17   \n",
            "\n",
            "  id.name          id.value                                     picture.large  \\\n",
            "0                      None  https://randomuser.me/api/portraits/women/55.jpg   \n",
            "1     NSS   98 77 86 6112 9    https://randomuser.me/api/portraits/men/21.jpg   \n",
            "2   INSEE  2950636196768 40  https://randomuser.me/api/portraits/women/74.jpg   \n",
            "3     SIN         842523672    https://randomuser.me/api/portraits/men/56.jpg   \n",
            "4    NINO     XK 81 17 42 Y  https://randomuser.me/api/portraits/women/37.jpg   \n",
            "\n",
            "                                      picture.medium  \\\n",
            "0  https://randomuser.me/api/portraits/med/women/...   \n",
            "1  https://randomuser.me/api/portraits/med/men/21...   \n",
            "2  https://randomuser.me/api/portraits/med/women/...   \n",
            "3  https://randomuser.me/api/portraits/med/men/56...   \n",
            "4  https://randomuser.me/api/portraits/med/women/...   \n",
            "\n",
            "                                   picture.thumbnail  \n",
            "0  https://randomuser.me/api/portraits/thumb/wome...  \n",
            "1  https://randomuser.me/api/portraits/thumb/men/...  \n",
            "2  https://randomuser.me/api/portraits/thumb/wome...  \n",
            "3  https://randomuser.me/api/portraits/thumb/men/...  \n",
            "4  https://randomuser.me/api/portraits/thumb/wome...  \n",
            "\n",
            "[5 rows x 34 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 3: Modular Cleaning/Transformation\n",
        "# Example: Clean and select specific columns from each\n",
        "\n",
        "# For CSV (Iris), let's only keep numeric columns and rename\n",
        "df_csv_clean = df_csv.rename(columns={'species':'source'}).dropna()\n",
        "\n",
        "# For JSON (User info), select name and email\n",
        "df_json_clean = df_json[['name', 'email']].copy()\n",
        "df_json_clean['source'] = 'json'\n",
        "\n",
        "# For API data (Random users), grab first/last name, email\n",
        "df_api_clean = pd.DataFrame()\n",
        "df_api_clean['name'] = df_api['name.first'] + \" \" + df_api['name.last']\n",
        "df_api_clean['email'] = df_api['email']\n",
        "df_api_clean['source'] = 'api'"
      ],
      "metadata": {
        "id": "5jElPR3-cVWf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 4: Prepare each cleaned DataFrame with identical columns\n",
        "\n",
        "common_cols = ['name', 'email', 'source',\n",
        "               'sepal_length', 'sepal_width', 'petal_length', 'petal_width']\n",
        "\n",
        "# CSV (Iris) — rename species to name, add missing columns\n",
        "df_csv_clean = df_csv.rename(columns={'species': 'name'})\n",
        "df_csv_clean['email'] = None\n",
        "df_csv_clean['source'] = 'csv'\n",
        "for col in ['sepal_length','sepal_width','petal_length','petal_width']:\n",
        "    # numeric columns already exist\n",
        "    pass\n",
        "\n",
        "# JSON (Users) — add placeholder iris columns\n",
        "df_json_clean = df_json[['name','email']].copy()\n",
        "df_json_clean['source'] = 'json'\n",
        "for col in ['sepal_length','sepal_width','petal_length','petal_width']:\n",
        "    df_json_clean[col] = None\n",
        "\n",
        "# API (Random Users) — add placeholder iris columns\n",
        "df_api_clean = pd.DataFrame({\n",
        "    'name': df_api['name.first'] + ' ' + df_api['name.last'],\n",
        "    'email': df_api['email'],\n",
        "    'source': 'api'\n",
        "})\n",
        "for col in ['sepal_length','sepal_width','petal_length','petal_width']:\n",
        "    df_api_clean[col] = None\n",
        "\n",
        "# Step 5: Concatenate into unified DataFrame\n",
        "unified_df = pd.concat([\n",
        "    df_csv_clean[common_cols],\n",
        "    df_json_clean[common_cols],\n",
        "    df_api_clean[common_cols]\n",
        "], ignore_index=True)\n",
        "\n",
        "print(\"\\nUnified Clean Dataset Sample:\")\n",
        "print(unified_df.head(10))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tx_1_0Tlck2J",
        "outputId": "ad3f6b6b-9e46-4a7f-a9a7-e60eeeb99abd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Unified Clean Dataset Sample:\n",
            "     name email source  sepal_length  sepal_width  petal_length  petal_width\n",
            "0  setosa  None    csv           5.1          3.5           1.4          0.2\n",
            "1  setosa  None    csv           4.9          3.0           1.4          0.2\n",
            "2  setosa  None    csv           4.7          3.2           1.3          0.2\n",
            "3  setosa  None    csv           4.6          3.1           1.5          0.2\n",
            "4  setosa  None    csv           5.0          3.6           1.4          0.2\n",
            "5  setosa  None    csv           5.4          3.9           1.7          0.4\n",
            "6  setosa  None    csv           4.6          3.4           1.4          0.3\n",
            "7  setosa  None    csv           5.0          3.4           1.5          0.2\n",
            "8  setosa  None    csv           4.4          2.9           1.4          0.2\n",
            "9  setosa  None    csv           4.9          3.1           1.5          0.1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-1748254337.py:30: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
            "  unified_df = pd.concat([\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 4: Prepare each cleaned DataFrame with identical columns\n",
        "\n",
        "common_cols = ['name', 'email', 'source',\n",
        "               'sepal_length', 'sepal_width', 'petal_length']\n",
        "\n",
        "# CSV (Iris) — rename species to name, add missing columns\n",
        "df_csv_clean = df_csv.rename(columns={'species': 'name'})\n",
        "df_csv_clean['email'] = None\n",
        "df_csv_clean['source'] = 'csv'\n",
        "for col in ['sepal_length','sepal_width','petal_length']:\n",
        "    # numeric columns already exist\n",
        "    pass\n",
        "\n",
        "# JSON (Users) — add placeholder iris columns\n",
        "df_json_clean = df_json[['name','email']].copy()\n",
        "df_json_clean['source'] = 'json'\n",
        "for col in ['sepal_length','sepal_width','petal_length',]:\n",
        "    df_json_clean[col] = None\n",
        "\n",
        "# API (Random Users) — add placeholder iris columns\n",
        "df_api_clean = pd.DataFrame({\n",
        "    'name': df_api['name.first'] + ' ' + df_api['name.last'],\n",
        "    'email': df_api['email'],\n",
        "    'source': 'api'\n",
        "})\n",
        "for col in ['sepal_length','sepal_width','petal_length',]:\n",
        "    df_api_clean[col] = None\n",
        "\n",
        "# Step 5: Concatenate into unified DataFrame\n",
        "unified_df = pd.concat([\n",
        "    df_csv_clean[common_cols],\n",
        "    df_json_clean[common_cols],\n",
        "    df_api_clean[common_cols]\n",
        "], ignore_index=True)\n",
        "\n",
        "print(\"\\nUnified Clean Dataset Sample:\")\n",
        "print(unified_df.head(10))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hu8RJfWJcsiX",
        "outputId": "c06500d9-fc30-41ab-ddd3-3b2c288e262d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Unified Clean Dataset Sample:\n",
            "     name email source  sepal_length  sepal_width  petal_length\n",
            "0  setosa  None    csv           5.1          3.5           1.4\n",
            "1  setosa  None    csv           4.9          3.0           1.4\n",
            "2  setosa  None    csv           4.7          3.2           1.3\n",
            "3  setosa  None    csv           4.6          3.1           1.5\n",
            "4  setosa  None    csv           5.0          3.6           1.4\n",
            "5  setosa  None    csv           5.4          3.9           1.7\n",
            "6  setosa  None    csv           4.6          3.4           1.4\n",
            "7  setosa  None    csv           5.0          3.4           1.5\n",
            "8  setosa  None    csv           4.4          2.9           1.4\n",
            "9  setosa  None    csv           4.9          3.1           1.5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-3614858963.py:30: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
            "  unified_df = pd.concat([\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import requests\n",
        "\n",
        "# CSV: Historical weather\n",
        "csv_url = \"https://raw.githubusercontent.com/fivethirtyeight/data/master/us-weather-history/KCLT.csv\"\n",
        "df_csv = pd.read_csv(csv_url)\n",
        "df_csv_clean = df_csv[['date', 'actual_mean_temp']].copy()\n",
        "df_csv_clean.columns = ['date', 'value']\n",
        "df_csv_clean['source'] = 'csv'\n",
        "\n",
        "# JSON: Sample API data\n",
        "json_url = \"https://raw.githubusercontent.com/json-iterator/test-data/master/large-file.json\" # Using a different JSON URL\n",
        "df_json = pd.read_json(json_url)\n",
        "df_json_clean = pd.DataFrame({\n",
        "    'date': [pd.Timestamp.today().strftime('%Y-%m-%d')],\n",
        "    'value': [len(df_json)],\n",
        "    'source': ['json']\n",
        "})\n",
        "\n",
        "# REST API: Current weather data\n",
        "api_url = \"https://api.open-meteo.com/v1/forecast?latitude=52.52&longitude=13.41&current_weather=true\"\n",
        "response = requests.get(api_url)\n",
        "if response.status_code == 200:\n",
        "    current_temp = response.json()['current_weather']['temperature']\n",
        "    df_api_clean = pd.DataFrame({\n",
        "        'date': [pd.Timestamp.today().strftime('%Y-%m-%d')],\n",
        "        'value': [current_temp],\n",
        "        'source': ['api']\n",
        "    })\n",
        "else:\n",
        "    df_api_clean = pd.DataFrame(columns=['date', 'value', 'source'])\n",
        "\n",
        "# Combine all\n",
        "unified_df = pd.concat([df_csv_clean, df_json_clean, df_api_clean], ignore_index=True)\n",
        "print(unified_df.head(10))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0JeWhs59eWj9",
        "outputId": "2183490c-addb-4a84-ef6d-454a184d72ca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "        date  value source\n",
            "0   2014-7-1   81.0    csv\n",
            "1   2014-7-2   85.0    csv\n",
            "2   2014-7-3   82.0    csv\n",
            "3   2014-7-4   75.0    csv\n",
            "4   2014-7-5   72.0    csv\n",
            "5   2014-7-6   74.0    csv\n",
            "6   2014-7-7   79.0    csv\n",
            "7   2014-7-8   83.0    csv\n",
            "8   2014-7-9   80.0    csv\n",
            "9  2014-7-10   78.0    csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import requests\n",
        "\n",
        "# Step 1: Load CSV - Online Retail Sales\n",
        "csv_url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/00352/Online%20Retail.xlsx\"\n",
        "df_csv = pd.read_excel(csv_url)\n",
        "\n",
        "# Clean CSV data: Use Description and UnitPrice\n",
        "df_csv_clean = df_csv[['Description', 'UnitPrice']].dropna()\n",
        "df_csv_clean.columns = ['product_name', 'price']\n",
        "df_csv_clean['source'] = 'csv'\n",
        "\n",
        "# Step 2: Load JSON - Sample Product Test Results\n",
        "# Using a different JSON URL with a simpler structure\n",
        "json_url = \"https://jsonplaceholder.typicode.com/posts\"\n",
        "response = requests.get(json_url)\n",
        "data = response.json()\n",
        "\n",
        "# Create DataFrame from the JSON data\n",
        "# Assuming the new JSON has a list of dictionaries with 'title' and 'id'\n",
        "json_products = []\n",
        "for item in data:\n",
        "    if 'title' in item and 'id' in item:\n",
        "        # Using 'title' as product_name and 'id' as a mock price\n",
        "        json_products.append({'product_name': item['title'], 'price': item['id']})\n",
        "\n",
        "df_json_clean = pd.DataFrame(json_products)\n",
        "df_json_clean['source'] = 'json'\n",
        "\n",
        "\n",
        "# Step 3: Load API - Fake Store Products\n",
        "api_url = \"https://fakestoreapi.com/products\"\n",
        "response = requests.get(api_url)\n",
        "\n",
        "if response.status_code == 200:\n",
        "    api_data = response.json()\n",
        "    df_api_clean = pd.DataFrame(api_data)[['title', 'price']]\n",
        "    df_api_clean.columns = ['product_name', 'price']\n",
        "    df_api_clean['source'] = 'api'\n",
        "else:\n",
        "    df_api_clean = pd.DataFrame(columns=['product_name', 'price', 'source'])\n",
        "\n",
        "\n",
        "# Step 4: Combine All Sources\n",
        "unified_df = pd.concat([df_csv_clean, df_json_clean, df_api_clean], ignore_index=True)\n",
        "\n",
        "# Step 5: Preview Output\n",
        "print(\"Unified Product Dataset (First 10 Rows):\")\n",
        "print(unified_df.head(10))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Re_Yrphfug4",
        "outputId": "f8b542b2-8cdd-4046-e25c-2e4824acca26"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unified Product Dataset (First 10 Rows):\n",
            "                          product_name  price source\n",
            "0   WHITE HANGING HEART T-LIGHT HOLDER   2.55    csv\n",
            "1                  WHITE METAL LANTERN   3.39    csv\n",
            "2       CREAM CUPID HEARTS COAT HANGER   2.75    csv\n",
            "3  KNITTED UNION FLAG HOT WATER BOTTLE   3.39    csv\n",
            "4       RED WOOLLY HOTTIE WHITE HEART.   3.39    csv\n",
            "5         SET 7 BABUSHKA NESTING BOXES   7.65    csv\n",
            "6    GLASS STAR FROSTED T-LIGHT HOLDER   4.25    csv\n",
            "7               HAND WARMER UNION JACK   1.85    csv\n",
            "8            HAND WARMER RED POLKA DOT   1.85    csv\n",
            "9        ASSORTED COLOUR BIRD ORNAMENT   1.69    csv\n"
          ]
        }
      ]
    }
  ]
}