{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bdf104f3",
   "metadata": {},
   "source": [
    "# Reuters News Topic Classification on Google Colab\n",
    "\n",
    "**Problem Statement:**  \n",
    "Build and train a text-classification model to categorize Reuters news articles into topics using the built-in Reuters datasetâ€”no external API keys needed.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2171ee40",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# 1. Import Libraries\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Embedding, GlobalAveragePooling1D, Dense\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.datasets import reuters\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbb3fca3",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# 2. Load & Preprocess Data\n",
    "vocab_size = 10000\n",
    "maxlen = 200\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = reuters.load_data(num_words=vocab_size)\n",
    "x_train = pad_sequences(x_train, maxlen=maxlen, padding='post', truncating='post')\n",
    "x_test  = pad_sequences(x_test,  maxlen=maxlen, padding='post', truncating='post')\n",
    "num_classes = np.max(y_train) + 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba68415d",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# 3. Define the Model\n",
    "model = Sequential([\n",
    "    Embedding(input_dim=vocab_size, output_dim=32, input_length=maxlen),\n",
    "    GlobalAveragePooling1D(),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(num_classes, activation='softmax')\n",
    "])\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5bd4663",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# 4. Train the Model\n",
    "history = model.fit(\n",
    "    x_train, y_train,\n",
    "    epochs=10,\n",
    "    batch_size=512,\n",
    "    validation_split=0.2\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a678ee1",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# 5. Evaluate on Test Set\n",
    "test_loss, test_acc = model.evaluate(x_test, y_test)\n",
    "print(f\"Test Accuracy: {test_acc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "300df442",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# 6. Sample Predictions\n",
    "sample_indices = np.random.choice(len(x_test), 5, replace=False)\n",
    "word_index = reuters.get_word_index()\n",
    "reverse_index = {v:k for k,v in word_index.items()}\n",
    "for idx in sample_indices:\n",
    "    decoded = ' '.join([reverse_index.get(i-3,'?') for i in x_test[idx] if i>3])\n",
    "    pred = np.argmax(model.predict(x_test[idx:idx+1]))\n",
    "    print(f\"Article {idx}: Predicted topic {pred}, True topic {y_test[idx]}\\nText excerpt: {decoded[:200]}...\\n\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
