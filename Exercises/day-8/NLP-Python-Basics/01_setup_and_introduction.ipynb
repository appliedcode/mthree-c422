{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7b23aca2",
   "metadata": {},
   "source": [
    "## Section 1: Environment Setup and Package Installation\n",
    "\n",
    "Before we begin our NLP journey, let's ensure all required packages are installed and working correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acae2c73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages (run this cell if packages are not already installed)\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "def install_package(package):\n",
    "    \"\"\"Install a package using pip\"\"\"\n",
    "    try:\n",
    "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", package])\n",
    "        print(f\"âœ“ Successfully installed {package}\")\n",
    "    except subprocess.CalledProcessError:\n",
    "        print(f\"âœ— Failed to install {package}\")\n",
    "\n",
    "# Core NLP packages\n",
    "packages = [\n",
    "    \"nltk==3.8.1\",\n",
    "    \"spacy==3.7.2\", \n",
    "    \"scikit-learn==1.3.2\",\n",
    "    \"transformers==4.35.2\",\n",
    "    \"datasets==2.14.6\",\n",
    "    \"torch==2.1.1\",\n",
    "    \"pandas==2.0.3\",\n",
    "    \"matplotlib==3.7.2\",\n",
    "    \"seaborn==0.12.2\",\n",
    "    \"wordcloud==1.9.2\",\n",
    "    \"textblob==0.17.1\"\n",
    "]\n",
    "\n",
    "# Uncomment the next lines to install packages\n",
    "# for package in packages:\n",
    "#     install_package(package)\n",
    "\n",
    "print(\"Package installation section complete!\")\n",
    "print(\"Note: Uncomment the installation loop above if you need to install packages.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb1da79d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify imports and download NLTK data\n",
    "import nltk\n",
    "import spacy\n",
    "import sklearn\n",
    "import transformers\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from collections import Counter\n",
    "import re\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"âœ“ All core packages imported successfully!\")\n",
    "\n",
    "# Download required NLTK data\n",
    "nltk_downloads = [\n",
    "    'punkt',\n",
    "    'stopwords', \n",
    "    'vader_lexicon',\n",
    "    'wordnet',\n",
    "    'averaged_perceptron_tagger',\n",
    "    'omw-1.4'\n",
    "]\n",
    "\n",
    "print(\"\\nDownloading NLTK data...\")\n",
    "for data in nltk_downloads:\n",
    "    try:\n",
    "        nltk.download(data, quiet=True)\n",
    "        print(f\"âœ“ Downloaded {data}\")\n",
    "    except:\n",
    "        print(f\"âœ— Failed to download {data}\")\n",
    "\n",
    "print(\"\\nðŸŽ‰ Environment setup complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4c5aceb",
   "metadata": {},
   "source": [
    "## Section 2: Introduction to Natural Language Processing\n",
    "\n",
    "### What is NLP?\n",
    "Natural Language Processing (NLP) is a branch of artificial intelligence that focuses on the interaction between computers and human language. It enables machines to:\n",
    "\n",
    "- **Understand** human language (reading comprehension)\n",
    "- **Generate** human-like text (text generation)\n",
    "- **Translate** between languages\n",
    "- **Extract insights** from text data\n",
    "- **Classify** and **analyze** text content\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cee59fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's start with a simple example to demonstrate basic NLP concepts\n",
    "\n",
    "# Sample text data\n",
    "sample_texts = [\n",
    "    \"I love this product! It's amazing and works perfectly.\",\n",
    "    \"This is the worst purchase I've ever made. Terrible quality!\",\n",
    "    \"The product is okay, nothing special but gets the job done.\",\n",
    "    \"Absolutely fantastic! Would recommend to everyone.\",\n",
    "    \"Not bad, could be better but decent for the price.\"\n",
    "]\n",
    "\n",
    "print(\"Sample Texts:\")\n",
    "print(\"=\" * 50)\n",
    "for i, text in enumerate(sample_texts, 1):\n",
    "    print(f\"{i}. {text}\")\n",
    "\n",
    "# Basic text analysis\n",
    "print(f\"\\nBasic Statistics:\")\n",
    "print(f\"Number of texts: {len(sample_texts)}\")\n",
    "print(f\"Total characters: {sum(len(text) for text in sample_texts)}\")\n",
    "print(f\"Average text length: {sum(len(text) for text in sample_texts) / len(sample_texts):.1f} characters\")\n",
    "\n",
    "# Word frequency analysis\n",
    "all_words = []\n",
    "for text in sample_texts:\n",
    "    # Simple tokenization (split by spaces and remove punctuation)\n",
    "    words = re.findall(r'\\b\\w+\\b', text.lower())\n",
    "    all_words.extend(words)\n",
    "\n",
    "word_freq = Counter(all_words)\n",
    "print(f\"\\nTop 10 Most Common Words:\")\n",
    "for word, count in word_freq.most_common(10):\n",
    "    print(f\"{word}: {count}\")\n",
    "\n",
    "# Basic sentiment indicators\n",
    "positive_words = ['love', 'amazing', 'perfectly', 'fantastic', 'recommend']\n",
    "negative_words = ['worst', 'terrible', 'bad']\n",
    "\n",
    "print(f\"\\nBasic Sentiment Analysis:\")\n",
    "for i, text in enumerate(sample_texts, 1):\n",
    "    text_lower = text.lower()\n",
    "    pos_count = sum(1 for word in positive_words if word in text_lower)\n",
    "    neg_count = sum(1 for word in negative_words if word in text_lower)\n",
    "    \n",
    "    if pos_count > neg_count:\n",
    "        sentiment = \"Positive\"\n",
    "    elif neg_count > pos_count:\n",
    "        sentiment = \"Negative\"\n",
    "    else:\n",
    "        sentiment = \"Neutral\"\n",
    "    \n",
    "    print(f\"Text {i}: {sentiment} (pos: {pos_count}, neg: {neg_count})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6f89763",
   "metadata": {},
   "source": [
    "## Section 3: Loading and Inspecting Datasets\n",
    "\n",
    "Throughout this course, we'll work with several real-world datasets. Let's load and inspect some of the key datasets we'll be using."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d062425",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create sample datasets for the course\n",
    "import os\n",
    "\n",
    "# Create data directory\n",
    "os.makedirs('data', exist_ok=True)\n",
    "\n",
    "# 1. Sample SMS Spam Dataset\n",
    "sms_data = [\n",
    "    (\"ham\", \"Hey, are we still on for lunch today?\"),\n",
    "    (\"spam\", \"URGENT! You've won $1000! Click here now!\"),\n",
    "    (\"ham\", \"Can you pick up milk on your way home?\"),\n",
    "    (\"spam\", \"FREE iPhone! Limited time offer! Call now!\"),\n",
    "    (\"ham\", \"Meeting moved to 3pm tomorrow\"),\n",
    "    (\"spam\", \"Congratulations! You've been selected for a special offer!\"),\n",
    "    (\"ham\", \"Thanks for the birthday wishes!\"),\n",
    "    (\"spam\", \"SALE ALERT: 90% off everything! Don't miss out!\"),\n",
    "    (\"ham\", \"Running late, be there in 10 minutes\"),\n",
    "    (\"spam\", \"You owe $500 in taxes. Pay immediately or face legal action!\")\n",
    "]\n",
    "\n",
    "sms_df = pd.DataFrame(sms_data, columns=['label', 'message'])\n",
    "sms_df.to_csv('data/sms_spam_sample.csv', index=False)\n",
    "\n",
    "print(\"SMS Spam Dataset:\")\n",
    "print(sms_df)\n",
    "print(f\"\\nDataset shape: {sms_df.shape}\")\n",
    "print(f\"Label distribution:\\n{sms_df['label'].value_counts()}\")\n",
    "\n",
    "# 2. Sample Movie Reviews Dataset  \n",
    "movie_reviews = [\n",
    "    (\"positive\", \"This movie was absolutely fantastic! Great acting and storyline.\"),\n",
    "    (\"negative\", \"Boring and predictable. Waste of time and money.\"),\n",
    "    (\"positive\", \"Brilliant cinematography and outstanding performances.\"),\n",
    "    (\"negative\", \"Poor script and terrible direction. Very disappointed.\"),\n",
    "    (\"positive\", \"Highly recommend! One of the best films this year.\"),\n",
    "    (\"negative\", \"Confusing plot and weak character development.\"),\n",
    "    (\"positive\", \"Amazing visual effects and compelling story.\"),\n",
    "    (\"negative\", \"Overrated and underwhelming. Expected much more.\"),\n",
    "    (\"positive\", \"Perfect blend of comedy and drama. Loved every minute!\"),\n",
    "    (\"negative\", \"Slow paced and lacks substance. Not worth watching.\")\n",
    "]\n",
    "\n",
    "reviews_df = pd.DataFrame(movie_reviews, columns=['sentiment', 'review'])\n",
    "reviews_df.to_csv('data/movie_reviews_sample.csv', index=False)\n",
    "\n",
    "print(f\"\\nMovie Reviews Dataset:\")\n",
    "print(reviews_df)\n",
    "print(f\"\\nDataset shape: {reviews_df.shape}\")\n",
    "print(f\"Sentiment distribution:\\n{reviews_df['sentiment'].value_counts()}\")\n",
    "\n",
    "# 3. Sample News Headlines Dataset\n",
    "news_headlines = [\n",
    "    \"Apple announces new iPhone with revolutionary camera technology\",\n",
    "    \"Stock market reaches all-time high amid economic recovery\",\n",
    "    \"Scientists discover new species in Amazon rainforest\",\n",
    "    \"Local restaurant wins prestigious culinary award\",\n",
    "    \"Tech company Microsoft invests in renewable energy projects\",\n",
    "    \"Weather forecast predicts heavy rainfall this weekend\",\n",
    "    \"University researchers develop breakthrough medical treatment\",\n",
    "    \"Amazon expands delivery services to rural areas\",\n",
    "    \"New study reveals benefits of regular exercise\",\n",
    "    \"Government announces new environmental protection policies\"\n",
    "]\n",
    "\n",
    "news_df = pd.DataFrame({'headline': news_headlines})\n",
    "news_df.to_csv('data/news_headlines_sample.csv', index=False)\n",
    "\n",
    "print(f\"\\nNews Headlines Dataset:\")\n",
    "print(news_df)\n",
    "print(f\"\\nDataset shape: {news_df.shape}\")\n",
    "\n",
    "print(f\"\\nâœ… Sample datasets created and saved to 'data/' directory!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdb59013",
   "metadata": {},
   "source": [
    "## Section 4: Quick Exercise - Your First NLP Task\n",
    "\n",
    "Let's practice with a simple exercise to get you comfortable with basic text processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "565bec60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 1: Text Statistics and Basic Analysis\n",
    "# \n",
    "# Task: Write a function that takes a text string and returns:\n",
    "# 1. Number of words\n",
    "# 2. Number of sentences (assume sentences end with '.', '!', or '?')\n",
    "# 3. Average word length\n",
    "# 4. Most frequent word\n",
    "# 5. Number of unique words\n",
    "\n",
    "def analyze_text(text):\n",
    "    \"\"\"\n",
    "    Analyze basic statistics of a text string.\n",
    "    \n",
    "    Args:\n",
    "        text (str): Input text to analyze\n",
    "    \n",
    "    Returns:\n",
    "        dict: Dictionary containing text statistics\n",
    "    \"\"\"\n",
    "    # TODO: Implement this function\n",
    "    # Hint: Use string methods, regular expressions, and Counter\n",
    "    \n",
    "    # Your code here\n",
    "    pass\n",
    "\n",
    "# Test your function with this sample text\n",
    "sample_text = \"\"\"\n",
    "Natural Language Processing is a fascinating field of artificial intelligence. \n",
    "It combines computational linguistics with machine learning and deep learning.\n",
    "NLP enables computers to understand, interpret, and generate human language in a valuable way!\n",
    "\"\"\"\n",
    "\n",
    "# Uncomment and run when you've implemented the function\n",
    "# result = analyze_text(sample_text)\n",
    "# print(\"Text Analysis Results:\")\n",
    "# for key, value in result.items():\n",
    "#     print(f\"{key}: {value}\")\n",
    "\n",
    "# Solution (run this cell to see the solution)\n",
    "def analyze_text_solution(text):\n",
    "    \"\"\"Complete solution for text analysis function\"\"\"\n",
    "    import re\n",
    "    from collections import Counter\n",
    "    \n",
    "    # Clean text and split into words\n",
    "    words = re.findall(r'\\b\\w+\\b', text.lower())\n",
    "    \n",
    "    # Count sentences\n",
    "    sentences = re.findall(r'[.!?]+', text)\n",
    "    \n",
    "    # Calculate statistics\n",
    "    num_words = len(words)\n",
    "    num_sentences = len(sentences)\n",
    "    avg_word_length = sum(len(word) for word in words) / num_words if num_words > 0 else 0\n",
    "    \n",
    "    # Find most frequent word\n",
    "    word_freq = Counter(words)\n",
    "    most_frequent = word_freq.most_common(1)[0] if words else (\"\", 0)\n",
    "    \n",
    "    # Count unique words\n",
    "    unique_words = len(set(words))\n",
    "    \n",
    "    return {\n",
    "        \"word_count\": num_words,\n",
    "        \"sentence_count\": num_sentences,\n",
    "        \"average_word_length\": round(avg_word_length, 2),\n",
    "        \"most_frequent_word\": f\"{most_frequent[0]} ({most_frequent[1]} times)\",\n",
    "        \"unique_words\": unique_words\n",
    "    }\n",
    "\n",
    "# Test the solution\n",
    "result = analyze_text_solution(sample_text)\n",
    "print(\"ðŸ“Š Text Analysis Results:\")\n",
    "print(\"=\" * 30)\n",
    "for key, value in result.items():\n",
    "    print(f\"{key.replace('_', ' ').title()}: {value}\")\n",
    "\n",
    "# Challenge: Try your function on the movie reviews dataset!\n",
    "print(f\"\\nðŸŽ¬ Analyzing movie reviews...\")\n",
    "for i, review in enumerate(reviews_df['review'].head(3), 1):\n",
    "    print(f\"\\nReview {i}:\")\n",
    "    stats = analyze_text_solution(review)\n",
    "    print(f\"Words: {stats['word_count']}, Unique: {stats['unique_words']}, Avg length: {stats['average_word_length']}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
