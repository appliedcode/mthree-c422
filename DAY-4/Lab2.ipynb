{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "vYLDdfOHy_RV"
      },
      "outputs": [],
      "source": [
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X, y = load_breast_cancer(return_X_y=True, as_frame=True)\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.3, random_state=42\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.feature_selection import SelectFromModel\n",
        "from sklearn.metrics import accuracy_score\n",
        "import numpy as np\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "rf = RandomForestClassifier(n_estimators=100, random_state=0)\n",
        "rf.fit(X_train, y_train)\n",
        "\n",
        "sfm_rf = SelectFromModel(rf, prefit=True, max_features=5, threshold=-np.inf)\n",
        "feat_rf = X_train.columns[sfm_rf.get_support()]\n",
        "\n",
        "model = LogisticRegression(max_iter=5000).fit(X_train[feat_rf], y_train)\n",
        "print(\"RF features:\", list(feat_rf))\n",
        "print(\"Accuracy (RF):\", accuracy_score(y_test, model.predict(X_test[feat_rf])))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JgjeWSeRzDZe",
        "outputId": "617a85e5-8b09-4c0f-e442-14103ef469bc"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RF features: ['mean concavity', 'mean concave points', 'worst radius', 'worst perimeter', 'worst concave points']\n",
            "Accuracy (RF): 0.9532163742690059\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import xgboost as xgb\n",
        "\n",
        "xgb_clf = xgb.XGBClassifier(\n",
        "    n_estimators=100, eval_metric='logloss', random_state=0\n",
        ")\n",
        "xgb_clf.fit(X_train, y_train)\n",
        "\n",
        "sfm_xgb = SelectFromModel(xgb_clf, prefit=True, max_features=5, threshold=-np.inf)\n",
        "feat_xgb = X_train.columns[sfm_xgb.get_support()]\n",
        "\n",
        "model = LogisticRegression(max_iter=5000).fit(X_train[feat_xgb], y_train)\n",
        "print(\"XGB features:\", list(feat_xgb))\n",
        "print(\"Accuracy (XGB):\", accuracy_score(y_test, model.predict(X_test[feat_xgb])))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WLE_Fo8vzJ8x",
        "outputId": "06a28c86-42e7-4e1d-b60d-93656e8c5699"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "XGB features: ['mean concave points', 'worst radius', 'worst perimeter', 'worst area', 'worst concave points']\n",
            "Accuracy (XGB): 0.9590643274853801\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.utils import resample\n",
        "\n",
        "# Parameters for stability selection\n",
        "n_bootstraps    = 100\n",
        "sample_fraction = 0.75\n",
        "C               = 1.0\n",
        "\n",
        "# Increase iterations and loosen tolerance\n",
        "max_iter = 20000\n",
        "tol      = 1e-3\n",
        "\n",
        "n_features       = X_train.shape[1]\n",
        "selection_counts = np.zeros(n_features, dtype=int)\n",
        "\n",
        "for i in range(n_bootstraps):\n",
        "    # a) bootstrap sample\n",
        "    idx  = resample(\n",
        "        np.arange(X_train.shape[0]),\n",
        "        replace=True,\n",
        "        n_samples=int(sample_fraction * X_train.shape[0]),\n",
        "        random_state=i\n",
        "    )\n",
        "    X_bs = X_train.values[idx]\n",
        "    y_bs = y_train.values[idx]\n",
        "\n",
        "    # b) fit L1â€penalized logistic with more iterations and looser tol\n",
        "    lr = LogisticRegression(\n",
        "        penalty='l1',\n",
        "        solver='saga',\n",
        "        C=C,\n",
        "        max_iter=max_iter,\n",
        "        tol=tol,\n",
        "        random_state=0\n",
        "    )\n",
        "    lr.fit(X_bs, y_bs)\n",
        "\n",
        "    # c) tally nonzero coefficients\n",
        "    nonzero = np.abs(lr.coef_)[0] > 1e-8\n",
        "    selection_counts += nonzero.astype(int)\n",
        "\n",
        "# Compute frequencies and pick top 5 stable features\n",
        "selection_freq = selection_counts / n_bootstraps\n",
        "top5_idx       = np.argsort(-selection_freq)[:5]\n",
        "feat_rl        = X_train.columns[top5_idx]\n",
        "\n",
        "# Retrain on the stable features\n",
        "final_model = LogisticRegression(max_iter=5000).fit(X_train[feat_rl], y_train)\n",
        "accuracy    = accuracy_score(y_test, final_model.predict(X_test[feat_rl]))\n",
        "\n",
        "print(\"Stability features:\", list(feat_rl))\n",
        "print(\"Accuracy (Stability):\", accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GQ-ahzzfzM_Z",
        "outputId": "128ae152-56f2-4eec-fb4a-c6dec0dc6ed1"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Stability features: ['mean radius', 'mean texture', 'mean perimeter', 'mean area', 'mean concavity']\n",
            "Accuracy (Stability): 0.935672514619883\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "dt = DecisionTreeClassifier(max_depth=3, random_state=0)\n",
        "dt.fit(X_train, y_train)\n",
        "\n",
        "import numpy as np\n",
        "idx_dt = np.argsort(dt.feature_importances_)[-5:]\n",
        "feat_dt = X_train.columns[idx_dt]\n",
        "\n",
        "model = LogisticRegression(max_iter=5000).fit(X_train[feat_dt], y_train)\n",
        "print(\"DT features:\", list(feat_dt))\n",
        "print(\"Accuracy (DT):\", accuracy_score(y_test, model.predict(X_test[feat_dt])))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O14kHYmGzRDS",
        "outputId": "eb8e1693-10cf-447d-8a9b-6594fcc8c371"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DT features: ['worst perimeter', 'worst area', 'worst radius', 'worst texture', 'mean concave points']\n",
            "Accuracy (DT): 0.9707602339181286\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "tKpXy6YS0sxp"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}