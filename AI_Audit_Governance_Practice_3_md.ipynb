{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNoXU3brc0w2+a1GQ7iz/KY",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/appliedcode/mthree-c422/blob/mthree-c422-Likhitha/AI_Audit_Governance_Practice_3_md.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dByUPTq3fCUk"
      },
      "outputs": [],
      "source": [
        "!pip -q install shap scikit-learn pandas numpy matplotlib\n",
        "\n",
        "import json, datetime as dt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import shap\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.datasets import fetch_openml\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import (roc_auc_score, confusion_matrix, classification_report)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "adult = fetch_openml(name=\"adult\", version=2, as_frame=True)\n",
        "X = adult.data.copy()\n",
        "y = adult.target.map({\">50K\": 1, \"<=50K\": 0}).astype(int)\n",
        "\n",
        "print(\"Dataset shape:\", X.shape)\n",
        "print(\"Target distribution:\\n\", y.value_counts())\n",
        "\n",
        "# Protected attribute for fairness analysis\n",
        "PROTECTED_COL = \"sex\"   # Male / Female\n",
        "\n",
        "# Train/val split (stratify on y to keep class balance)\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.30, random_state=42, stratify=y\n",
        ")"
      ],
      "metadata": {
        "id": "yZM038PPfKeb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cat_cols = X.select_dtypes(include=[\"object\", \"category\"]).columns.tolist()\n",
        "num_cols = [c for c in X.columns if c not in cat_cols]\n",
        "\n",
        "# NOTE: scikit-learn >=1.2 replaced OneHotEncoder(sparse=...) with sparse_output=...\n",
        "# We set sparse_output=False so the pipeline returns a dense array (handy for SHAP).\n",
        "preproc = ColumnTransformer(\n",
        "    transformers=[\n",
        "        (\"cats\", Pipeline(steps=[\n",
        "            (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
        "            (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False))\n",
        "        ]), cat_cols),\n",
        "        (\"nums\", Pipeline(steps=[\n",
        "            (\"imputer\", SimpleImputer(strategy=\"median\"))\n",
        "        ]), num_cols),\n",
        "    ],\n",
        "    remainder=\"drop\",\n",
        ")\n",
        "\n",
        "clf = RandomForestClassifier(\n",
        "    n_estimators=400,\n",
        "    random_state=42,\n",
        "    n_jobs=-1,\n",
        "    class_weight=\"balanced_subsample\",\n",
        ")\n",
        "\n",
        "pipe = Pipeline(steps=[(\"prep\", preproc), (\"clf\", clf)])\n",
        "pipe.fit(X_train, y_train)\n",
        "\n",
        "y_prob = pipe.predict_proba(X_test)[:, 1]\n",
        "y_pred = (y_prob >= 0.5).astype(int)\n",
        "\n",
        "print(\"\\n=== Performance ===\")\n",
        "print(\"ROC-AUC:\", roc_auc_score(y_test, y_prob))\n",
        "print(\"Confusion matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
        "print(\"Classification report:\\n\", classification_report(y_test, y_pred))"
      ],
      "metadata": {
        "id": "r78aVLEofR3T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def demographic_parity(y_hat: np.ndarray, group: pd.Series):\n",
        "    \"\"\"Returns (DP difference, group positive rates dict).\"\"\"\n",
        "    rates = y_hat.groupby(group).mean() if isinstance(y_hat, pd.Series) else pd.Series(y_hat).groupby(group).mean()\n",
        "    return float(rates.max() - rates.min()), rates.to_dict()\n",
        "\n",
        "def equal_opportunity(y_true: np.ndarray, y_hat: np.ndarray, group: pd.Series):\n",
        "    \"\"\"TPR difference across groups and TPRs per group.\"\"\"\n",
        "    df = pd.DataFrame({\"y_true\": y_true, \"y_hat\": y_hat, \"group\": group.values})\n",
        "    tprs = {}\n",
        "    for g, sub in df.groupby(\"group\"):\n",
        "        # TPR = TP / (TP + FN) among the positives\n",
        "        pos = sub[sub.y_true == 1]\n",
        "        tpr = (pos.y_hat == 1).mean() if len(pos) > 0 else np.nan\n",
        "        tprs[g] = float(tpr if not np.isnan(tpr) else 0.0)\n",
        "    diff = max(tprs.values()) - min(tprs.values()) if tprs else 0.0\n",
        "    return float(diff), tprs\n",
        "\n",
        "def disparate_impact_ratio(y_hat: np.ndarray, group: pd.Series, privileged_value=\"Male\"):\n",
        "    \"\"\"min(rate)/max(rate) across groups (or unprivileged/privileged by label).\"\"\"\n",
        "    rates = y_hat.groupby(group).mean() if isinstance(y_hat, pd.Series) else pd.Series(y_hat).groupby(group).mean()\n",
        "    # General DI: min(rate)/max(rate)\n",
        "    di = float(rates.min() / rates.max()) if rates.max() > 0 else 0.0\n",
        "    return di, rates.to_dict()\n",
        "\n",
        "# Get the protected attribute aligned to test indices\n",
        "g_test = X_test[PROTECTED_COL].reset_index(drop=True)\n",
        "y_test_s = pd.Series(y_test).reset_index(drop=True)\n",
        "y_pred_s = pd.Series(y_pred).reset_index(drop=True)\n",
        "\n",
        "dp_diff, dp_rates = demographic_parity(y_pred_s, g_test)\n",
        "eo_diff, eo_tprs  = equal_opportunity(y_test_s, y_pred_s, g_test)\n",
        "di_ratio, di_rates = disparate_impact_ratio(y_pred_s, g_test)\n",
        "\n",
        "print(\"\\n=== Fairness (by sex) ===\")\n",
        "print(f\"Demographic Parity Difference: {dp_diff:.4f}\")\n",
        "print(f\"Equal Opportunity Difference : {eo_diff:.4f}\")\n",
        "print(f\"Disparate Impact Ratio       : {di_ratio:.4f}\")\n",
        "print(\"Group positive rates:\", dp_rates)\n",
        "print(\"Group TPRs:\", eo_tprs)\n",
        "\n",
        "# Policy thresholds (example values, adjust with Risk/Compliance)\n",
        "DP_BOUND = 0.10        # <= acceptable DP difference\n",
        "EO_BOUND = 0.10        # <= acceptable EO difference\n",
        "DI_LOWER_BOUND = 0.80  # >= acceptable DI ratio (80% rule)\n",
        "fairness_pass = (dp_diff <= DP_BOUND) and (eo_diff <= EO_BOUND) and (di_ratio >= DI_LOWER_BOUND)\n"
      ],
      "metadata": {
        "id": "kFs8isjXfZCs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_test_enc = pipe.named_steps[\"prep\"].transform(X_test)\n",
        "feature_names = pipe.named_steps[\"prep\"].get_feature_names_out()\n",
        "\n",
        "# Train a SHAP TreeExplainer on the fitted RandomForest\n",
        "explainer = shap.TreeExplainer(pipe.named_steps[\"clf\"])\n",
        "shap_values = explainer.shap_values(X_test_enc)\n",
        "\n",
        "# Handle possible SHAP return shapes across versions:\n",
        "# - Newer binary tree models: np.ndarray (n_samples, n_features)\n",
        "# - Older versions: list [neg, pos] → pick positive class\n",
        "if isinstance(shap_values, (list, tuple)):\n",
        "    shap_for_pos = shap_values[1] if len(shap_values) > 1 else shap_values[0]\n",
        "else:\n",
        "    shap_for_pos = shap_values\n",
        "\n",
        "# Sanity check\n",
        "if shap_for_pos.shape[1] != len(feature_names):\n",
        "    raise ValueError(\n",
        "        f\"SHAP feature length mismatch: shap_features={shap_for_pos.shape[1]} \"\n",
        "        f\"vs names={len(feature_names)}\"\n",
        "    )\n",
        "\n",
        "# Mean |SHAP| per feature\n",
        "mean_abs_shap = np.abs(shap_for_pos).mean(axis=0)\n",
        "top_idx = np.argsort(mean_abs_shap)[::-1][:20]\n",
        "top_features = pd.DataFrame({\n",
        "    \"feature\": np.array(feature_names)[top_idx],\n",
        "    \"mean_abs_shap\": mean_abs_shap[top_idx]\n",
        "})\n",
        "\n",
        "print(\"\\n=== Top features by mean |SHAP| ===\")\n",
        "print(top_features.to_string(index=False))\n",
        "\n",
        "# Plot summary bar (compact, stable in notebooks)\n",
        "print(\"\\nRendering SHAP summary bar plot...\")\n",
        "shap.summary_plot(shap_for_pos, features=X_test_enc, feature_names=feature_names,\n",
        "                  plot_type=\"bar\", show=True)\n"
      ],
      "metadata": {
        "id": "Xb8Iyu7Afe3c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X2_train = X_train.drop(columns=[PROTECTED_COL])\n",
        "X2_test  = X_test.drop(columns=[PROTECTED_COL])\n",
        "\n",
        "# Rebuild preprocessor for the new schema\n",
        "cat2 = X2_train.select_dtypes(include=[\"object\", \"category\"]).columns.tolist()\n",
        "num2 = [c for c in X2_train.columns if c not in cat2]\n",
        "\n",
        "preproc2 = ColumnTransformer(\n",
        "    transformers=[\n",
        "        (\"cats\", Pipeline(steps=[\n",
        "            (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
        "            (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False))\n",
        "        ]), cat2),\n",
        "        (\"nums\", Pipeline(steps=[\n",
        "            (\"imputer\", SimpleImputer(strategy=\"median\"))\n",
        "        ]), num2),\n",
        "    ]\n",
        ")\n",
        "\n",
        "pipe2 = Pipeline(steps=[(\"prep\", preproc2), (\"clf\", RandomForestClassifier(\n",
        "    n_estimators=400, random_state=42, n_jobs=-1, class_weight=\"balanced_subsample\"\n",
        "))])\n",
        "\n",
        "pipe2.fit(X2_train, y_train)\n",
        "y2_prob = pipe2.predict_proba(X2_test)[:, 1]\n",
        "y2_pred = (y2_prob >= 0.5).astype(int)\n",
        "\n",
        "# Fairness on the same protected attribute (taken from original X_test)\n",
        "dp2, _ = demographic_parity(pd.Series(y2_pred), g_test)\n",
        "eo2, _ = equal_opportunity(pd.Series(y_test).reset_index(drop=True), pd.Series(y2_pred), g_test)\n",
        "di2, _ = disparate_impact_ratio(pd.Series(y2_pred), g_test)\n",
        "\n",
        "print(\"\\n=== Sex-blind Variant (removed 'sex') ===\")\n",
        "print(\"ROC-AUC:\", roc_auc_score(y_test, y2_prob))\n",
        "print(f\"DP diff: {dp2:.4f}, EO diff: {eo2:.4f}, DI ratio: {di2:.4f}\")\n"
      ],
      "metadata": {
        "id": "_ZohTsZYfjnW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "audit_log = {\n",
        "    \"timestamp\": dt.datetime.utcnow().isoformat() + \"Z\",\n",
        "    \"dataset\": \"Adult (Census Income) — OpenML\",\n",
        "    \"protected_attribute\": PROTECTED_COL,\n",
        "    \"library_versions\": {\n",
        "        \"sklearn\": __import__(\"sklearn\").__version__,\n",
        "        \"pandas\": pd.__version__,\n",
        "        \"numpy\": np.__version__,\n",
        "        \"shap\": shap.__version__,\n",
        "    },\n",
        "    \"model\": {\n",
        "        \"family\": \"RandomForestClassifier\",\n",
        "        \"n_estimators\": 400,\n",
        "        \"class_weight\": \"balanced_subsample\",\n",
        "        \"random_state\": 42\n",
        "    },\n",
        "    \"performance\": {\n",
        "        \"roc_auc\": float(roc_auc_score(y_test, y_prob)),\n",
        "        \"confusion_matrix\": confusion_matrix(y_test, y_pred).tolist(),\n",
        "        \"classification_report\": classification_report(y_test, y_pred, output_dict=True),\n",
        "    },\n",
        "    \"fairness\": {\n",
        "        \"demographic_parity_difference\": float(dp_diff),\n",
        "        \"equal_opportunity_difference\": float(eo_diff),\n",
        "        \"disparate_impact_ratio\": float(di_ratio),\n",
        "        \"group_positive_rates\": dp_rates,\n",
        "        \"group_tprs\": eo_tprs,\n",
        "        \"policy_thresholds\": {\n",
        "            \"dp_max\": DP_BOUND,\n",
        "            \"eo_max\": EO_BOUND,\n",
        "            \"di_min\": DI_LOWER_BOUND\n",
        "        },\n",
        "        \"fairness_gate_pass\": bool(fairness_pass),\n",
        "    },\n",
        "    \"explainability\": {\n",
        "        \"top_features_by_mean_abs_shap\": top_features.to_dict(orient=\"records\")\n",
        "    },\n",
        "    \"mitigation_experiment\": {\n",
        "        \"sex_blind_variant\": {\n",
        "            \"roc_auc\": float(roc_auc_score(y_test, y2_prob)),\n",
        "            \"dp_diff\": float(dp2),\n",
        "            \"eo_diff\": float(eo2),\n",
        "            \"di_ratio\": float(di2),\n",
        "        }\n",
        "    }\n",
        "}\n",
        "\n",
        "print(\"\\n=== Audit Log (preview) ===\")\n",
        "print(json.dumps({\n",
        "    \"timestamp\": audit_log[\"timestamp\"],\n",
        "    \"performance\": {\"roc_auc\": audit_log[\"performance\"][\"roc_auc\"]},\n",
        "    \"fairness\": {\n",
        "        \"dp_diff\": audit_log[\"fairness\"][\"demographic_parity_difference\"],\n",
        "        \"eo_diff\": audit_log[\"fairness\"][\"equal_opportunity_difference\"],\n",
        "        \"di_ratio\": audit_log[\"fairness\"][\"disparate_impact_ratio\"],\n",
        "        \"fairness_gate_pass\": audit_log[\"fairness\"][\"fairness_gate_pass\"]\n",
        "    }\n",
        "}, indent=2))\n",
        "\n",
        "# Optional: persist to file (uncomment to save in Colab)\n",
        "# with open(\"adult_income_audit_log.json\", \"w\") as f:\n",
        "#     json.dump(audit_log, f, indent=2)\n",
        "\n",
        "report = f\"\"\"\n",
        "AI Governance & Compliance Report — Adult Income (>50K) Model\n",
        "\n",
        "Timestamp (UTC): {audit_log['timestamp']}\n",
        "Protected Attribute: {PROTECTED_COL}\n",
        "\n",
        "Performance:\n",
        "- ROC-AUC: {audit_log['performance']['roc_auc']:.3f}\n",
        "- Confusion Matrix: {audit_log['performance']['confusion_matrix']}\n",
        "\n",
        "Fairness:\n",
        "- Demographic Parity Difference: {audit_log['fairness']['demographic_parity_difference']:.3f} (<= {DP_BOUND} → {'PASS' if dp_diff <= DP_BOUND else 'FAIL'})\n",
        "- Equal Opportunity Difference : {audit_log['fairness']['equal_opportunity_difference']:.3f} (<= {EO_BOUND} → {'PASS' if eo_diff <= EO_BOUND else 'FAIL'})\n",
        "- Disparate Impact Ratio       : {audit_log['fairness']['disparate_impact_ratio']:.3f} (>= {DI_LOWER_BOUND} → {'PASS' if di_ratio >= DI_LOWER_BOUND else 'FAIL'})\n",
        "- Group Positive Rates         : {audit_log['fairness']['group_positive_rates']}\n",
        "- Group TPRs                   : {audit_log['fairness']['group_tprs']}\n",
        "- Overall Fairness Gate        : {'PASS' if fairness_pass else 'FAIL'}\n",
        "\n",
        "Explainability:\n",
        "- Top features by mean |SHAP| (top 10):\n",
        "{top_features.head(10).to_string(index=False)}\n",
        "\n",
        "Mitigation Experiment — sex-blind:\n",
        "- ROC-AUC: {audit_log['mitigation_experiment']['sex_blind_variant']['roc_auc']:.3f}\n",
        "- DP diff: {audit_log['mitigation_experiment']['sex_blind_variant']['dp_diff']:.3f}\n",
        "- EO diff: {audit_log['mitigation_experiment']['sex_blind_variant']['eo_diff']:.3f}\n",
        "- DI ratio: {audit_log['mitigation_experiment']['sex_blind_variant']['di_ratio']:.3f}\n",
        "\n",
        "Recommendations:\n",
        "1) Align fairness thresholds (DP/EO/DI) with your Risk & Compliance policy.\n",
        "2) If fairness gate fails, consider: (a) removing/regularizing sensitive or proxy features,\n",
        "   (b) reweighting or resampling to balance subgroups, (c) group-specific decision thresholds.\n",
        "3) Log this audit (metrics + SHAP evidence) to a model registry and schedule periodic re-audits.\n",
        "4) Publish a plain-language Model Card describing intended use, limits, and fairness findings.\n",
        "\"\"\"\n",
        "print(\"\\n\" + report)"
      ],
      "metadata": {
        "id": "NMTvQ37RfpPH"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}