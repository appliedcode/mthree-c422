{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/appliedcode/mthree-c422/blob/main/Exercises/day-6/Multiple_Sources/Multiple_demo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Practical Data Ingestion from Multiple Sources in Colab\n",
        "This lab is inspired by the image and will guide you through ingesting data from multiple sources **(CSV, JSON, REST API)**, cleaning and transforming the data, and producing a unified clean dataset using Python and pandas in Google Colab.\n",
        "\n",
        "Objectives\n",
        "- Ingest data from CSV, JSON, and REST API sources\n",
        "\n",
        "- Use a central “ingestion layer” (pandas) for data import\n",
        "\n",
        "- Apply cleaning and transformation steps modularly\n",
        "\n",
        "- Consolidate results into a single, unified output\n",
        "\n"
      ],
      "metadata": {
        "id": "RpsOG3v9XMxn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Set Up Environment\n",
        "!pip install pandas requests -q"
      ],
      "metadata": {
        "id": "dDQaHeWjk73I"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 2: Ingest Data from Multiple Sources\n",
        "# a. CSV File\n",
        "import pandas as pd\n",
        "\n",
        "csv_url = \"https://raw.githubusercontent.com/uiuc-cse/data-fa14/gh-pages/data/iris.csv\"\n",
        "df_csv = pd.read_csv(csv_url)\n",
        "print(\"CSV Data Sample:\")\n",
        "print(df_csv.head())\n",
        "\n",
        "# b. JSON File\n",
        "import json\n",
        "\n",
        "json_url = \"https://jsonplaceholder.typicode.com/users\"\n",
        "df_json = pd.read_json(json_url)\n",
        "print(\"\\nJSON Data Sample:\")\n",
        "print(df_json.head())\n",
        "\n",
        "#c. REST API\n",
        "import requests\n",
        "\n",
        "api_url = \"https://randomuser.me/api/?results=5\"\n",
        "response = requests.get(api_url)\n",
        "data = response.json()\n",
        "df_api = pd.json_normalize(data['results'])\n",
        "print(\"\\nREST API Data Sample:\")\n",
        "print(df_api.head())\n"
      ],
      "metadata": {
        "id": "1GR4c7Y4k_ny",
        "outputId": "c06a5fff-90c1-4a4e-bcc3-4a3bd6064e17",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CSV Data Sample:\n",
            "   sepal_length  sepal_width  petal_length  petal_width species\n",
            "0           5.1          3.5           1.4          0.2  setosa\n",
            "1           4.9          3.0           1.4          0.2  setosa\n",
            "2           4.7          3.2           1.3          0.2  setosa\n",
            "3           4.6          3.1           1.5          0.2  setosa\n",
            "4           5.0          3.6           1.4          0.2  setosa\n",
            "\n",
            "JSON Data Sample:\n",
            "   id              name   username                      email  \\\n",
            "0   1     Leanne Graham       Bret          Sincere@april.biz   \n",
            "1   2      Ervin Howell  Antonette          Shanna@melissa.tv   \n",
            "2   3  Clementine Bauch   Samantha         Nathan@yesenia.net   \n",
            "3   4  Patricia Lebsack   Karianne  Julianne.OConner@kory.org   \n",
            "4   5  Chelsey Dietrich     Kamren   Lucio_Hettinger@annie.ca   \n",
            "\n",
            "                                             address                  phone  \\\n",
            "0  {'street': 'Kulas Light', 'suite': 'Apt. 556',...  1-770-736-8031 x56442   \n",
            "1  {'street': 'Victor Plains', 'suite': 'Suite 87...    010-692-6593 x09125   \n",
            "2  {'street': 'Douglas Extension', 'suite': 'Suit...         1-463-123-4447   \n",
            "3  {'street': 'Hoeger Mall', 'suite': 'Apt. 692',...      493-170-9623 x156   \n",
            "4  {'street': 'Skiles Walks', 'suite': 'Suite 351...          (254)954-1289   \n",
            "\n",
            "         website                                            company  \n",
            "0  hildegard.org  {'name': 'Romaguera-Crona', 'catchPhrase': 'Mu...  \n",
            "1  anastasia.net  {'name': 'Deckow-Crist', 'catchPhrase': 'Proac...  \n",
            "2    ramiro.info  {'name': 'Romaguera-Jacobson', 'catchPhrase': ...  \n",
            "3       kale.biz  {'name': 'Robel-Corkery', 'catchPhrase': 'Mult...  \n",
            "4   demarco.info  {'name': 'Keebler LLC', 'catchPhrase': 'User-c...  \n",
            "\n",
            "REST API Data Sample:\n",
            "   gender                       email           phone            cell nat  \\\n",
            "0  female     venla.koski@example.com      02-443-271   048-116-02-69  FI   \n",
            "1    male     emil.ketola@example.com      04-649-387   045-142-84-56  FI   \n",
            "2  female   fatma.demirel@example.com  (729)-262-4996  (286)-807-5700  TR   \n",
            "3  female        lea.klop@example.com   (058) 6665221   (06) 22322373  NL   \n",
            "4    male  asher.williams@example.com  (101)-560-5202  (726)-763-3918  NZ   \n",
            "\n",
            "  name.title name.first name.last  location.street.number  \\\n",
            "0        Mrs      Venla     Koski                    9790   \n",
            "1         Mr       Emil    Ketola                    6823   \n",
            "2         Ms      Fatma   Demirel                      48   \n",
            "3       Miss        Lea      Klop                    6881   \n",
            "4         Mr      Asher  Williams                    3148   \n",
            "\n",
            "  location.street.name  ...  \\\n",
            "0       Mechelininkatu  ...   \n",
            "1          Tehtaankatu  ...   \n",
            "2     Talak Göktepe Cd  ...   \n",
            "3          Binnenvaert  ...   \n",
            "4     Main Street East  ...   \n",
            "\n",
            "                                        login.sha256  \\\n",
            "0  9c087c16e5953df8e84681e7f7a0e4e0fb0689489c122f...   \n",
            "1  5f895dd9c0fd1d07fce461539004eaa59f5f1f2e4da404...   \n",
            "2  1c77c46dd6e8694a807272fdcbb213f1d8e23653551c0d...   \n",
            "3  928555fcfc86f8d2ebca7d72b67646eadf952bd14e39fa...   \n",
            "4  35ad86ce036f148c564fe7374974bb3903c107b6860739...   \n",
            "\n",
            "                   dob.date dob.age           registered.date registered.age  \\\n",
            "0  1950-07-14T11:02:34.541Z      75  2009-12-04T03:33:09.922Z             15   \n",
            "1  1958-08-24T02:33:41.182Z      66  2017-12-19T07:23:00.190Z              7   \n",
            "2  1963-05-02T11:45:07.912Z      62  2011-10-11T08:38:38.634Z             13   \n",
            "3  1960-03-06T13:15:12.043Z      65  2015-09-05T08:19:05.144Z              9   \n",
            "4  1980-03-05T18:34:57.020Z      45  2012-06-18T17:09:50.466Z             13   \n",
            "\n",
            "  id.name           id.value  \\\n",
            "0    HETU  NaNNA790undefined   \n",
            "1    HETU  NaNNA437undefined   \n",
            "2                       None   \n",
            "3     BSN           43253715   \n",
            "4                       None   \n",
            "\n",
            "                                      picture.large  \\\n",
            "0   https://randomuser.me/api/portraits/women/9.jpg   \n",
            "1     https://randomuser.me/api/portraits/men/3.jpg   \n",
            "2   https://randomuser.me/api/portraits/women/7.jpg   \n",
            "3  https://randomuser.me/api/portraits/women/42.jpg   \n",
            "4     https://randomuser.me/api/portraits/men/3.jpg   \n",
            "\n",
            "                                      picture.medium  \\\n",
            "0  https://randomuser.me/api/portraits/med/women/...   \n",
            "1  https://randomuser.me/api/portraits/med/men/3.jpg   \n",
            "2  https://randomuser.me/api/portraits/med/women/...   \n",
            "3  https://randomuser.me/api/portraits/med/women/...   \n",
            "4  https://randomuser.me/api/portraits/med/men/3.jpg   \n",
            "\n",
            "                                   picture.thumbnail  \n",
            "0  https://randomuser.me/api/portraits/thumb/wome...  \n",
            "1  https://randomuser.me/api/portraits/thumb/men/...  \n",
            "2  https://randomuser.me/api/portraits/thumb/wome...  \n",
            "3  https://randomuser.me/api/portraits/thumb/wome...  \n",
            "4  https://randomuser.me/api/portraits/thumb/men/...  \n",
            "\n",
            "[5 rows x 34 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 3: Modular Cleaning/Transformation\n",
        "# Example: Clean and select specific columns from each\n",
        "\n",
        "# For CSV (Iris), let's only keep numeric columns and rename\n",
        "df_csv_clean = df_csv.rename(columns={'species':'source'}).dropna()\n",
        "\n",
        "# For JSON (User info), select name and email\n",
        "df_json_clean = df_json[['name', 'email']].copy()\n",
        "df_json_clean['source'] = 'json'\n",
        "\n",
        "# For API data (Random users), grab first/last name, email\n",
        "df_api_clean = pd.DataFrame()\n",
        "df_api_clean['name'] = df_api['name.first'] + \" \" + df_api['name.last']\n",
        "df_api_clean['email'] = df_api['email']\n",
        "df_api_clean['source'] = 'api'\n"
      ],
      "metadata": {
        "id": "MBtYPeyxlIti"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 4: Prepare each cleaned DataFrame with identical columns\n",
        "\n",
        "common_cols = ['name', 'email', 'source',\n",
        "               'sepal_length', 'sepal_width', 'petal_length', 'petal_width']\n",
        "\n",
        "# CSV (Iris) — rename species to name, add missing columns\n",
        "df_csv_clean = df_csv.rename(columns={'species': 'name'})\n",
        "df_csv_clean['email'] = None\n",
        "df_csv_clean['source'] = 'csv'\n",
        "for col in ['sepal_length','sepal_width','petal_length','petal_width']:\n",
        "    # numeric columns already exist\n",
        "    pass\n",
        "\n",
        "# JSON (Users) — add placeholder iris columns\n",
        "df_json_clean = df_json[['name','email']].copy()\n",
        "df_json_clean['source'] = 'json'\n",
        "for col in ['sepal_length','sepal_width','petal_length','petal_width']:\n",
        "    df_json_clean[col] = None\n",
        "\n",
        "# API (Random Users) — add placeholder iris columns\n",
        "df_api_clean = pd.DataFrame({\n",
        "    'name': df_api['name.first'] + ' ' + df_api['name.last'],\n",
        "    'email': df_api['email'],\n",
        "    'source': 'api'\n",
        "})\n",
        "for col in ['sepal_length','sepal_width','petal_length','petal_width']:\n",
        "    df_api_clean[col] = None\n",
        "\n",
        "# Step 5: Concatenate into unified DataFrame\n",
        "unified_df = pd.concat([\n",
        "    df_csv_clean[common_cols],\n",
        "    df_json_clean[common_cols],\n",
        "    df_api_clean[common_cols]\n",
        "], ignore_index=True)\n",
        "\n",
        "print(\"\\nUnified Clean Dataset Sample:\")\n",
        "print(unified_df.head(10))\n"
      ],
      "metadata": {
        "id": "pfcxyfiklLtx",
        "outputId": "57de5db2-fbff-4ad8-d276-e27a5f5b20df",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Unified Clean Dataset Sample:\n",
            "     name email source  sepal_length  sepal_width  petal_length  petal_width\n",
            "0  setosa  None    csv           5.1          3.5           1.4          0.2\n",
            "1  setosa  None    csv           4.9          3.0           1.4          0.2\n",
            "2  setosa  None    csv           4.7          3.2           1.3          0.2\n",
            "3  setosa  None    csv           4.6          3.1           1.5          0.2\n",
            "4  setosa  None    csv           5.0          3.6           1.4          0.2\n",
            "5  setosa  None    csv           5.4          3.9           1.7          0.4\n",
            "6  setosa  None    csv           4.6          3.4           1.4          0.3\n",
            "7  setosa  None    csv           5.0          3.4           1.5          0.2\n",
            "8  setosa  None    csv           4.4          2.9           1.4          0.2\n",
            "9  setosa  None    csv           4.9          3.1           1.5          0.1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-1068823431.py:30: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
            "  unified_df = pd.concat([\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 5: Reflection\n",
        "- Identify which steps required the most standardization.\n",
        "\n",
        "- What common problems occur when merging data of different shapes and sources?\n",
        "\n",
        "- Why is a central ingestion and transformation layer important for reliability and scalability?"
      ],
      "metadata": {
        "id": "bot06-lplNtZ"
      }
    }
  ],
  "metadata": {
    "colab": {
      "name": "Welcome to Colab",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}