{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/appliedcode/mthree-c422/blob/main/Exercises/day-6/practice.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RpsOG3v9XMxn"
      },
      "source": [
        "# ETL Lab Exercise: Global Earthquake Data Analysis\n",
        "\n",
        "## Problem Statement\n",
        "\n",
        "In this lab, you will build a complete ETL (Extract-Transform-Load) pipeline in Google Colab using publicly available global earthquake data from the US Geological Survey (USGS).\n",
        "\n",
        "---\n",
        "\n",
        "## Tasks\n",
        "\n",
        "### 1. Extract\n",
        "- **Download:**  \n",
        "  Download the latest global earthquake data directly from the USGS public API or their CSV archive.  \n",
        "  - Example URL (last 30 days earthquake data):  \n",
        "    https://earthquake.usgs.gov/earthquakes/feed/v1.0/summary/all_month.csv\n",
        "- **Load:**  \n",
        "  Load the CSV file into a pandas DataFrame.\n",
        "\n",
        "### 2. Transform\n",
        "- **Clean:**  \n",
        "  - Handle missing or inconsistent data entries.\n",
        "  - Rename columns for clarity if necessary.\n",
        "- **Feature Engineering:**  \n",
        "  - Create a new column `DepthCategory` classifying earthquake depth as \"Shallow\" (<70 km), \"Intermediate\" (70-300 km), or \"Deep\" (>300 km).\n",
        "  - Calculate time-based features such as extracting the month and weekday from the timestamp.\n",
        "  - Filter earthquakes by magnitude threshold (e.g., magnitude ≥ 4.0).\n",
        "\n",
        "### 3. Load\n",
        "- **Local Storage:**  \n",
        "  Store the transformed DataFrame into a local SQLite database inside Colab.\n",
        "- **Query & Analyze:**  \n",
        "  - Write SQL queries to:\n",
        "    - Find the number of earthquakes per depth category.\n",
        "    - List the top 5 strongest earthquakes in the last 30 days.\n",
        "    - Find average magnitude by weekday.\n",
        "\n",
        "---\n",
        "\n",
        "## Constraints\n",
        "\n",
        "- Perform the entire ETL process only with pandas, SQLite, and standard Python within Google Colab.\n",
        "- Do not use any external databases or proprietary cloud services.\n",
        "\n",
        "---\n",
        "\n",
        "## Dataset Details\n",
        "\n",
        "- **Dataset:** Global earthquakes, last 30 days  \n",
        "- **Source URL:** [USGS Earthquake Data - All Month CSV](https://earthquake.usgs.gov/earthquakes/feed/v1.0/summary/all_month.csv)\n",
        "\n",
        "---\n",
        "\n",
        "## Example Challenge Questions\n",
        "\n",
        "- Which depth category experiences the most earthquakes?\n",
        "- On which weekday do the strongest earthquakes most frequently occur?\n",
        "- What is the distribution of earthquake magnitudes in your filtered data?\n",
        "\n",
        "---\n",
        "\n",
        "**Expected Outcome:**  \n",
        "You will gain practical ETL experience on a real-world geoscience dataset, including downloading live data, cleaning and feature engineering, and storing/querying the results locally—all within a Colab notebook.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WI2MFwO5Q76F"
      },
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "include_colab_link": true,
      "name": "Welcome to Colab",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
