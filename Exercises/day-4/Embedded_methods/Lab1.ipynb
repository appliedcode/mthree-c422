{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMfJAjJbGBwgL+yApU9xiSz",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/appliedcode/mthree-c422/blob/main/Exercises/day-4/Embedded_methods/Lab1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "Je1rSo0GgiJ0",
        "outputId": "338bd68c-3dc3-49e1-aafd-2c5cdac5a094",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['mean radius',\n",
              " 'mean texture',\n",
              " 'mean perimeter',\n",
              " 'mean area',\n",
              " 'mean smoothness',\n",
              " 'mean compactness',\n",
              " 'mean concavity',\n",
              " 'mean concave points',\n",
              " 'mean symmetry',\n",
              " 'mean fractal dimension',\n",
              " 'radius error',\n",
              " 'texture error',\n",
              " 'perimeter error',\n",
              " 'area error',\n",
              " 'smoothness error',\n",
              " 'compactness error',\n",
              " 'concavity error',\n",
              " 'concave points error',\n",
              " 'symmetry error',\n",
              " 'fractal dimension error',\n",
              " 'worst radius',\n",
              " 'worst texture',\n",
              " 'worst perimeter',\n",
              " 'worst area',\n",
              " 'worst smoothness',\n",
              " 'worst compactness',\n",
              " 'worst concavity',\n",
              " 'worst concave points',\n",
              " 'worst symmetry',\n",
              " 'worst fractal dimension']"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "# Lab Exercises: Embedded Feature‐Selection Methods\n",
        "# Use the Breast Cancer dataset (sklearn.datasets.load_breast_cancer) for all exercises. Split once into training and test sets:\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X, y = load_breast_cancer(return_X_y=True, as_frame=True)\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.3, random_state=42\n",
        ")\n",
        "X.columns.tolist()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Exercise 1: L1-Regularized Logistic Regression\n",
        "- Fit LogisticRegression(penalty='l1', solver='saga', C=1.0, max_iter=5000).\n",
        "\n",
        "- Use SelectFromModel (prefit) to select the 5 features with nonzero coefficients.\n",
        "\n",
        "- Retrain a vanilla logistic model on those features.\n",
        "\n",
        "- Report selected features and test accuracy."
      ],
      "metadata": {
        "id": "rbDBckzBgvE9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.feature_selection import SelectFromModel\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "model_l1 = LogisticRegression(penalty='l1', solver='saga', C=1.0, max_iter=5000)\n",
        "model_l1.fit(X_train, y_train)\n",
        "\n",
        "sfm_l1 = SelectFromModel(model_l1, prefit=True, max_features=5)\n",
        "feat_l1 = X_train.columns[sfm_l1.get_support()]\n",
        "\n",
        "model = LogisticRegression(max_iter=5000).fit(X_train[feat_l1], y_train)\n",
        "print(\"L1 features:\", list(feat_l1))\n",
        "print(\"Accuracy (L1):\", accuracy_score(y_test, model.predict(X_test[feat_l1])))\n"
      ],
      "metadata": {
        "id": "mJ9vGlC-gqTu",
        "outputId": "9a610247-7034-4487-d674-24ba62252c80",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "L1 features: ['mean perimeter', 'area error', 'worst radius', 'worst perimeter', 'worst area']\n",
            "Accuracy (L1): 0.9590643274853801\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Exercise 2: L2-Regularization with Thresholding\n",
        "- Fit LogisticRegression(penalty='l2', C=1.0, max_iter=5000).\n",
        "\n",
        "- Extract absolute coefficients, select the 5 largest.\n",
        "\n",
        "- Retrain and evaluate on those features."
      ],
      "metadata": {
        "id": "LrQIwB2Kg4BT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "model_l2 = LogisticRegression(penalty='l2', C=1.0, max_iter=5000)\n",
        "model_l2.fit(X_train, y_train)\n",
        "\n",
        "abs_coefs = np.abs(model_l2.coef_)[0]\n",
        "idx = np.argsort(abs_coefs)[-5:]\n",
        "feat_l2 = X_train.columns[idx]\n",
        "\n",
        "model = LogisticRegression(max_iter=5000).fit(X_train[feat_l2], y_train)\n",
        "print(\"L2 features:\", list(feat_l2))\n",
        "print(\"Accuracy (L2):\", accuracy_score(y_test, model.predict(X_test[feat_l2])))\n"
      ],
      "metadata": {
        "id": "UtHlhNfgg0_N",
        "outputId": "f07c4ea7-7e59-4cde-869a-6998ed3eb70f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "L2 features: ['worst symmetry', 'worst compactness', 'mean radius', 'worst concavity', 'texture error']\n",
            "Accuracy (L2): 0.9532163742690059\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Exercise 3: Elastic Net Regularization\n",
        "- Standardize data with StandardScaler.\n",
        "\n",
        "- Fit ElasticNetCV(l1_ratio=[.1, .5, .9], cv=5).\n",
        "\n",
        "- Use SelectFromModel to pick the 5 nonzero–coefficient features.\n",
        "\n",
        "- Retrain and evaluate."
      ],
      "metadata": {
        "id": "q9Ihd18WhEoF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import ElasticNetCV, LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# 1. Standardize the data\n",
        "scaler = StandardScaler().fit(X_train)\n",
        "X_tr_s = scaler.transform(X_train)\n",
        "X_ts_s = scaler.transform(X_test)\n",
        "\n",
        "# 2. Fit ElasticNetCV with increased iterations\n",
        "enet = ElasticNetCV(\n",
        "    l1_ratio=[.1, .5, .9],\n",
        "    cv=5,\n",
        "    max_iter=10000,\n",
        "    tol=1e-4,\n",
        "    random_state=0\n",
        ")\n",
        "enet.fit(X_tr_s, y_train)\n",
        "\n",
        "# 3. Manually select the 5 nonzero coefficients with largest magnitude\n",
        "coefs = enet.coef_  # shape (n_features,)\n",
        "# Zero out truly zero (or near-zero) coefficients first\n",
        "nonzero_idxs = np.where(np.abs(coefs) > 1e-8)[0]\n",
        "# Sort those by absolute value descending\n",
        "sorted_nonzero = nonzero_idxs[np.argsort(-np.abs(coefs[nonzero_idxs]))]\n",
        "top5_idxs = sorted_nonzero[:5]\n",
        "\n",
        "feat_enet = X_train.columns[top5_idxs]\n",
        "\n",
        "# 4. Retrain Logistic Regression on selected features\n",
        "model = LogisticRegression(max_iter=5000).fit(\n",
        "    X_tr_s[:, top5_idxs],\n",
        "    y_train\n",
        ")\n",
        "\n",
        "# 5. Evaluate on test data\n",
        "accuracy = accuracy_score(\n",
        "    y_test,\n",
        "    model.predict(X_ts_s[:, top5_idxs])\n",
        ")\n",
        "\n",
        "print(\"Elastic Net features:\", list(feat_enet))\n",
        "print(\"Accuracy (ElasticNet):\", accuracy)\n",
        "\n"
      ],
      "metadata": {
        "id": "2CfDVtaZg-2R",
        "outputId": "e8f2b43b-a610-4d8c-bbcd-d0aa1679db1b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Elastic Net features: ['worst radius', 'worst area', 'mean concave points', 'mean compactness', 'radius error']\n",
            "Accuracy (ElasticNet): 0.9415204678362573\n"
          ]
        }
      ]
    }
  ]
}