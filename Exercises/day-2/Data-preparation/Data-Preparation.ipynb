{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4815d1a5",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Data Preparation and Pre-processing Lab Exercises\n",
    "---\n",
    "\n",
    "## Exercise 1: Titanic Data — Data Loading & Inspection\n",
    "\n",
    "**Objective:** Load a public dataset and inspect its structure.\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Load Titanic dataset\n",
    "url = \"https://raw.githubusercontent.com/datasciencedojo/datasets/master/titanic.csv\"\n",
    "df = pd.read_csv(url)\n",
    "\n",
    "# Preview and inspect\n",
    "print(df.head())\n",
    "print(df.dtypes)\n",
    "print(df.isnull().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66cdf022",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "---\n",
    "\n",
    "## Exercise 2: Titanic Data — Simple EDA\n",
    "\n",
    "**Objective:** Visualize distributions of key features.\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Histogram of passenger ages\n",
    "plt.hist(df['Age'].dropna(), bins=30)\n",
    "plt.title('Age Distribution')\n",
    "plt.xlabel('Age')\n",
    "plt.ylabel('Count')\n",
    "plt.show()\n",
    "\n",
    "# Bar chart of embarked locations\n",
    "df['Embarked'].value_counts().plot(kind='bar')\n",
    "plt.title('Embarked Value Counts')\n",
    "plt.xlabel('Port')\n",
    "plt.ylabel('Count')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb520794",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "---\n",
    "\n",
    "## Exercise 3: Bike Sharing — Data Loading & Preview\n",
    "\n",
    "**Objective:** Work with a zipped dataset, extract and load.\n",
    "\n",
    "import pandas as pd, zipfile, io, urllib.request\n",
    "\n",
    "# Download and read day.csv from bike-sharing ZIP\n",
    "zip_url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/00275/Bike-Sharing-Dataset.zip\"\n",
    "resp = urllib.request.urlopen(zip_url)\n",
    "z = zipfile.ZipFile(io.BytesIO(resp.read()))\n",
    "df_day = pd.read_csv(z.open(\"day.csv\"))\n",
    "\n",
    "print(df_day.head())\n",
    "print(df_day.describe())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bccdd4d",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "---\n",
    "\n",
    "## Exercise 4: Bike Sharing — Scatter Plot & Correlation\n",
    "\n",
    "**Objective:** Explore relationship between temperature and rentals.\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Scatter plot\n",
    "sns.scatterplot(x='temp', y='cnt', data=df_day, alpha=0.5)\n",
    "plt.title('Normalized Temperature vs. Total Rentals')\n",
    "plt.show()\n",
    "\n",
    "# Correlation heatmap for numeric features\n",
    "sns.heatmap(df_day.select_dtypes('number').corr(), annot=True, fmt='.2f', cmap='coolwarm')\n",
    "plt.title('Feature Correlation Matrix')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce02b013",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "---\n",
    "\n",
    "## Exercise 5: Linear Regression — Sales Prediction\n",
    "\n",
    "**Objective:** Build a regression model on synthetic sales data.\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Generate synthetic data\n",
    "np.random.seed(0)\n",
    "X = np.random.rand(100,1) * 100\n",
    "y = 5 + 2 * X.flatten() + np.random.randn(100)*10\n",
    "df_sales = pd.DataFrame({'AdSpend':X.flatten(), 'Sales':y})\n",
    "\n",
    "# Train/test split\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Fit model\n",
    "model = LinearRegression().fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "print(\"RMSE:\", mean_squared_error(y_test, y_pred, squared=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9f70591",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "---\n",
    "\n",
    "## Exercise 6: Classification — Predicting Survival\n",
    "\n",
    "**Objective:** Build a classifier on Titanic data.\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Prepare data\n",
    "df_clf = df.dropna(subset=['Age','Embarked'])\n",
    "X = pd.get_dummies(df_clf[['Pclass','Sex','Age','Embarked']], drop_first=True)\n",
    "y = df_clf['Survived']\n",
    "\n",
    "# Train/test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "\n",
    "# Train and evaluate\n",
    "clf = RandomForestClassifier(random_state=0).fit(X_train, y_train)\n",
    "print(classification_report(y_test, clf.predict(X_test)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b2355c4",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "---\n",
    "\n",
    "## Exercise 7: Time Series — ARIMA Forecasting\n",
    "\n",
    "**Objective:** Fit an ARIMA model on daily bike rentals.\n",
    "\n",
    "import pandas as pd\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "# Prepare series\n",
    "ts = df_day.set_index('dteday')['cnt']\n",
    "train, test = ts[:300], ts[300:]\n",
    "\n",
    "# Fit ARIMA\n",
    "model = ARIMA(train, order=(2,1,2)).fit()\n",
    "forecast = model.predict(start=test.index[0], end=test.index[-1])\n",
    "\n",
    "# Evaluate\n",
    "print(\"MAE:\", mean_absolute_error(test, forecast))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1b88315",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "---\n",
    "\n",
    "## Exercise 8: Clustering — Customer Segmentation\n",
    "\n",
    "**Objective:** Perform K-Means clustering on synthetic customer data.\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.cluster import KMeans\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Synthetic data\n",
    "np.random.seed(0)\n",
    "data = np.vstack([np.random.normal(loc=(i*5,i*5), scale=1, size=(50,2)) for i in range(3)])\n",
    "df_cust = pd.DataFrame(data, columns=['Feature1','Feature2'])\n",
    "\n",
    "# K-Means\n",
    "kmeans = KMeans(n_clusters=3, random_state=0).fit(df_cust)\n",
    "df_cust['Cluster'] = kmeans.labels_\n",
    "\n",
    "# Plot clusters\n",
    "plt.scatter(df_cust['Feature1'], df_cust['Feature2'], c=df_cust['Cluster'], cmap='tab10')\n",
    "plt.title('K-Means Clustering (k=3)')\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
