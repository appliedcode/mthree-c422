{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "619835ad",
   "metadata": {},
   "source": [
    "# Session 9: BERT Fine-tuning and Classification Tasks\n",
    "\n",
    "## üìö Learning Objectives\n",
    "By the end of this session, you will be able to:\n",
    "- Understand BERT architecture and pre-training objectives\n",
    "- Fine-tune BERT for text classification tasks\n",
    "- Implement custom datasets and data loaders\n",
    "- Apply transfer learning principles to NLP\n",
    "- Evaluate fine-tuned models and interpret results\n",
    "- Optimize training parameters and avoid overfitting\n",
    "\n",
    "## üéØ Session Overview\n",
    "1. **BERT Deep Dive** - Architecture, pre-training, and variants\n",
    "2. **Fine-tuning Setup** - Data preparation and model configuration\n",
    "3. **Classification Tasks** - Sentiment analysis and text classification\n",
    "4. **Training Pipeline** - Loss functions, optimizers, and training loops\n",
    "5. **Model Evaluation** - Metrics, validation, and error analysis\n",
    "6. **Advanced Techniques** - Learning rate scheduling and regularization\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0957453",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Required imports for BERT fine-tuning\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "# Transformers and datasets\n",
    "try:\n",
    "    from transformers import (\n",
    "        BertTokenizer, BertForSequenceClassification,\n",
    "        AdamW, get_linear_schedule_with_warmup,\n",
    "        TrainingArguments, Trainer\n",
    "    )\n",
    "    transformers_available = True\n",
    "    print(\"‚úÖ Transformers library loaded successfully\")\n",
    "except ImportError:\n",
    "    transformers_available = False\n",
    "    print(\"‚ùå Transformers library not available\")\n",
    "\n",
    "try:\n",
    "    from datasets import Dataset as HFDataset\n",
    "    datasets_available = True\n",
    "    print(\"‚úÖ Datasets library available\")\n",
    "except ImportError:\n",
    "    datasets_available = False\n",
    "    print(\"‚ùå Datasets library not available\")\n",
    "\n",
    "# Set device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"üîß Using device: {device}\")\n",
    "\n",
    "# Set random seeds\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "print(\"üì¶ Setup completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61dacbe4",
   "metadata": {},
   "source": [
    "## Section 1: Understanding BERT Architecture\n",
    "\n",
    "### 1.1 BERT Key Concepts\n",
    "\n",
    "**Pre-training Objectives:**\n",
    "1. **Masked Language Modeling (MLM)**: Predict masked tokens\n",
    "2. **Next Sentence Prediction (NSP)**: Determine if two sentences are consecutive\n",
    "\n",
    "**Architecture Features:**\n",
    "- **Bidirectional**: Processes text in both directions\n",
    "- **Transformer Encoder**: Stack of 12 (base) or 24 (large) layers\n",
    "- **Multi-Head Attention**: 12 (base) or 16 (large) attention heads\n",
    "- **Hidden Size**: 768 (base) or 1024 (large) dimensions\n",
    "\n",
    "### 1.2 Fine-tuning Approach\n",
    "- Add task-specific layers on top of BERT\n",
    "- Fine-tune all parameters end-to-end\n",
    "- Use lower learning rates than pre-training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46159c55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom Dataset Class for Text Classification\n",
    "\n",
    "class TextClassificationDataset(Dataset):\n",
    "    \"\"\"Custom dataset for text classification with BERT\"\"\"\n",
    "    \n",
    "    def __init__(self, texts, labels, tokenizer, max_length=128):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        text = str(self.texts[idx])\n",
    "        label = self.labels[idx]\n",
    "        \n",
    "        # Tokenize text\n",
    "        encoding = self.tokenizer(\n",
    "            text,\n",
    "            truncation=True,\n",
    "            padding='max_length',\n",
    "            max_length=self.max_length,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        \n",
    "        return {\n",
    "            'input_ids': encoding['input_ids'].flatten(),\n",
    "            'attention_mask': encoding['attention_mask'].flatten(),\n",
    "            'labels': torch.tensor(label, dtype=torch.long)\n",
    "        }\n",
    "\n",
    "def create_sample_dataset():\n",
    "    \"\"\"Create a sample sentiment analysis dataset\"\"\"\n",
    "    \n",
    "    # Sample data for sentiment classification\n",
    "    sample_data = [\n",
    "        (\"I love this product! It's amazing.\", 1),  # Positive\n",
    "        (\"This is the worst experience ever.\", 0),  # Negative\n",
    "        (\"Great quality and fast delivery.\", 1),    # Positive\n",
    "        (\"Terrible customer service.\", 0),          # Negative\n",
    "        (\"Absolutely fantastic! Highly recommend.\", 1),  # Positive\n",
    "        (\"Poor quality, not worth the money.\", 0),  # Negative\n",
    "        (\"Excellent features and easy to use.\", 1), # Positive\n",
    "        (\"Disappointing and overpriced.\", 0),       # Negative\n",
    "        (\"Outstanding performance and design.\", 1), # Positive\n",
    "        (\"Completely broken upon arrival.\", 0),     # Negative\n",
    "        (\"This product exceeded my expectations.\", 1),  # Positive\n",
    "        (\"Not what I ordered, very frustrated.\", 0),    # Negative\n",
    "        (\"Perfect for my needs, very satisfied.\", 1),   # Positive\n",
    "        (\"Waste of money, would not recommend.\", 0),    # Negative\n",
    "        (\"Impressive build quality and features.\", 1),  # Positive\n",
    "        (\"Cheaply made and unreliable.\", 0),            # Negative\n",
    "        (\"Best purchase I've made this year.\", 1),      # Positive\n",
    "        (\"Returned it immediately, poor quality.\", 0),  # Negative\n",
    "        (\"Works perfectly, exactly as described.\", 1),  # Positive\n",
    "        (\"Defective product, very disappointing.\", 0),  # Negative\n",
    "    ]\n",
    "    \n",
    "    texts, labels = zip(*sample_data)\n",
    "    return list(texts), list(labels)\n",
    "\n",
    "def prepare_data_loaders(texts, labels, tokenizer, test_size=0.2, batch_size=8):\n",
    "    \"\"\"Prepare train and test data loaders\"\"\"\n",
    "    \n",
    "    # Split data\n",
    "    train_texts, test_texts, train_labels, test_labels = train_test_split(\n",
    "        texts, labels, test_size=test_size, random_state=42, stratify=labels\n",
    "    )\n",
    "    \n",
    "    print(f\"Training samples: {len(train_texts)}\")\n",
    "    print(f\"Testing samples: {len(test_texts)}\")\n",
    "    \n",
    "    # Create datasets\n",
    "    train_dataset = TextClassificationDataset(train_texts, train_labels, tokenizer)\n",
    "    test_dataset = TextClassificationDataset(test_texts, test_labels, tokenizer)\n",
    "    \n",
    "    # Create data loaders\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "    \n",
    "    return train_loader, test_loader, train_dataset, test_dataset\n",
    "\n",
    "# Training function for BERT fine-tuning\n",
    "def train_bert_model(model, train_loader, test_loader, num_epochs=3, learning_rate=2e-5):\n",
    "    \"\"\"Train BERT model for classification\"\"\"\n",
    "    \n",
    "    # Setup optimizer and scheduler\n",
    "    optimizer = AdamW(model.parameters(), lr=learning_rate)\n",
    "    \n",
    "    total_steps = len(train_loader) * num_epochs\n",
    "    scheduler = get_linear_schedule_with_warmup(\n",
    "        optimizer,\n",
    "        num_warmup_steps=0,\n",
    "        num_training_steps=total_steps\n",
    "    )\n",
    "    \n",
    "    # Training history\n",
    "    train_losses = []\n",
    "    train_accuracies = []\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        total_loss = 0\n",
    "        correct_predictions = 0\n",
    "        total_predictions = 0\n",
    "        \n",
    "        print(f\"\\\\nEpoch {epoch + 1}/{num_epochs}\")\n",
    "        print(\"-\" * 30)\n",
    "        \n",
    "        for batch_idx, batch in enumerate(train_loader):\n",
    "            # Move batch to device\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "            \n",
    "            # Forward pass\n",
    "            outputs = model(\n",
    "                input_ids=input_ids,\n",
    "                attention_mask=attention_mask,\n",
    "                labels=labels\n",
    "            )\n",
    "            \n",
    "            loss = outputs.loss\n",
    "            logits = outputs.logits\n",
    "            \n",
    "            # Backward pass\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "            \n",
    "            # Calculate accuracy\n",
    "            predictions = torch.argmax(logits, dim=1)\n",
    "            correct_predictions += (predictions == labels).sum().item()\n",
    "            total_predictions += labels.size(0)\n",
    "            total_loss += loss.item()\n",
    "            \n",
    "            if batch_idx % 2 == 0:  # Print every 2 batches\n",
    "                print(f\"  Batch {batch_idx}/{len(train_loader)}, Loss: {loss.item():.4f}\")\n",
    "        \n",
    "        # Calculate epoch metrics\n",
    "        avg_loss = total_loss / len(train_loader)\n",
    "        accuracy = correct_predictions / total_predictions\n",
    "        \n",
    "        train_losses.append(avg_loss)\n",
    "        train_accuracies.append(accuracy)\n",
    "        \n",
    "        print(f\"  Avg Loss: {avg_loss:.4f}, Accuracy: {accuracy:.4f}\")\n",
    "        \n",
    "        # Evaluate on test set\n",
    "        test_accuracy = evaluate_model(model, test_loader)\n",
    "        print(f\"  Test Accuracy: {test_accuracy:.4f}\")\n",
    "    \n",
    "    return train_losses, train_accuracies\n",
    "\n",
    "def evaluate_model(model, test_loader):\n",
    "    \"\"\"Evaluate model performance\"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    correct_predictions = 0\n",
    "    total_predictions = 0\n",
    "    all_predictions = []\n",
    "    all_labels = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in test_loader:\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "            \n",
    "            outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "            logits = outputs.logits\n",
    "            \n",
    "            predictions = torch.argmax(logits, dim=1)\n",
    "            correct_predictions += (predictions == labels).sum().item()\n",
    "            total_predictions += labels.size(0)\n",
    "            \n",
    "            all_predictions.extend(predictions.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "    \n",
    "    accuracy = correct_predictions / total_predictions\n",
    "    \n",
    "    # Detailed evaluation\n",
    "    if len(set(all_labels)) > 1:  # Multi-class classification\n",
    "        print(\"\\\\nüìä Detailed Evaluation:\")\n",
    "        print(classification_report(all_labels, all_predictions, \n",
    "                                  target_names=['Negative', 'Positive']))\n",
    "        \n",
    "        # Confusion matrix\n",
    "        cm = confusion_matrix(all_labels, all_predictions)\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "                   xticklabels=['Negative', 'Positive'],\n",
    "                   yticklabels=['Negative', 'Positive'])\n",
    "        plt.title('Confusion Matrix')\n",
    "        plt.ylabel('True Label')\n",
    "        plt.xlabel('Predicted Label')\n",
    "        plt.show()\n",
    "    \n",
    "    model.train()  # Set back to training mode\n",
    "    return accuracy\n",
    "\n",
    "# Main fine-tuning demonstration\n",
    "if transformers_available:\n",
    "    print(\"üöÄ BERT FINE-TUNING DEMONSTRATION\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Load pre-trained BERT model and tokenizer\n",
    "    model_name = \"bert-base-uncased\"\n",
    "    tokenizer = BertTokenizer.from_pretrained(model_name)\n",
    "    model = BertForSequenceClassification.from_pretrained(\n",
    "        model_name,\n",
    "        num_labels=2  # Binary classification (positive/negative)\n",
    "    )\n",
    "    model.to(device)\n",
    "    \n",
    "    print(f\"‚úÖ Loaded BERT model: {model_name}\")\n",
    "    print(f\"   Number of parameters: {sum(p.numel() for p in model.parameters()):,}\")\n",
    "    \n",
    "    # Create sample dataset\n",
    "    texts, labels = create_sample_dataset()\n",
    "    print(f\"\\\\nüìä Dataset Statistics:\")\n",
    "    print(f\"   Total samples: {len(texts)}\")\n",
    "    print(f\"   Positive samples: {sum(labels)}\")\n",
    "    print(f\"   Negative samples: {len(labels) - sum(labels)}\")\n",
    "    \n",
    "    # Prepare data loaders\n",
    "    train_loader, test_loader, train_dataset, test_dataset = prepare_data_loaders(\n",
    "        texts, labels, tokenizer, batch_size=4  # Small batch size for demo\n",
    "    )\n",
    "    \n",
    "    # Show sample tokenization\n",
    "    print(f\"\\\\nüî§ Sample Tokenization:\")\n",
    "    sample_text = texts[0]\n",
    "    tokens = tokenizer.tokenize(sample_text)\n",
    "    token_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
    "    \n",
    "    print(f\"Original text: {sample_text}\")\n",
    "    print(f\"Tokens: {tokens}\")\n",
    "    print(f\"Token IDs: {token_ids}\")\n",
    "    \n",
    "    # Train the model\n",
    "    print(f\"\\\\nüéØ Starting Fine-tuning:\")\n",
    "    train_losses, train_accuracies = train_bert_model(\n",
    "        model, train_loader, test_loader, \n",
    "        num_epochs=2,  # Small number for demo\n",
    "        learning_rate=2e-5\n",
    "    )\n",
    "    \n",
    "    # Plot training progress\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
    "    \n",
    "    ax1.plot(train_losses, 'b-', label='Training Loss')\n",
    "    ax1.set_title('Training Loss')\n",
    "    ax1.set_xlabel('Epoch')\n",
    "    ax1.set_ylabel('Loss')\n",
    "    ax1.legend()\n",
    "    \n",
    "    ax2.plot(train_accuracies, 'r-', label='Training Accuracy')\n",
    "    ax2.set_title('Training Accuracy')\n",
    "    ax2.set_xlabel('Epoch')\n",
    "    ax2.set_ylabel('Accuracy')\n",
    "    ax2.legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Final evaluation\n",
    "    print(f\"\\\\nüèÅ Final Model Evaluation:\")\n",
    "    final_accuracy = evaluate_model(model, test_loader)\n",
    "    print(f\"Final Test Accuracy: {final_accuracy:.4f}\")\n",
    "\n",
    "else:\n",
    "    print(\"‚ùå Transformers library not available for BERT fine-tuning demo\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
